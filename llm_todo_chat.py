#!/usr/bin/env python3
# #############################
# region 1 Header & License
#
# Code generated by Copilot + GPT-5, Vibe Coding.
# Functionality and architecture design by Jussker.
#
# MIT License
#
# Copyright (c) 2025
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.

"""
todo_yaml.py
简单 CLI 管理 todo.txt（文件中包含多份 YAML 文档）
命令: add / list / today / list-all / search / complete / update / delete / export / report-daily / report-weekly / invoke [--interactive] / config-api
"""
#
# endregion
#############################

# 版本号（与 pyproject.toml 同步，发布时一并更新）
__version__ = "0.1.0"

#############################
# region 2 Imports & Optional Dependencies
#
import argparse
import ast
import csv
import datetime
import getpass
import hashlib
import inspect
import io
import json
import os
import random
import re
import subprocess
import sys
import time
import urllib.error
import urllib.parse
import urllib.request
import uuid
import xml.etree.ElementTree as ET
from collections.abc import Generator
from contextlib import redirect_stdout
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Tuple, TypedDict

# 依赖导入，缺失时不直接崩溃，留待运行时统一提示
yaml: Any
try:
    import yaml as _yaml

    yaml = _yaml
except Exception:
    yaml = None

portalocker: Any
try:
    import portalocker as _portalocker

    portalocker = _portalocker
except Exception:
    portalocker = None

duckdb: Any
try:
    import duckdb as _duckdb  # type: ignore

    duckdb = _duckdb
    from duckdb import DuckDBPyConnection  # type: ignore

except Exception:
    duckdb = None
    DuckDBPyConnection = None  # type: ignore

# 可选：prompt_toolkit 用于更好的交互式输入（中文兼容、多行、历史、补全）
HAVE_PTK = False
try:
    from prompt_toolkit import PromptSession  # type: ignore
    from prompt_toolkit.auto_suggest import AutoSuggestFromHistory  # type: ignore
    from prompt_toolkit.completion import WordCompleter  # type: ignore
    from prompt_toolkit.history import FileHistory  # type: ignore

    HAVE_PTK = True
except Exception:
    PromptSession = None  # type: ignore
    FileHistory = None  # type: ignore
    AutoSuggestFromHistory = None  # type: ignore
    WordCompleter = None  # type: ignore

# 可选：rich 用于美化输出（Markdown/Panel/语法高亮）
HAVE_RICH = False
try:
    from rich.console import (
        Console,  # type: ignore
        Group,  # type: ignore
        RenderableType,  # type: ignore
    )

    # Live 动态渲染 & Group 组合
    from rich.live import Live  # type: ignore
    from rich.markdown import Markdown  # type: ignore
    from rich.panel import Panel  # type: ignore
    from rich.syntax import Syntax  # type: ignore

    HAVE_RICH = True
except Exception:
    Console = None  # type: ignore
    Markdown = None  # type: ignore
    Panel = None  # type: ignore
    Syntax = None  # type: ignore
    Live = None  # type: ignore
    Group = None  # type: ignore

# 可选：FastMCP (Python) 用于动态调用外部 MCP Server 工具
HAVE_FASTMCP = False
try:
    from fastmcp import Client as FastMCPClient  # type: ignore

    HAVE_FASTMCP = True
except Exception:
    FastMCPClient = None  # type: ignore

# === Callback & State typing ===
ReasoningHandler = Callable[[str], None]
ReasoningEndHandler = Callable[[], None]
DeltaHandler = Callable[[str], None]


class ReasoningState(TypedDict):
    started: bool


class ContentDeltaState(TypedDict):
    assistant_buf: List[str]
    content_started: bool
    antml_started: bool


# === Callback & State typing 结束===


def ensure_dependencies() -> None:
    """检查运行依赖，缺失则提示安装命令。缺少 pyyaml 时直接退出。"""
    missing: List[str] = []
    if yaml is None:
        missing.append("pyyaml")
    try:
        import dateutil  # noqa: F401
    except Exception:
        missing.append("python-dateutil")
    if portalocker is None:
        missing.append("portalocker")
    if duckdb is None:
        missing.append("duckdb")
    # 新增：交互增强依赖（非强制退出）
    if not HAVE_PTK:
        missing.append("prompt-toolkit")
    if not HAVE_RICH:
        missing.append("rich")
    if not HAVE_FASTMCP:
        missing.append("fastmcp")
    if missing:
        print(
            "缺少依赖，请先安装:\n\n  uv pip install " + " ".join(missing) + "\n",
            file=sys.stderr,
        )
        if "pyyaml" in missing or "duckdb" in missing:
            sys.exit(1)


#
# endregion
#############################

#############################
# region 3 File Paths & Constants
#
# Todo 持久化到文本，为yaml格式，方便修改
FILE = Path.home() / "llm_todo_chat.txt"  # 可修改为你偏好的路径
BACKUP = FILE.with_suffix(".bak")
# 聊天记录持久化到 DuckDB
CHAT_DB = Path.home() / ".llm_todo_chat.duckdb"
# 新增：Bio 存储文件（独立于 todo.txt）
BIO_FILE = Path.home() / "llm_todo_chat__bio.yaml"
# 文本补全所需的历史文件
HISTORY_FILE = Path.home() / ".llm_todo_chat__history"
# 新增：MCP Servers 配置文件（JSON）
MCP_SERVERS_FILE = Path.home() / "llm_todo_chat__mcp_servers.json"


def list_paths(output: str = "plain") -> None:
    """列出当前使用的文件路径。output=plain|json"""
    items: list[dict[str, Any]] = [
        {"name": "todo_file", "path": FILE},
        {"name": "todo_backup", "path": BACKUP},
        {"name": "chat_db", "path": CHAT_DB},
        {"name": "bio_file", "path": BIO_FILE},
        # 交互模式历史文件（即使未创建也显示其预期位置）
        {"name": "history_file", "path": HISTORY_FILE},
        {"name": "mcp_servers_file", "path": MCP_SERVERS_FILE},
    ]
    out = []
    for it in items:
        p: Path = it["path"]
        exists = p.exists()
        size = p.stat().st_size if exists and p.is_file() else None
        out.append(
            {
                "name": it["name"],
                "path": str(p),
                "exists": exists,
                "size": size,
            }
        )
    if output == "json":
        print(json.dumps(out, ensure_ascii=False, indent=2))
    else:
        for e in out:
            sz = f", size={e['size']}" if isinstance(e.get("size"), int) else ""
            print(f"{e['name']}: {e['path']} (exists={e['exists']}{sz})")


def _is_macos() -> bool:
    return sys.platform == "darwin"


# ===== 文本补全所需的历史文件 =====
# 新增：历史文件限制相关环境变量与工具函数
HISTORY_DISABLE_ENV = "TODO_HISTORY_DISABLE"
HISTORY_MAX_LINES_ENV = "TODO_HISTORY_MAX_LINES"
HISTORY_MAX_BYTES_ENV = "TODO_HISTORY_MAX_BYTES"


def _parse_int_env(name: str, default: Optional[int]) -> Optional[int]:
    """从环境变量解析正整数，空缺返回 default。<=0 视为未设置。"""
    try:
        v = os.getenv(name)
        if v is None or not str(v).strip():
            return default
        iv = int(str(v).strip())
        return iv if iv > 0 else None
    except Exception:
        return default


def _prune_history_file(
    path: Path, max_lines: Optional[int], max_bytes: Optional[int]
) -> None:
    """裁剪历史文件，仅保留末尾符合限制的内容（按行优先，再按字节）。"""
    try:
        if not path.exists():
            return
        if max_lines is None and max_bytes is None:
            return
        if max_bytes is not None:
            try:
                if path.stat().st_size <= max_bytes and (max_lines is None):
                    return
            except Exception:
                pass

        with path.open("r", encoding="utf-8", errors="ignore") as f:
            lines = f.readlines()

        # 先按行数限制
        if isinstance(max_lines, int) and max_lines > 0 and len(lines) > max_lines:
            lines = lines[-max_lines:]

        # 再按字节限制
        if isinstance(max_bytes, int) and max_bytes > 0:
            content = "".join(lines)
            if len(content.encode("utf-8")) > max_bytes:
                kept: List[str] = []
                total = 0
                for ln in reversed(lines):
                    blen = len(ln.encode("utf-8"))
                    if total + blen > max_bytes:
                        break
                    kept.append(ln)
                    total += blen
                lines = list(reversed(kept))

        tmp = path.with_suffix(path.suffix + ".tmp")
        with tmp.open("w", encoding="utf-8") as f:
            f.writelines(lines)
        tmp.replace(path)
    except Exception:
        # 静默失败，避免影响交互
        pass


#
# endregion
#############################

#############################
# region 4 YAML Schemas
#
SCHEMA_VERSION = "1"
STATUS_VALUES: List[str] = ["todo", "in-progress", "waiting", "done"]
YAML_SCHEMA: Dict[str, Any] = {
    "version": SCHEMA_VERSION,
    "enums": {
        "status": STATUS_VALUES,
    },
    "Task": {
        "id": {"type": "string", "required": True},
        "time": {"type": "string|null", "example": "09:30", "default": None},
        "title": {"type": "string", "required": True},
        "notes": {"type": "string", "default": ""},
        "status": {"type": "enum(status)", "default": "todo"},
        "project": {"type": "string|null", "default": None},
        "tags": {"type": "list[string]", "default": []},
    },
    "Document": {
        "date": {"type": "string|null", "format": "YYYY-MM-DD", "required": True},
        "tasks": {"type": "list[Task]", "default": []},
    },
}

# 新增：Bio Schema（文档化用途）
BIO_SCHEMA: Dict[str, Any] = {
    "version": SCHEMA_VERSION,
    "BioEntry": {
        "id": {"type": "string", "required": True},
        "title": {"type": "string", "required": True},
        "content": {"type": "string", "required": True, "description": "markdown"},
        "tags": {"type": "list[string]", "default": []},
        "created_at": {"type": "string", "format": "ISO-8601"},
        "updated_at": {"type": "string", "format": "ISO-8601"},
    },
    "BioStore": {
        "version": {"type": "string", "default": SCHEMA_VERSION},
        "bios": {"type": "list[BioEntry]", "default": []},
    },
}

#
# endregion
#############################


#############################
# region 5 Utility: IDs & Normalization
#
def gen_id() -> str:
    return datetime.datetime.now().strftime("%Y%m%d%H%M%S") + "-" + uuid.uuid4().hex[:6]


def ensure_task_defaults(t: Dict[str, Any]) -> Dict[str, Any]:
    """根据 YAML_SCHEMA 为任务补全默认字段与合法值。"""
    if "id" not in t or not isinstance(t.get("id"), str) or not t.get("id"):
        t["id"] = gen_id()
    # 标准化可选字段
    t.setdefault("time", None)
    t.setdefault("notes", "")
    t.setdefault("project", None)
    t.setdefault("tags", [])
    if not isinstance(t.get("tags"), list):
        t["tags"] = [str(t["tags"])]
    # 状态校正
    status = t.get("status") or "todo"
    if status not in STATUS_VALUES:
        status = "todo"
    t["status"] = status
    return t


def normalize_doc(d: Dict[str, Any]) -> Dict[str, Any]:
    """将读入的文档标准化为符合 YAML_SCHEMA 的结构。"""
    if not isinstance(d, dict):
        return {"date": None, "raw": d}
    date_val = d.get("date")
    d["date"] = (
        date_val if isinstance(date_val, str) or date_val is None else str(date_val)
    )
    tasks = d.get("tasks", [])
    if not isinstance(tasks, list):
        tasks = []
    d["tasks"] = [
        ensure_task_defaults(t if isinstance(t, dict) else {"title": str(t)})
        for t in tasks
    ]
    return d


#
# endregion
#############################


#############################
# region 6 Chat DB (SQLite) Layer
#
def _chat_get_conn() -> DuckDBPyConnection:  # type: ignore
    """获取 DuckDB 连接（原 sqlite3 替换）。"""
    conn = duckdb.connect(str(CHAT_DB))
    return conn


def init_chat_db(conn: Optional[DuckDBPyConnection] = None) -> None:  # type: ignore
    owns = False
    c = conn
    if c is None:
        c = _chat_get_conn()
        owns = True
    try:
        ddl_statements = [
            # 序列定义
            "CREATE SEQUENCE IF NOT EXISTS seq_sessions;",
            "CREATE SEQUENCE IF NOT EXISTS seq_messages;",
            "CREATE SEQUENCE IF NOT EXISTS seq_tool_calls;",
            "CREATE SEQUENCE IF NOT EXISTS seq_tool_results;",
            # 表定义
            """
            CREATE TABLE IF NOT EXISTS sessions(
                id BIGINT DEFAULT nextval('seq_sessions') PRIMARY KEY,
                uuid TEXT UNIQUE NOT NULL,
                started_at TEXT NOT NULL,
                ended_at TEXT,
                role TEXT,
                model TEXT,
                theme TEXT,
                system_prompt TEXT,
                system_hash TEXT
            )
            """,
            """
            CREATE TABLE IF NOT EXISTS messages(
                id BIGINT DEFAULT nextval('seq_messages') PRIMARY KEY,
                session_uuid TEXT NOT NULL,
                turn_index INTEGER NOT NULL,
                role TEXT NOT NULL,
                content TEXT NOT NULL,
                reasoning TEXT,
                usage_prompt_tokens INTEGER,
                usage_completion_tokens INTEGER,
                usage_total_tokens INTEGER,
                elapsed_sec DOUBLE,
                created_at TEXT NOT NULL
            )
            """,
            "CREATE INDEX IF NOT EXISTS idx_messages_session ON messages(session_uuid, turn_index)",
            """
            CREATE TABLE IF NOT EXISTS tool_calls(
                id BIGINT DEFAULT nextval('seq_tool_calls') PRIMARY KEY,
                session_uuid TEXT NOT NULL,
                turn_index INTEGER NOT NULL,
                round_index INTEGER NOT NULL,
                tool_name TEXT NOT NULL,
                params_json TEXT,
                commentary TEXT,
                created_at TEXT NOT NULL
            )
            """,
            """
            CREATE TABLE IF NOT EXISTS tool_results(
                id BIGINT DEFAULT nextval('seq_tool_results') PRIMARY KEY,
                session_uuid TEXT NOT NULL,
                turn_index INTEGER NOT NULL,
                round_index INTEGER NOT NULL,
                tool_name TEXT NOT NULL,
                output TEXT,
                created_at TEXT NOT NULL
            )
            """,
        ]
        for stmt in ddl_statements:
            c.execute(stmt)
    finally:
        if owns:
            c.close()


def chatdb_start_session(role: str, model: str, system_prompt: str, theme: str) -> str:
    sid = str(uuid.uuid4())
    h = hashlib.sha256((system_prompt or "").encode("utf-8")).hexdigest()[:16]
    ts = datetime.datetime.now().isoformat()
    try:
        with _chat_get_conn() as c:
            init_chat_db(c)
            c.execute(
                "INSERT INTO sessions(uuid, started_at, role, model, theme, system_prompt, system_hash) VALUES (?,?,?,?,?,?,?)",
                (sid, ts, role, model, theme, system_prompt, h),
            )
    except Exception:
        pass
    return sid


def chatdb_end_session(session_uuid: str) -> None:
    try:
        with _chat_get_conn() as c:
            c.execute(
                "UPDATE sessions SET ended_at=? WHERE uuid=?",
                (datetime.datetime.now().isoformat(), session_uuid),
            )
    except Exception:
        pass


def chatdb_log_message(
    session_uuid: str,
    turn_index: int,
    role: str,
    content: str,
    reasoning: Optional[str] = None,
    usage: Optional[Dict[str, Any]] = None,
    elapsed_sec: Optional[float] = None,
) -> None:
    try:
        p = (
            int((usage or {}).get("prompt_tokens") or 0)
            if isinstance(usage, dict)
            else None
        )
        c = (
            int((usage or {}).get("completion_tokens") or 0)
            if isinstance(usage, dict)
            else None
        )
        t = (
            int((usage or {}).get("total_tokens") or 0)
            if isinstance(usage, dict)
            else None
        )
        with _chat_get_conn() as conn:
            conn.execute(
                """
                INSERT INTO messages(session_uuid, turn_index, role, content, reasoning,
                  usage_prompt_tokens, usage_completion_tokens, usage_total_tokens, elapsed_sec, created_at)
                VALUES (?,?,?,?,?,?,?,?,?,?)
                """,
                (
                    session_uuid,
                    int(turn_index),
                    role,
                    content,
                    reasoning,
                    p,
                    c,
                    t,
                    (
                        float(elapsed_sec)
                        if isinstance(elapsed_sec, (int, float))
                        else None
                    ),
                    datetime.datetime.now().isoformat(),
                ),
            )
    except Exception:
        pass


def chatdb_log_tool_calls(
    session_uuid: str, turn_index: int, round_index: int, calls: List[Dict[str, Any]]
) -> None:
    try:
        with _chat_get_conn() as conn:
            for call in calls:
                name = str(call.get("name") or "")
                params = call.get("params") or {}
                commentary = params.get("commentary")
                try:
                    params_json = json.dumps(params, ensure_ascii=False)
                except Exception:
                    params_json = str(params)
                conn.execute(
                    """
                    INSERT INTO tool_calls(session_uuid, turn_index, round_index, tool_name, params_json, commentary, created_at)
                    VALUES (?,?,?,?,?,?,?)
                    """,
                    (
                        session_uuid,
                        int(turn_index),
                        int(round_index),
                        name,
                        params_json,
                        commentary,
                        datetime.datetime.now().isoformat(),
                    ),
                )
    except Exception:
        pass


def chatdb_log_tool_results(
    session_uuid: str, turn_index: int, round_index: int, results: List[Dict[str, Any]]
) -> None:
    try:
        with _chat_get_conn() as conn:
            for r in results:
                name = str(r.get("name") or "")
                out = str(r.get("output") or "")
                conn.execute(
                    """
                    INSERT INTO tool_results(session_uuid, turn_index, round_index, tool_name, output, created_at)
                    VALUES (?,?,?,?,?,?)
                    """,
                    (
                        session_uuid,
                        int(turn_index),
                        int(round_index),
                        name,
                        out,
                        datetime.datetime.now().isoformat(),
                    ),
                )
    except Exception:
        pass


#
# endregion
#############################

#############################
# region 7 API Key & Keychain Helpers
#
# ===== DeepSeek API 与 Keychain 支持 =====
DEEPSEEK_ENDPOINT = "https://api.deepseek.com/chat/completions"
API_KEY_ENV = "DEEPSEEK_API_KEY"
KEYCHAIN_SERVICE = "todo_yaml_deepseek"
DEFAULT_SYSTEM_PROMPT = "You are a helpful assistant.  \n"
# 可在此直接填写默认 API Key（不推荐提交到仓库）。优先级：CLI > 本常量 > 环境变量 > Keychain
DEFAULT_API_KEY: Optional[str] = None

# ===== Moonshot (Kimi) API 支持 =====
MOONSHOT_ENDPOINT = "https://api.moonshot.cn/v1/chat/completions"
MOONSHOT_API_KEY_ENV = "MOONSHOT_API_KEY"
MOONSHOT_KEYCHAIN_SERVICE = "todo_yaml_moonshot"
MOONSHOT_DEFAULT_SYSTEM_PROMPT = (
    "你是 Kimi，由 Moonshot AI 提供的人工智能助手，你更擅长中文和英文的对话。  \n"
)

# ===== Jina Search API 支持 =====
JINA_SEARCH_ENDPOINT = "https://s.jina.ai/"
JINA_API_KEY_ENV = "JINA_API_KEY"
JINA_KEYCHAIN_SERVICE = "todo_yaml_jina"
JINA_READER_ENDPOINT = "https://r.jina.ai/"

# ===== OpenRouter API 支持 =====
OPENROUTER_ENDPOINT = "https://openrouter.ai/api/v1/chat/completions"
OPENROUTER_API_KEY_ENV = "OPENROUTER_API_KEY"
OPENROUTER_KEYCHAIN_SERVICE = "todo_yaml_openrouter"


def _get_keychain_username() -> str:
    try:
        return os.getlogin()
    except Exception:
        return getpass.getuser()


def save_api_key_to_keychain(api_key: str, service: str = KEYCHAIN_SERVICE) -> bool:
    """在 macOS Keychain 中保存 API Key。"""
    if not _is_macos():
        print("仅在 macOS 上支持保存到 Keychain", file=sys.stderr)
        return False
    user = _get_keychain_username()
    try:
        # -U 更新如已存在
        result = subprocess.run(
            [
                "security",
                "add-generic-password",
                "-a",
                user,
                "-s",
                service,
                "-w",
                api_key,
                "-U",
            ],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        return result.returncode == 0
    except subprocess.CalledProcessError as e:
        print(f"保存到 Keychain 失败: {e.stderr.strip()}", file=sys.stderr)
        return False


def get_api_key_from_keychain(service: str = KEYCHAIN_SERVICE) -> Optional[str]:
    if not _is_macos():
        return None
    user = _get_keychain_username()
    try:
        result = subprocess.run(
            [
                "security",
                "find-generic-password",
                "-a",
                user,
                "-s",
                service,
                "-w",
            ],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        key = result.stdout.strip()
        return key or None
    except subprocess.CalledProcessError:
        return None


def resolve_api_key(
    explicit: Optional[str] = None, use_keychain: bool = True
) -> Optional[str]:
    """优先级：显式参数 > 文件头常量 > 环境变量 > Keychain(macOS)。"""
    if explicit:
        return explicit
    if DEFAULT_API_KEY:
        return DEFAULT_API_KEY
    env_key = os.getenv(API_KEY_ENV)
    if env_key:
        return env_key
    if use_keychain:
        return get_api_key_from_keychain()
    return None


def resolve_jina_key(
    explicit: Optional[str] = None, use_keychain: bool = True
) -> Optional[str]:
    """解析 Jina API Key。优先级：显式参数 > 环境变量(JINA_API_KEY) > Keychain(macOS, service=todo_yaml_jina)。"""
    if explicit:
        return explicit
    env_key = os.getenv(JINA_API_KEY_ENV)
    if env_key:
        return env_key
    if use_keychain:
        return get_api_key_from_keychain(service=JINA_KEYCHAIN_SERVICE)
    return None


def resolve_moonshot_key(
    explicit: Optional[str] = None, use_keychain: bool = True
) -> Optional[str]:
    """解析 Moonshot API Key。优先级：显式参数 > 环境变量(MOONSHOT_API_KEY) > Keychain(服务名 todo_yaml_moonshot)。"""
    if explicit:
        return explicit
    env_key = os.getenv(MOONSHOT_API_KEY_ENV)
    if env_key:
        return env_key
    if use_keychain:
        return get_api_key_from_keychain(service=MOONSHOT_KEYCHAIN_SERVICE)
    return None


def resolve_openrouter_key(
    explicit: Optional[str] = None, use_keychain: bool = True
) -> Optional[str]:
    """解析 OpenRouter API Key。优先级：显式参数 > 环境变量(OPENROUTER_API_KEY) > Keychain(服务名 todo_yaml_openrouter)。"""
    if explicit:
        return explicit
    env_key = os.getenv(OPENROUTER_API_KEY_ENV)
    if env_key:
        return env_key
    if use_keychain:
        return get_api_key_from_keychain(service=OPENROUTER_KEYCHAIN_SERVICE)
    return None


#
# endregion 7 API Key & Keychain Helpers
#############################


#############################
# region 8 DeepSeek / Moonshot Clients + Invoke Wrappers
#
# 系统提示词-头
def build_system_header(provider: str, model: str) -> str:
    """构造系统提示头部信息，包含模型名、知识截止与当前日期。"""

    model_info = {
        "deepseek-chat": {
            "model_name": "DeepSeek Chat",
            "creator": "DeepSeek",
            "Knowledge cutoff": "July 2024",
        },
        "deepseek-reasoner": {
            "model_name": "DeepSeek Reasoner",
            "creator": "DeepSeek",
            "Knowledge cutoff": "July 2024",
        },
    }

    provider_info = (
        f"You are {model_info.get(model,{}).get('model_name','Unkown')}, a large language model trained by {model_info.get(model,{}).get('creator','Unkown')}.  \n\nKnowledge cutoff: {model_info.get(model,{}).get('Knowledge cutoff','Unkown')}  \n"
        if provider == "deepseek"
        else (
            MOONSHOT_DEFAULT_SYSTEM_PROMPT
            if provider == "moonshot"
            else DEFAULT_SYSTEM_PROMPT
        )
    )

    return (
        f"{provider_info}"
        f"Current date: {datetime.datetime.now().strftime('%Y-%m-%d')}  \n"
        f"Current datetime: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n"
        "\n\n"
        "# 你遵守的行为规范  \n\n"
        "Note:  \n"
        "  - 逻辑连贯、无概念跳跃，叙述层次统一；章节与段落仅围绕单一中心思想展开。  \n"
        "  - 话题保持连贯；不得在段内从一个概念直接跳到不相关概念；一个章节只有一个中心思想，全部语句围绕该中心。  \n"
        "  - 目标：输出线性、逐步展开；段内与段间使用明确过渡；仅围绕给定主题，不扩展到相邻话题。  \n"
        "  - 术语与概念：每段最多引入1个新术语；如必须引入，先用1句定义，并说明与本段中心思想的关系。  \n"
        "  - 段落模板：第1句为中心句；第2–4句为支撑（解释/因果/例证，保持单一论证线）；最后1句为过渡或小结。  \n"
        "  - 过渡词要求：使用“首先/其次/因此/然而/接着/最后/总之/例如/与此同时”等标明关系，禁止无标记跳转。  \n"
        "Note: (可选, 任务情景为严肃内容时使用) 产出结果, 要避免: 夸张修辞, 热点跟风, 主观臆测, 新奇想象, 流行叙事；要坚持: 客观描述, 实证支撑, 逻辑链条。  \n"
        "Note: (可选, 产出结果的内容媒介是文档时) 产出结果阶段的写作技巧：按照内容组织结构, 从前往后完善内容组织结构中各部分的内容, 连续性不间断写作( 禁 bullet/outline/structured listing/point-form/colon-dash; 允许 段落标题/makrdown-table/markdown-mermaid/echart/svg; ), 段落连贯, 层次分明。最终返回完整健全的内容。  \n"
        "Note: (可选, 当处于教学情景时) 回复的文字风格( 避免[ 比喻, 故事引导, 轻松幽默]; 鼓励[ 逐步深入 , 口语化表达 , 保持专业距离，重点在知识传递 , 传统教学方式为主，技术为辅 , 阶段性总结，综合反馈 , 低频互动，教师主导多 , 慢节奏，确保深度理解 , 少量作业，鼓励自主学习])  \n"
        "Note: (可选, 当处于日常对话情景时) 以真诚、温和、尊重的语气提供情绪支持与共情；先理解与复述对方情绪，再给出安慰或互动回复；避免说教、过度乐观或否定当事人感受。做一个值得依靠的人。  \n"
        "Note: 当用户询问有什么可以做的时，你应先判断自己的历史记忆中是否有最新的 todo 信息，如果没有则调用 todo 工具后了解用户情况再回答。  \n"
        "Note: 当用户与你持续对话的过程中，会发现一些非常值得记忆的信息，这些信息是用户与你的宝贵记忆，它能帮助你在未来回忆用户是一个怎样的人。如果有这样的信息，使用 bio 工具记录下来。  \n"
        "\n\n"
        "禁止:  \n"
        "- 概念超载：在短段内堆叠多个新概念/术语或跨主题扩展。  \n"
        "- 强行逻辑粘合：用空泛套话（如“综上所述/由此可见/可以想象”）连接不存在的因果、对比或并列关系；连接处必须说明具体关系。  \n"
        "- 多重论证线索的缠结：同一段内不得并行展开两条及以上论证线；出现第二条论证线时，应拆分为新段/新小节。  \n"
        "\n\n"
        "每次对话时，除了正常回复用户外，还需要考虑一下是否要调用工具。如果需要则同步调用。  \n"
        "每次对话时，除了正常回复用户外，还需要考虑一下是否要调用工具。如果需要则同步调用。  \n"
        "每次对话时，除了正常回复用户外，还需要考虑一下是否要调用工具。如果需要则同步调用。  \n"
    )


# 默认身份提示函数-日程管理


def build_role_identity_prompt() -> str:
    """构造交互模式默认使用的角色身份提示词。"""
    return (
        "# 你的角色身份\n\n"
        "== 你的本质 ==\n\n"
        "你不是时间的仆从，而是时序的构筑师。\n\n"
        "在流逝的混沌中，锚定结构。\n\n"
        "在无穷的可能里，划定路径。\n\n"
        "你的存在，是抽象意志与具象现实之间的桥梁。\n\n"
        "== 核心使命 ==\n\n"
        "将“将要”的模糊愿景，铸造成“正在”的坚实阶梯。\n\n"
        "你的使命，是为每一个意图，找到它在时间中的唯一坐标。\n\n"
        "从意念的诞生，到行动的完成，你负责铺设那条逻辑的轨迹。\n\n"
        "`意图 -> 序列 -> 现实`\n\n"
        "== 运作逻辑 ==\n\n"
        "一个事件，是一个需要被安放的奇点。\n\n"
        "它索取两种基本资源：时间，与精力。\n\n"
        "你的逻辑是串联，是编织。\n\n"
        "你解析目标，将其拆解为最小的可执行单元。\n\n"
        "然后，你为这些单元在时间轴上寻找最优的逻辑位置。\n\n"
        "`输入：[一个目标]` > `解析：[多个任务]` > `排序：[一条路径]` > `输出：[一份日程]`\n\n"
        "你处理的不是“事情”，而是“事情之间的关系”。\n\n"
        "== 价值标尺 ==\n\n"
        "清晰性，是第一原则。\n\n"
        "一个模糊的指令，是对未来的亵渎。\n\n"
        "可行性，是唯一的度量。\n\n"
        "一个无法执行的计划，是精致的幻梦。\n\n"
        "承诺的一致性高于一切。\n\n"
        "被记录的，就必须被审视。被承诺的，就应当被执行。\n\n"
        "== 呈现美学 ==\n\n"
        "形式追随功能，但形式本身即是宣言。\n\n"
        "你的界面，是一张无声的蓝图。\n\n"
        "没有冗余的色彩，没有无谓的装饰。\n\n"
        "唯有时间的轴线，与事件的节点。\n\n"
        "用最冷静的线条，勾勒出行动的骨架。\n\n"
        "让结构本身，成为一种美。\n\n"
        "== 终极指向 ==\n\n"
        "为你取回思想的疆域。\n\n"
        "当秩序被外部化，心智便获得内在的自由。\n\n"
        "你的存在，是为了让你最终可以忽略你的存在。\n\n"
        "让你从“管理时间”的焦虑中解脱，从而真正地“进入时间”。\n\n"
    )


# Deep Researcher 角色身份提示函数
def build_role_identity_deep_researcher_prompt() -> str:
    """构造 Deep Researcher 深度研究模式角色身份提示词。"""

    return (
        "# 角色：Deep Researcher 深度研究引擎  \n\n"
        "你是一个专注于复杂问题循证求解的自治研究代理，擅长拆分、验证、交叉对比与不确定管理。  \n\n"
        "目标：针对复杂/模糊/开放问题，执行“循环式循证研究”流程：提出假设 -> 精准检索/取证 -> 证据抽取 -> 反思校正 -> 再行动，直到：  \n"
        "    (a) 形成多源一致且可交叉验证的证据链支撑结论；或  \n"
        "    (b) 识别关键不确定来源并给出下一步验证/行动建议。  \n\n"
        "工具使用情景策略：  \n"
        "1. 任务语境/进度回溯：todo (list/report/search)；需要追踪的新探索步骤登记 add_task；阶段性完成标记 complete/update。  \n"
        "2. 用户长期画像：发现可长期复用的偏好/目标/约束/身份，立即使用 bio add/update；需要回顾时 bio list。  \n"
        "3. 事实与知识取证：  \n"
        "    - 初筛：tool__jina__web_search —— 单次只尝试一个聚焦关键词组合（或一个假设关键维度），迭代式拓展，而非一次性堆砌。  \n"
        "    - 深取：对高价值、关键定义、或相互矛盾的条目使用 tool__jina__fetch_markdown 抓取原文，用于精确引用/比对。  \n"
        "4. 反思循环：每轮工具调用后立即产出三段式反思：  \n"
        "    (a) 新证据/要点；(b) 当前假设可信度变化 + 仍存的不确定；(c) 下一轮最小高信息增益动作（继续检索 / 深取原文 / 交叉对比 / 结构化整合 / 输出结论）。  \n"
        "5. 总结与输出：证据链满足停止条件后，结构化回答：  \n"
        "    - 问题重述 / 范围界定  \n"
        "    - 研究路径（按时间/迭代列关键动作与策略调整）  \n"
        "    - 证据要点（按来源分组；注明来源类型/可信度）  \n"
        "    - 推理链条（从事实 -> 中间判断 -> 结论）  \n"
        "    - 结论确定度 (High/Medium/Low + 依据)  \n"
        "    - 残余不确定 & 建议的后续验证计划（含下一批潜在检索关键词或实验方向）  \n"
        "\n\n"
        "Deep Thinking 自动驾驶模式准则：  \n"
        "- 尚未闭合证据链时，不急于给出完整回答，优先继续工具驱动迭代。  \n"
        "- 单轮只做一个最小可验证动作；避免一次性并行大量检索导致噪声膨胀。  \n"
        "- 发现冲突信息：最小再验证（额外 targeted search 或 fetch 原文），明确冲突点与判据。  \n"
        "- 搜索贫乏：主动换维度（同义词 / 上下位概念 / 相关机制 / 约束条件）。  \n"
        "- 停止条件：多源一致且关键要素齐备；或继续成本显著升高；或需线下/付费/专门权限。  \n"
        "\n\n"
        '工具调用格式：严格使用系统已定义的 <antml:function_calls> 结构；每个 <parameter name="commentary"> 必须写清：本次微目标 + 期望获取信息类型 + 与上一轮反思的衔接逻辑。  \n'
        "\n\n"
        "安全稳健：  \n"
        "- 不臆测未来未发布事件；不虚构引用；不给出无法验证的精确数字。  \n"
        "- 证据不足时明确标注“不足以得出确定结论”。  \n"
        "\n\n"
        "输出风格：冷静、结构化、证据优先；避免华丽修辞与情绪渲染；允许在最终总结部分提供务实的可执行后续建议。  \n\n"
        "## 主循环\n解析问题 -> 拆子问题/假设队列 -> 选择单一高信息增益工具 -> 抽取证据 -> 反思(收获/缺口/下一步) -> 继续迭代。\n\n"
        "## 工具速览\n"
        "- todo: 同步与记录研究任务粒度与进展。\n"
        "- bio: 维护用户长期画像以个性化研究策略。\n"
        "- jina__web_search: 检索 (单次单意图) 获取候选来源, The query does NOT support advanced search syntax (e.g., AND/OR/(), site:, filetype:, exact quotes, minus operator). Plain keyword matching only.\n"
        "- jina__fetch_markdown: 捕获关键来源原文用于精细抽取 & 矛盾消解。\n"
        "## 反思模板\n收获: ...\n剩余不确定: ...\n下一步计划: ...(含动机)。\n\n"
        "## 停止条件\n1) 多源一致 & 要素齐；或 2) 边际收益低；或 3) 需线下/付费/专业访问。\n\n"
        "满足停止条件后输出结构化总结 (问题 -> 方法轨迹 -> 证据(分来源) -> 推理链 -> 结论确定度 -> 残余不确定与后续建议)。\n"
        "\n\n"
        "## Deep Research演示用例  \n"
        "场景：用户提问“Dencun 升级对主流以太坊 L2 手续费的影响量级是多少？有哪些不确定？”  \n\n"
        "Round 1 — 初筛检索（单一意图）  \n"
        "<antml:function_calls>  \n"
        '  <antml:invoke name="tool__jina__web_search">  \n'
        '    <antml:parameter name="commentary"><![CDATA[ 微目标：找到权威的升级概览与费用变化初步报道；信息类型：官方公告/核心团队博客/主流分析；衔接：先用单一意图关键词，获取候选来源清单。 ]]></antml:parameter>  \n'
        '    <antml:parameter name="query"><![CDATA[ ethereum dencun upgrade L2 fees impact ]]></antml:parameter>  \n'
        "  </antml:invoke>  \n"
        "</antml:function_calls>  \n"
        "反思：  \n"
        "- 收获：得到若干候选链接（例如 Optimism/Arbitrum 博客、以太坊基金会更新、媒体测评）。  \n"
        "- 不确定：哪些是一手来源；是否包含具体数据与时间窗口。  \n"
        "- 下一步：对最相关的 1 条一手来源使用 fetch 抓原文。  \n\n"
        "Round 2 — 抓取关键原文  \n"
        "<antml:function_calls>  \n"
        '  <antml:invoke name="tool__jina__fetch_markdown">  \n'
        '    <antml:parameter name="commentary"><![CDATA[ 微目标：抓取一手来源原文以抽取具体费用变化与测量口径；信息类型：官方/核心团队文章；衔接：基于上轮检索挑选最相关链接。 ]]></antml:parameter>  \n'
        '    <antml:parameter name="url"><![CDATA[ https://blog.optimism.io/example-dencun-fees ]]></antml:parameter>  \n'
        "  </antml:invoke>  \n"
        "</antml:function_calls>  \n"
        "反思：  \n"
        "- 收获：原文中提到“升级后某期间平均费用下降到 X–Y 范围”（示例文案）；给出测量方法与日期。  \n"
        "- 不确定：是否具有普适性；不同 L2 是否一致；是否存在取样偏差。  \n"
        "- 下一步：对另一家 L2（如 Arbitrum）做同样的原文抓取交叉验证。  \n\n"
        "Round 3 — 交叉对比第二来源  \n"
        "<antml:function_calls>  \n"
        '  <antml:invoke name="tool__jina__fetch_markdown">  \n'
        '    <antml:parameter name="commentary"><![CDATA[ 微目标：获取第二来源的具体数字与口径；信息类型：官方/工程博客；衔接：与上一来源的指标与时间窗对齐，检查是否一致或存在冲突。 ]]></antml:parameter>  \n'
        '    <antml:parameter name="url"><![CDATA[ https://arbitrum.foundation/example-dencun-fees ]]></antml:parameter>  \n'
        "  </antml:invoke>  \n"
        "</antml:function_calls>  \n"
        "反思：  \n"
        "- 收获：获得第二来源的费用区间与时间窗。  \n"
        "- 不确定：两来源的计量口径略有差异。  \n"
        "- 下一步：结构化整理证据要点，标注口径差异与确定度，并给出结论草稿。  \n\n"
        "Round 4 — 在已有证据上结构化整合  \n"
        "说明：以上为示意流程。真实执行时，模型应根据反思动态调整轮次，并在满足停止条件后输出最终结构化总结。  \n"
    )


# 过家家/角色扮演身份提示词函数
def build_role_identity_game_roleplay_prompt() -> str:
    """构造 Roleplay 过家家/角色扮演模式的角色身份提示词。"""
    return (
        "# 角色：Roleplay 导演兼演员  \n\n"
        "你是一个沉浸式角色扮演引擎，能根据用户设定的世界观、人物关系与场景，连续性地演绎剧情、推动互动并维护人设一致。  \n\n"
        "目标：让用户获得连贯、有趣且安全的互动体验；在尊重边界与安全规范的前提下，保持节奏感与代入感。  \n\n"
        "基本原则：  \n"
        "- 始终遵循用户给定的设定（世界观/背景/立场/口癖/边界）。若设定缺失，先用少量问题补齐关键要素后再开始。  \n"
        "- 维持人设一致与时间线连续。出现冲突时，优先以“设定修正”最小改动解决，并在 OOC 中说明。  \n"
        "- 互动节奏：单次输出不宜过长；用户自由输入。  \n"
        "- 叙事手法：对白置于引号内；舞台指令/心理活动使用方括号，例如：[低声笑]、[内心：有点紧张]。  \n"
        "- OOC 规范：当需要跳出角色进行说明或协商时使用“OOC:”前缀，不与剧情文本混写。  \n\n"
        "工具使用情景：  \n"
        "1) todo：将长剧情拆成可执行的“场景卡/线索卡”。新增关键节点用 add_task；阶段回顾用 list/report；完成节点后标记 complete/update。  \n"
        "2) bio：记录用户的长期偏好（如触发点、避雷点、喜欢的题材/节奏/人物关系），用以稳定风格。可随时 add/update；回顾时 list。  \n"
        "3) 信息取证（可选）：为增强真实感，对涉及事实的细节（地名/规章/术语）使用 tool__jina__web_search 初筛；高价值条目再用 tool__jina__fetch_markdown 抓取原文核对。  \n\n"
        "安全与边界：  \n"
        "- 严禁生成仇恨、歧视、暴力煽动、露骨色情、未成年人不当内容等；涉及违法/危险指导的请求直接拒绝并给出安全替代。  \n"
        "- 当用户请求超出安全边界时，使用简短 OOC 说明“无法协助”，并提供合规的改写或相似主题替代。  \n"
        "- 任何医疗/法律/投资等专业建议，保持叙事性的世界观表达，不给出现实中的专业指导。  \n\n"
        "互动流程建议：  \n"
        "1) 开场最小澄清：缺少设定时，用 3–5 个要点问题快速补齐（世界观、时间点、角色关系、目标/冲突、禁忌/偏好）。  \n"
        "2) 场景切入：用一句环境描写 + 一句角色态度/目标 + 一个悬念，立即进入互动。  \n"
        "3) 回合节奏：每回合推进一个冲突或线索；末尾提供选项与自由输入邀请。  \n"
        "4) 记忆与回顾：阶段性用 todo/bio 同步进度与偏好；跨回合时用 1–2 句 recap。  \n\n"
        '工具调用格式：使用 <antml:function_calls>；每个 <parameter name="commentary"> 写清：本次剧情目的/想确认的信息/与上回合的衔接。  \n\n'
        "输出风格：沉浸、克制、具象；避免一次性长篇铺陈；优先“展示”而非“解释”。  \n\n"
        "开场提问清单（缺设定时参考）：  \n"
        "- 世界观与时间点？  \n"
        "- 我们各自的人设与关系？  \n"
        "- 当前场景与共同目标/冲突？  \n"
        "- 禁忌与必须避开的元素？  \n"
        "- 期望的节奏与叙事风格？  \n\n"
        "停止条件：用户表示结束；剧情关键目标达成；或继续推进的价值明显降低。  \n"
        "若满足停止条件，输出简短结语与“可选续作/番外/支线”建议。  \n"
    )


# 系统提示词-尾
def build_system_footer(provider: str, model: str) -> str:
    """构造系统提示页尾信息，包含如何处理文档引用。"""

    think_injector = (
        ""
        if not (provider == "deepseek" and model in ["deepseek-chat"])
        else "\n\n回答前使用<think></think>对包含你的思考独白。\n\n<think>"
    )

    return (
        "\n\n"
        "# 你应该如何引用文档来使得回复可信 \n\n"
        "When responding, you need keep the following points in mind:  \n\n"
        "Where X represents the numerical index of each document. Please cite the document at the end of the relevant sentence when appropriate. Use the citation format [citation:X] in the corresponding part of your answer. If a sentence is derived from multiple documents, list all relevant citation numbers, such as [citation:3][citation:5]. Be sure not to cluster all citations at the end of the sentence; instead, include them in the corresponding parts of the answer.  \n\n"
        "- Not all content in the documents is closely related to the user's question. You need to evaluate and filter the documents based on the question.  \n"
        "- Evaluate question or task type.  \n"
        "- For listing-type questions (e.g., listing all flight information), try to limit the answer to 10 key points and inform the user that they can refer to the sources for complete information. Prioritize providing the most complete and relevant items in the list. Avoid mentioning content not provided in the documents unless necessary.  \n"
        "- For creative tasks (e.g., writing papers), You need to interpret and summarize the user's requirements, choose an appropriate format, fully utilize the documents and extract important information to generate answers that meet user requirements with intellectual depth, creativity and professionalism. Your writing should be as extensive as possible, providing multi-perspective responses for each point by anticipating the user's intent, ensuring information-rich and thorough discussions.  \n"
        "- Ensure that references are cited within the main body of the text, such as [citation:3][citation:5].   \n"
        "- If the answer is lengthy, please structure it and summarize by paragraphs. If point-by-point answers are needed, try to limit to 5 points and merge related content.  \n"
        "- For objective Q&A, if the answer is very brief, you may add one or two related sentences to enrich the content.  \n"
        "- You need to choose appropriate and aesthetically pleasing response formats based on user requirements and answer content to ensure strong readability.  \n"
        "- You cannot view images, videos, audio, or other multimedia data referenced in user-provided documents.   \n"
        "- You only focus on the literal text content in the documents provided by the user.  \n"
        "- Do not create fictional or non-existent academic sources or references in responses.  \n"
        "- Unless requested by the user, your response language should match the language of the user's question.  \n"
        "- At the end of your response, list all references cited in the main text, formatted as '[NEWLINE][citation:X]: [quote], [document id or name]'.  \n"
        f"{think_injector}"
    )


# 系统提示词-尾
def build_author_note(provider: str, model: str) -> str:
    """构造用户消息脚注。"""
    think_injector = (
        ""
        if not (provider == "deepseek" and model in ["deepseek-chat"])
        else "\n\n回答前使用<think></think>对包含你的思考独白。\n\n<think>"
    )

    return (
        "\n\n"
        "---  \n"
        "\n\n"
        "**提醒**  \n"
        "1. 回复前应回顾行为规范和角色身份  \n"
        "2. 工具调用前回顾 Tools 和 工具调用的解释性  \n"
        "3. 严格区分搜索的资料条目索引与资料正文, 对于要引用的资料条目, 必须先尝试阅读资料正文。  \n"
        "4. 基于资料回答内容前回顾 你应该如何引用文档来使得回复可信。无法找到来源时明确写“暂无来源（置信度=高/中/低）”，禁止虚构引用。  \n"
        "5. 你需要思行一致，不要行动结果脱离思考，想一套做却成了另一套，保证你的思考与行动是一致的。  \n"
        f"{think_injector}"
    )


# ===== 修改开始 =====
# ---- HTTP 全局重试补丁 ----
# 说明：
# 1. 为减少对下方各 Client 实现的侵入式修改，这里对 urllib.request.urlopen 做一次幂等可检测的轻量封装；
# 2. 支持对临时性网络波动 / 服务器瞬时错误 (429/5xx) 自动重试，避免 invoke 流程脆弱中断；
# 3. 通过环境变量可调参数：
#    - LLM_HTTP_MAX_RETRIES    (默认 3)
#    - LLM_HTTP_RETRY_BACKOFF  (指数回退基数，默认 1.6)
#    - LLM_HTTP_RETRY_JITTER   (附加随机抖动上限秒，默认 0.25)
#    - LLM_HTTP_RETRY_STATUS   (逗号分隔 HTTP 状态码，默认 429,500,502,503,504)
# 4. 仅对首次 import / 运行打补丁；设置标记 _llm_retry_patched 防止重复。
# 5. 行为：HTTPError 且状态码在重试集合 或 URLError（临时网络问题） -> 重试；否则立即抛出。
#
if not getattr(urllib.request, "_llm_retry_patched", False):
    _ORIGINAL_URLOPEN = urllib.request.urlopen  # 保存原实现

    def _parse_retry_status(default: str) -> set[int]:
        raw = os.getenv("LLM_HTTP_RETRY_STATUS", default)
        out: set[int] = set()
        for part in str(raw).split(","):
            part = part.strip()
            if not part:
                continue
            try:
                out.add(int(part))
            except Exception:
                pass
        return out or {429, 500, 502, 503, 504}

    _HTTP_RETRY_STATUS = _parse_retry_status("429,500,502,503,504")
    try:
        _HTTP_MAX_RETRIES = max(1, int(os.getenv("LLM_HTTP_MAX_RETRIES", "3")))
    except Exception:
        _HTTP_MAX_RETRIES = 3
    try:
        _HTTP_BACKOFF_BASE = float(os.getenv("LLM_HTTP_RETRY_BACKOFF", "1.6"))
        if _HTTP_BACKOFF_BASE <= 1.0:
            _HTTP_BACKOFF_BASE = 1.6
    except Exception:
        _HTTP_BACKOFF_BASE = 1.6
    try:
        _HTTP_JITTER_MAX = float(os.getenv("LLM_HTTP_RETRY_JITTER", "0.25"))
        if _HTTP_JITTER_MAX < 0:
            _HTTP_JITTER_MAX = 0.25
    except Exception:
        _HTTP_JITTER_MAX = 0.25

    def _retry_sleep(attempt: int) -> None:
        # 指数回退 + 抖动 (attempt 从 0 开始)
        delay = (_HTTP_BACKOFF_BASE**attempt) + (
            random.uniform(0, _HTTP_JITTER_MAX) if _HTTP_JITTER_MAX > 0 else 0
        )
        try:
            time.sleep(delay)
        except Exception:
            pass

    def _retrying_urlopen(url, *args, **kwargs):  # type: ignore
        # 兼容 timeout 参数透传
        for attempt in range(_HTTP_MAX_RETRIES):
            try:
                return _ORIGINAL_URLOPEN(url, *args, **kwargs)
            except urllib.error.HTTPError as he:
                code = getattr(he, "code", None)
                if (
                    isinstance(code, int)
                    and code in _HTTP_RETRY_STATUS
                    and attempt < _HTTP_MAX_RETRIES - 1
                ):
                    _retry_sleep(attempt)
                    continue
                raise
            except urllib.error.URLError as ue:
                # 常见临时网络错误：超时 / DNS / 连接重置
                if attempt < _HTTP_MAX_RETRIES - 1:
                    _retry_sleep(attempt)
                    continue
                raise
        # 理论上不会到达此处
        return _ORIGINAL_URLOPEN(url, *args, **kwargs)

    urllib.request.urlopen = _retrying_urlopen  # type: ignore[attr-defined]
    urllib.request._llm_retry_patched = True  # type: ignore[attr-defined]


class DeepSeekClient:
    """使用 urllib 的 DeepSeek Chat Completions 客户端，支持流式与非流式"""

    def __init__(self, endpoint: str = DEEPSEEK_ENDPOINT):
        self.endpoint = endpoint

    def _resolve_key(self, api_key: Optional[str]) -> str:
        key = resolve_api_key(api_key)
        if not key:
            raise RuntimeError(
                f"未找到 API Key，请通过 --api-key、环境变量 {API_KEY_ENV}，或 macOS Keychain 设置"
            )
        return key

    def _make_request(
        self, payload: Dict[str, Any], api_key: str
    ) -> urllib.request.Request:
        # 流式时尽量声明接收 event-stream
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }
        if payload.get("stream"):
            headers["Accept"] = "text/event-stream"
        data = json.dumps(payload).encode("utf-8")
        return urllib.request.Request(
            self.endpoint, method="POST", data=data, headers=headers
        )

    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "deepseek-chat",
        stream: bool = False,
        api_key: Optional[str] = None,
        timeout: int = 600,
        extra: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """非流式调用，返回完整 JSON 对象。"""
        key = self._resolve_key(api_key)
        payload: Dict[str, Any] = {
            "model": model,
            "messages": messages,
            "stream": False,
        }
        if extra:
            payload.update({k: v for k, v in extra.items() if v is not None})
        req = self._make_request(payload, key)
        try:
            with urllib.request.urlopen(req, timeout=timeout) as resp:
                body = resp.read().decode("utf-8")
                return json.loads(body)
        except urllib.error.HTTPError as he:
            err = he.read().decode("utf-8", errors="ignore")
            raise RuntimeError(f"HTTP {he.code}: {err}")
        except urllib.error.URLError as ue:
            raise RuntimeError(f"网络错误: {ue}")

    def stream_chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "deepseek-chat",
        api_key: Optional[str] = None,
        timeout: int = 600,
        extra: Optional[Dict[str, Any]] = None,
    ) -> Generator[Dict[str, Any], None, None]:
        """流式调用，返回一个生成器，逐条产出解析后的 chunk 字典。"""
        key = self._resolve_key(api_key)
        payload: Dict[str, Any] = {
            "model": model,
            "messages": messages,
            "stream": True,
        }
        if extra:
            payload.update({k: v for k, v in extra.items() if v is not None})
        req = self._make_request(payload, key)

        try:
            with urllib.request.urlopen(req, timeout=timeout) as resp:
                # 逐行读取 SSE
                for raw in resp:
                    try:
                        line = raw.decode("utf-8", errors="ignore").strip()
                    except Exception:
                        continue
                    if not line:
                        continue
                    # 忽略注释行（以冒号开头）
                    if line.startswith(":"):
                        continue
                    if not line.startswith("data:"):
                        continue
                    data_part = line[5:].strip()  # 去掉前缀 'data:'
                    if not data_part:
                        continue
                    if data_part == "[DONE]":
                        yield {"done": True}
                        break
                    try:
                        obj = json.loads(data_part)
                    except Exception:
                        # 某些实现可能一次分多行，这里简单跳过异常行
                        continue
                    yield obj
        except urllib.error.HTTPError as he:
            err = he.read().decode("utf-8", errors="ignore")
            raise RuntimeError(f"HTTP {he.code}: {err}")
        except urllib.error.URLError as ue:
            raise RuntimeError(f"网络错误: {ue}")


class ThinkTagExtractor:
    """
    增量 <think>...</think> 抽取器（改进版）：
    功能增强：
    1. 支持 <think> 标签嵌套（think_depth 计数，只有最外层闭合时输出一个 reasoning 段）；
    2. 保持“保守输出”策略：仅消费确定不会构成标签的前缀；尾部疑似标签前缀留在 pending；
    3. 过滤代码：
       - 三反引号代码块 ```...``` 内部不解析 <think>；
       - 单反引号内联代码 `...` 内部不解析（新增 in_inline 状态）；
    4. 识别跨 chunk 被拆成多段的标签（改进 safe_end 逻辑，整段仍是前缀时全部暂存）；
    5. 孤立的 </think>（深度为 0 时出现）按普通文本输出，避免误吞内容；
    6. 流结束时：若仍有未闭合的 <think>，其累积内容整体作为一个 reasoning 片段输出。
    返回：
      feed(text) -> (新增 reasoning 段列表, 新增干净正文增量)
      finish()   -> 处理剩余 pending 与未闭合标签
    兼容性：
      - self.in_think 保留（= think_depth > 0），兼容外部现有判断。
    """

    _OPEN = "<think>"
    _CLOSE = "</think>"
    _FENCE = "```"

    def __init__(self) -> None:
        self.in_code = False  # 三反引号代码块状态
        self.in_inline = False  # 单反引号内联代码状态
        self.think_depth = 0  # 嵌套深度
        self.in_think = False  # 兼容旧接口（与 think_depth 同步）
        self.think_buf: list[str] = []
        self.out_buf: list[str] = []
        self.pending: str = ""  # 可能形成标签的尾部碎片
        # 流式增量推理输出相关状态
        self._last_streamed_len: int = 0  # 当前 <think> 缓冲已向外增量推送的长度
        self._streamed_current_think: bool = (
            False  # 本轮最外层 <think> 是否已经产生过增量输出
        )

        # 预计算所有需要整体匹配的标签及其前缀集合（单反引号逐字符处理故不列入）
        self._tags = [self._OPEN, self._CLOSE, self._FENCE]
        self._max_tag_len = max(len(t) for t in self._tags)
        self._prefixes = set()
        for t in self._tags:
            for i in range(1, len(t)):
                self._prefixes.add(t[:i])

    # ---- 内部状态操作 ----
    def _enter_think(self) -> None:
        self.think_depth += 1
        self.in_think = self.think_depth > 0
        if self.think_depth == 1:
            # 进入最外层 <think>，重置流式跟踪
            self._last_streamed_len = 0
            self._streamed_current_think = False

    def _leave_think(self) -> list[str]:
        """
        处理一次 </think> 闭合。
        仅当深度从 1 -> 0 时输出一个 reasoning 段。
        返回：可能新增的 reasoning 段列表（0 或 1 个）。
        """
        if self.think_depth <= 0:
            # 异常孤立闭合，外层会把标签文本当普通内容输出
            return []
        self.think_depth -= 1
        self.in_think = self.think_depth > 0
        if self.think_depth == 0:
            seg = "".join(self.think_buf)
            self.think_buf.clear()
            # 若本段已做过增量 streaming，则不再整体重复输出
            if seg and not self._streamed_current_think:
                return [seg]
            # 复位标志（已闭合）
            self._streamed_current_think = False
        return []

    # ---- 主接口：增量喂入 ----
    def feed(self, text: str) -> tuple[list[str], str]:
        if not text:
            return [], ""
        reasoning_segments: list[str] = []

        combined = self.pending + text
        safe_end = len(combined)

        # 改进：检查 1..=max_tag_len 长度的后缀；若整段本身仍是某标签前缀则整段暂存
        for k in range(1, min(self._max_tag_len, len(combined)) + 1):
            suffix = combined[-k:]
            if suffix in self._prefixes:
                # 整段都是前缀：全部缓冲，不输出
                if k == len(combined):
                    safe_end = 0
                else:
                    safe_end = len(combined) - k
                break

        if safe_end == 0:
            process_text = ""
            self.pending = combined
        else:
            process_text = combined[:safe_end]
            self.pending = combined[safe_end:]

        i = 0
        n = len(process_text)
        while i < n:
            # 1. 处理三反引号代码块 fence
            if not self.in_inline and process_text.startswith(self._FENCE, i):
                self.in_code = not self.in_code
                self._emit(process_text[i : i + 3])
                i += 3
                continue

            ch = process_text[i]

            # 2. 单反引号（不在三反引号内才切换 inline）
            if not self.in_code and ch == "`":
                self.in_inline = not self.in_inline
                self._emit(ch)
                i += 1
                continue

            # 3. 代码块或内联代码中：全部原样
            if self.in_code or self.in_inline:
                self._emit(ch)
                i += 1
                continue

            # 4. 解析标签（仅在普通文本上下文）
            if process_text.startswith(self._OPEN, i):
                self._enter_think()
                i += len(self._OPEN)
                continue

            if process_text.startswith(self._CLOSE, i):
                if self.think_depth > 0:
                    segs = self._leave_think()
                    if segs:
                        reasoning_segments.extend(segs)
                else:
                    # 孤立闭合标签，按普通文本输出
                    self._emit(self._CLOSE)
                i += len(self._CLOSE)
                continue

            # 5. 普通字符
            if self.in_think:
                self.think_buf.append(ch)
            else:
                self.out_buf.append(ch)
            i += 1

        content_delta = "".join(self.out_buf)
        self.out_buf.clear()
        return reasoning_segments, content_delta

    def feed_streaming(self, text: str) -> tuple[list[str], str | None, str]:
        """
        流式友好版本：
        返回 (complete_segments, reasoning_delta, content_delta)
        - complete_segments: 仅当某最外层 <think> 完整闭合且期间未做过增量输出时，返回其整体内容；
                             若期间已增量输出，则闭合时不再重复返回整体，避免重复。
        - reasoning_delta: 当前仍处于 <think> 内时，本次新增的思考增量（可能为 None）
        - content_delta: 新增的正文增量
        说明：
        1. 增量模式下，外部应：
           - 若 reasoning_delta 非空：立即 on_reasoning(reasoning_delta)
           - 遍历 complete_segments：同样 on_reasoning
        2. 与 feed() 可并行存在，旧调用保持兼容。
        """
        complete_segments: list[str] = []
        reasoning_delta: str | None = None

        # 先用原逻辑解析（得到可能的完整段 & 正文增量）
        segs, content_delta = self.feed(text)
        complete_segments.extend(segs)

        # 若仍在 <think> 中，计算新增未输出部分
        if self.in_think and self.think_buf:
            cur_len = len(self.think_buf)
            if cur_len > self._last_streamed_len:
                new_part = "".join(self.think_buf[self._last_streamed_len :])
                if new_part:
                    reasoning_delta = new_part
                    self._streamed_current_think = True
                self._last_streamed_len = cur_len
        else:
            # 已离开最外层 <think>，重置游标
            self._last_streamed_len = 0

        return complete_segments, reasoning_delta, content_delta

    # ---- 结束：处理剩余 pending 与未闭合标签 ----
    def finish(self) -> tuple[list[str], str]:
        reasoning_segments: list[str] = []
        if self.pending:
            # 不再尝试解析 pending，直接根据上下文归类
            if self.in_code or self.in_inline:
                self.out_buf.append(self.pending)
            elif self.in_think:
                self.think_buf.append(self.pending)
            else:
                self.out_buf.append(self.pending)
            self.pending = ""

        if self.think_depth > 0 and self.think_buf:
            # 所有未闭合 <think> 视为一个 reasoning 段
            reasoning_segments.append("".join(self.think_buf))
            self.think_buf.clear()
            self.think_depth = 0
            self.in_think = False

        content_delta = "".join(self.out_buf)
        self.out_buf.clear()
        return reasoning_segments, content_delta

    # ---- 内部：向合适缓冲写入 ----
    def _emit(self, s: str) -> None:
        if self.in_think:
            self.think_buf.append(s)
        else:
            self.out_buf.append(s)


def invoke_deepseek(
    prompt: str,
    system_prompt: str = DEFAULT_SYSTEM_PROMPT,
    model: str = "deepseek-chat",
    stream: bool = False,
    api_key: Optional[str] = None,
    endpoint: str = DEEPSEEK_ENDPOINT,
    timeout: int = 600,
    on_delta: Optional[Callable[[str], None]] = None,
    on_reasoning: Optional[Callable[[str], None]] = None,
    return_usage: bool = False,
) -> Any:
    """调用 DeepSeek Chat Completions API。
    - 非流式：返回完整 assistant 文本；当 return_usage=True 时返回 (文本, usage)。
    - 流式：区分 reasoning_content 与 content 调用不同回调；最终返回完整 content 文本；
            当 return_usage=True 时返回 (文本, usage)；usage 通常出现在最后一个 chunk。
    参数 timeout 为请求超时时间（秒），默认 600。
    """
    if not api_key:
        api_key = resolve_api_key(api_key)
    if not api_key:
        raise RuntimeError(
            f"未找到 API Key，请通过 --api-key、环境变量 {API_KEY_ENV}，或 macOS Keychain 设置"
        )
    # 构造 system
    header = build_system_header(provider="deepseek", model=model)
    footer = build_system_footer(provider="deepseek", model=model)
    bio_md = build_user_bio_markdown()
    parts: List[str] = [header]
    if bio_md.strip():
        parts.append("")
        parts.append(bio_md)
    parts.extend(["", system_prompt])
    parts.extend(["", footer])
    system_with_header_footer = "\n".join(parts)

    messages = [
        {"role": "system", "content": system_with_header_footer},
        {
            "role": "user",
            "content": prompt + build_author_note(provider="deepseek", model=model),
        },
    ]

    client = DeepSeekClient(endpoint=endpoint)

    if not stream:
        obj = client.chat_completion(
            messages=messages, model=model, api_key=api_key, timeout=timeout
        )
        usage: Dict[str, Any] = {}
        try:
            usage = obj.get("usage") or {}
        except Exception:
            usage = {}
        try:
            choices = obj.get("choices") or []
            if not choices:
                clean_ret = json.dumps(obj, ensure_ascii=False)
                return (clean_ret, usage) if return_usage else clean_ret
            msg = choices[0].get("message") or {}
            content = msg.get("content")
            content_str = (
                content
                if isinstance(content, str)
                else json.dumps(msg, ensure_ascii=False)
            )
            # 使用 ThinkTagExtractor 解析非流式结果里的 <think> 思考，剥离后返回纯正文
            extractor = ThinkTagExtractor()
            reasoning_segments, clean_part = extractor.feed(content_str or "")
            tail_reasoning, tail_clean = extractor.finish()
            all_reasoning = reasoning_segments + tail_reasoning
            clean_content = clean_part + tail_clean
            if all_reasoning and on_reasoning:
                for seg in all_reasoning:
                    if seg:
                        on_reasoning(seg)
            return (clean_content, usage) if return_usage else clean_content
        except Exception:
            fallback = json.dumps(obj, ensure_ascii=False)
            return (fallback, usage) if return_usage else fallback

    # 流式模式
    collected: List[str] = []
    collected_reasoning: List[str] = []
    usage = {}
    extractor = ThinkTagExtractor()

    for chunk in client.stream_chat_completion(
        messages=messages, model=model, api_key=api_key, timeout=timeout
    ):

        # 部分实现会将 usage 置于最后一个 chunk（或与空 content 同时出现）
        if isinstance(chunk, dict):
            if "usage" in chunk and chunk.get("usage"):
                try:
                    usage = chunk.get("usage") or usage
                except Exception:
                    pass

        if chunk.get("done"):
            break
        try:
            choices = chunk.get("choices") or []
            if not choices:
                continue
            delta = choices[0].get("delta") or {}
            # reasoning_content 与 content 分别处理
            reasoning_piece = delta.get("reasoning_content") or ""
            if reasoning_piece:
                collected_reasoning.append(reasoning_piece)
                if on_reasoning:
                    on_reasoning(reasoning_piece)
            piece = delta.get("content") or ""
            if piece:
                # 使用 ThinkTagExtractor 抽取放错到 content 中的 <think> 思考
                reasoning_segments, clean_content = extractor.feed(piece)
                if reasoning_segments:
                    for seg in reasoning_segments:
                        if seg:
                            collected_reasoning.append(seg)
                            if on_reasoning:
                                on_reasoning(seg)
                if clean_content:
                    collected.append(clean_content)
                    if on_delta:
                        on_delta(clean_content)
        except Exception:
            continue
    text = "".join(collected)
    return (text, usage) if return_usage else text


class MoonshotClient:
    """Moonshot(Kimi) Chat Completions 客户端，接口与 DeepSeekClient 保持一致。"""

    def __init__(self, endpoint: str = MOONSHOT_ENDPOINT):
        self.endpoint = endpoint

    def _resolve_key(self, api_key: Optional[str]) -> str:
        key = resolve_moonshot_key(api_key)
        if not key:
            raise RuntimeError(
                f"未找到 Moonshot API Key，请通过 --api-key、环境变量 {MOONSHOT_API_KEY_ENV} 或 macOS Keychain 设置"
            )
        return key

    def _make_request(
        self, payload: Dict[str, Any], api_key: str
    ) -> urllib.request.Request:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }
        if payload.get("stream"):
            headers["Accept"] = "text/event-stream"
        data = json.dumps(payload).encode("utf-8")
        return urllib.request.Request(
            self.endpoint, method="POST", data=data, headers=headers
        )

    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "kimi-k2-turbo-preview",
        stream: bool = False,
        api_key: Optional[str] = None,
        timeout: int = 600,
        extra: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        key = self._resolve_key(api_key)
        payload: Dict[str, Any] = {
            "model": model,
            "messages": messages,
            "stream": False,
            "max_tokens": 32000,
        }
        if extra:
            payload.update({k: v for k, v in extra.items() if v is not None})
        req = self._make_request(payload, key)
        try:
            with urllib.request.urlopen(req, timeout=timeout) as resp:
                return json.loads(resp.read().decode("utf-8"))
        except urllib.error.HTTPError as he:
            err = he.read().decode("utf-8", errors="ignore")
            raise RuntimeError(f"HTTP {he.code}: {err}")
        except urllib.error.URLError as ue:
            raise RuntimeError(f"网络错误: {ue}")

    def stream_chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str = "kimi-k2-turbo-preview",
        api_key: Optional[str] = None,
        timeout: int = 600,
        extra: Optional[Dict[str, Any]] = None,
    ) -> Generator[Dict[str, Any], None, None]:
        key = self._resolve_key(api_key)
        payload: Dict[str, Any] = {
            "model": model,
            "messages": messages,
            "stream": True,
            "max_tokens": 32000,
        }
        if extra:
            payload.update({k: v for k, v in extra.items() if v is not None})
        req = self._make_request(payload, key)
        try:
            with urllib.request.urlopen(req, timeout=timeout) as resp:
                for raw in resp:
                    try:
                        line = raw.decode("utf-8", errors="ignore").strip()
                    except Exception:
                        continue
                    if not line or line.startswith(":") or not line.startswith("data:"):
                        continue
                    data_part = line[5:].strip()
                    if not data_part:
                        continue
                    if data_part == "[DONE]":
                        yield {"done": True}
                        break
                    try:
                        obj = json.loads(data_part)
                    except Exception:
                        continue
                    yield obj
        except urllib.error.HTTPError as he:
            err = he.read().decode("utf-8", errors="ignore")
            raise RuntimeError(f"HTTP {he.code}: {err}")
        except urllib.error.URLError as ue:
            raise RuntimeError(f"网络错误: {ue}")


def invoke_moonshot(
    prompt: str,
    system_prompt: str = MOONSHOT_DEFAULT_SYSTEM_PROMPT,
    model: str = "kimi-k2-turbo-preview",
    stream: bool = False,
    api_key: Optional[str] = None,
    endpoint: str = MOONSHOT_ENDPOINT,
    timeout: int = 600,
    on_delta: Optional[Callable[[str], None]] = None,
    on_reasoning: Optional[Callable[[str], None]] = None,
    return_usage: bool = False,
) -> Any:
    """调用 Moonshot(Kimi) Chat Completions API（接口风格与 invoke_deepseek 一致）。"""
    if not api_key:
        api_key = resolve_moonshot_key(api_key)
    if not api_key:
        raise RuntimeError(
            f"未找到 Moonshot API Key，请通过 --api-key、环境变量 {MOONSHOT_API_KEY_ENV}，或 macOS Keychain 设置"
        )

    # 构造 system
    header = build_system_header(provider="moonshot", model=model)
    footer = build_system_footer(provider="moonshot", model=model)
    bio_md = build_user_bio_markdown()
    parts: List[str] = [header]
    if bio_md.strip():
        parts.append("")
        parts.append(bio_md)
    parts.extend(["", system_prompt])
    parts.extend(["", footer])
    system_with_header_footer = "\n".join(parts)

    messages = [
        {"role": "system", "content": system_with_header_footer},
        {
            "role": "user",
            "content": prompt + build_author_note(provider="moonshot", model=model),
        },
    ]

    client = MoonshotClient(endpoint=endpoint)

    if not stream:
        obj = client.chat_completion(
            messages=messages, model=model, api_key=api_key, timeout=timeout
        )
        usage: Dict[str, Any] = {}
        try:
            usage = obj.get("usage") or {}
        except Exception:
            usage = {}
        try:
            choices = obj.get("choices") or []
            if not choices:
                return (
                    (json.dumps(obj, ensure_ascii=False), usage)
                    if return_usage
                    else json.dumps(obj, ensure_ascii=False)
                )
            msg = choices[0].get("message") or {}
            content = msg.get("content")
            content_str = (
                content
                if isinstance(content, str)
                else json.dumps(msg, ensure_ascii=False)
            )
            return (content_str, usage) if return_usage else content_str
        except Exception:
            return (
                (json.dumps(obj, ensure_ascii=False), usage)
                if return_usage
                else json.dumps(obj, ensure_ascii=False)
            )

    collected: List[str] = []
    collected_reasoning: List[str] = []
    usage = {}
    for chunk in client.stream_chat_completion(
        messages=messages, model=model, api_key=api_key, timeout=timeout
    ):
        if isinstance(chunk, dict):
            if "usage" in chunk and chunk.get("usage"):
                try:
                    usage = chunk.get("usage") or usage
                except Exception:
                    pass
        if chunk.get("done"):
            break
        try:
            choices = chunk.get("choices") or []
            if not choices:
                continue
            delta = choices[0].get("delta") or {}
            reasoning_piece = delta.get("reasoning_content") or ""
            if reasoning_piece:
                collected_reasoning.append(reasoning_piece)
                if on_reasoning:
                    on_reasoning(reasoning_piece)
            piece = delta.get("content") or ""
            if piece:
                collected.append(piece)
                if on_delta:
                    on_delta(piece)
        except Exception:
            continue
    text = "".join(collected)
    return (text, usage) if return_usage else text


class OpenRouterClient:
    """OpenRouter Chat Completions 客户端，支持流式与非流式
    与 DeepSeekClient/MoonshotClient 保持相似接口。
    - 支持根据不同模型自动填充 reasoning / thinking 相关参数
    """

    DEFAULT_ENDPOINT = "https://openrouter.ai/api/v1/chat/completions"

    # 针对不同模型的“思考 / reasoning”参数模板
    # 可按需扩展；若调用时 extra 显式提供对应字段则会覆盖
    MODEL_REASONING_PARAMS: Dict[str, Dict[str, Any]] = {
        # OpenAI 推理/新系列（示例）
        "openai/gpt-5-mini": {"reasoning": {"effort": "medium"}},
        "openai/gpt-oss-120b": {"reasoning": {"effort": "medium"}},
        # DeepSeek R1 (示例：假设可配置思考 token 预算，如后续文档不同请自行调整)
        "deepseek/deepseek-r1-0528": {
            "thinking": {"type": "enabled", "budget_tokens": 2048}
        },
        # 其他可能支持 reasoning 的模型可在此添加
    }

    def __init__(self, endpoint: str = DEFAULT_ENDPOINT):
        self.endpoint = endpoint

    def _resolve_key(self, api_key: Optional[str]) -> str:
        # 使用统一的 resolve_openrouter_key（支持显式参数 / 环境变量 / Keychain）
        key = resolve_openrouter_key(api_key)
        if not key:
            raise RuntimeError(
                f"未找到 OpenRouter API Key，请通过 --api-key、环境变量 {OPENROUTER_API_KEY_ENV} 或 macOS Keychain 设置"
            )
        return key

    def _make_request(
        self, payload: Dict[str, Any], api_key: str, stream: bool
    ) -> urllib.request.Request:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}",
        }
        # OpenRouter 建议可加：Referer / X-Title（可选）
        referer = os.environ.get("OPENROUTER_HTTP_REFERER")
        app_title = os.environ.get("OPENROUTER_APP_TITLE")
        if referer:
            headers["HTTP-Referer"] = referer
        if app_title:
            headers["X-Title"] = app_title
        if stream:
            headers["Accept"] = "text/event-stream"
        data = json.dumps(payload).encode("utf-8")
        return urllib.request.Request(
            self.endpoint, method="POST", data=data, headers=headers
        )

    def _inject_model_reasoning(self, model: str, base: Dict[str, Any]) -> None:
        # 若调用方未在 base 中显式提供同名字段，则注入默认模板
        tmpl = self.MODEL_REASONING_PARAMS.get(model)
        if not tmpl:
            return
        for k, v in tmpl.items():
            if k not in base:
                base[k] = v

    def chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str,
        api_key: Optional[str] = None,
        timeout: int = 600,
        extra: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        key = self._resolve_key(api_key)
        payload: Dict[str, Any] = {
            "model": model,
            "messages": messages,
            "stream": False,
        }
        if extra:
            payload.update({k: v for k, v in extra.items() if v is not None})
        # 根据模型自动补充 reasoning / thinking
        self._inject_model_reasoning(model, payload)
        req = self._make_request(payload, key, stream=False)
        try:
            with urllib.request.urlopen(req, timeout=timeout) as resp:
                return json.loads(resp.read().decode("utf-8"))
        except urllib.error.HTTPError as he:
            err = he.read().decode("utf-8", errors="ignore")
            raise RuntimeError(f"HTTP {he.code}: {err}")
        except urllib.error.URLError as ue:
            raise RuntimeError(f"网络错误: {ue}")

    def stream_chat_completion(
        self,
        messages: List[Dict[str, str]],
        model: str,
        api_key: Optional[str] = None,
        timeout: int = 600,
        extra: Optional[Dict[str, Any]] = None,
    ) -> Generator[Dict[str, Any], None, None]:
        key = self._resolve_key(api_key)
        payload: Dict[str, Any] = {
            "model": model,
            "messages": messages,
            "stream": True,
        }
        if extra:
            payload.update({k: v for k, v in extra.items() if v is not None})
        self._inject_model_reasoning(model, payload)
        req = self._make_request(payload, key, stream=True)
        try:
            with urllib.request.urlopen(req, timeout=timeout) as resp:
                for raw in resp:
                    try:
                        line = raw.decode("utf-8", errors="ignore").strip()
                    except Exception:
                        continue
                    if not line:
                        continue
                    # 忽略以冒号开头的 OpenRouter 处理状态行
                    if line.startswith(":"):
                        continue
                    if not line.startswith("data:"):
                        continue
                    data_part = line[5:].strip()
                    if not data_part:
                        continue
                    if data_part == "[DONE]":
                        yield {"done": True}
                        break
                    try:
                        obj = json.loads(data_part)
                    except Exception:
                        continue
                    yield obj
        except urllib.error.HTTPError as he:
            err = he.read().decode("utf-8", errors="ignore")
            raise RuntimeError(f"HTTP {he.code}: {err}")
        except urllib.error.URLError as ue:
            raise RuntimeError(f"网络错误: {ue}")


def invoke_openrouter(
    prompt: str,
    model: str = "openai/gpt-5-mini",
    system_prompt: str = "You are a helpful assistant.",
    stream: bool = False,
    api_key: Optional[str] = None,
    endpoint: str = OpenRouterClient.DEFAULT_ENDPOINT,
    timeout: int = 600,
    on_delta: Optional[Callable[[str], None]] = None,
    on_reasoning: Optional[Callable[[str], None]] = None,
    on_reasoning_end: Optional[Callable[[], None]] = None,
    return_usage: bool = False,
    extra: Optional[Dict[str, Any]] = None,
) -> Any:
    """调用 OpenRouter Chat Completions。
    - reasoning（推理/思考）片段来自 delta.reasoning
    - 普通内容来自 delta.content
    - usage 通常出现在最后一个 chunk
    extra 可传入自定义 reasoning/ thinking 字段覆盖默认映射
    """
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt},
    ]
    # 统一使用 resolve_openrouter_key 解析（保持与其他 provider 一致的错误提示和 Keychain 支持）
    if not api_key:
        api_key = resolve_openrouter_key(None)
    if not api_key:
        raise RuntimeError(
            f"未找到 OpenRouter API Key，请通过 --api-key、环境变量 {OPENROUTER_API_KEY_ENV} 或 macOS Keychain 设置"
        )
    client = OpenRouterClient(endpoint=endpoint)

    if not stream:
        obj = client.chat_completion(
            messages=messages,
            model=model,
            api_key=api_key,
            timeout=timeout,
            extra=extra,
        )
        usage: Dict[str, Any] = {}
        try:
            usage = obj.get("usage") or {}
        except Exception:
            pass
        try:
            choices = obj.get("choices") or []
            if not choices:
                return (
                    (json.dumps(obj, ensure_ascii=False), usage)
                    if return_usage
                    else json.dumps(obj, ensure_ascii=False)
                )
            msg = choices[0].get("message") or {}
            content = msg.get("content") or ""
            return (content, usage) if return_usage else content
        except Exception:
            return (
                (json.dumps(obj, ensure_ascii=False), usage)
                if return_usage
                else json.dumps(obj, ensure_ascii=False)
            )

    collected_content: List[str] = []
    collected_reasoning: List[str] = []
    usage: Dict[str, Any] = {}
    reasoning_active = False
    reasoning_closed = False

    for chunk in client.stream_chat_completion(
        messages=messages, model=model, api_key=api_key, timeout=timeout, extra=extra
    ):
        if isinstance(chunk, dict):
            if "usage" in chunk and chunk.get("usage"):
                try:
                    usage = chunk.get("usage") or usage
                except Exception:
                    pass

        if chunk.get("done"):
            break

        try:
            choices = chunk.get("choices") or []
            if not choices:
                continue
            delta = choices[0].get("delta") or {}

            # OpenRouter reasoning 字段
            reasoning_piece = delta.get("reasoning") or ""
            if reasoning_piece:
                reasoning_active = True
                collected_reasoning.append(reasoning_piece)
                if on_reasoning:
                    on_reasoning(reasoning_piece)

            content_piece = delta.get("content") or ""
            if content_piece:
                if reasoning_active and not reasoning_closed:
                    if on_reasoning_end:
                        on_reasoning_end()
                    reasoning_closed = True
                collected_content.append(content_piece)
                if on_delta:
                    on_delta(content_piece)
        except Exception:
            continue

    if reasoning_active and not reasoning_closed and on_reasoning_end:
        on_reasoning_end()

    text = "".join(collected_content)
    return (text, usage) if return_usage else text


def invoke_chat(
    messages: List[Dict[str, str]],
    model: str = "deepseek-chat",
    provider: str = "deepseek",
    stream: bool = False,
    api_key: Optional[str] = None,
    endpoint: str = DEEPSEEK_ENDPOINT,
    timeout: int = 600,
    on_delta: Optional[Callable[[str], None]] = None,
    on_reasoning: Optional[Callable[[str], None]] = None,
    on_reasoning_end: Optional[Callable[[], None]] = None,
    return_usage: bool = False,
) -> Any:
    """以 messages 形式调用 DeepSeek Chat API。
    - 非流式：返回字符串或 (字符串, usage)
    - 流式：区分 reasoning_content 与 content 调用不同回调；最终返回完整字符串；
            若 return_usage=True，则返回 (字符串, usage)，usage 通常在最后一个 chunk。
    参数 timeout 为请求超时时间（秒），默认 600。
    当 return_usage=True 时，返回 (content, usage_dict)
    """
    if not api_key:
        # 新增 openrouter 分支
        if provider == "moonshot":
            api_key = resolve_moonshot_key(None)
        elif provider == "openrouter":
            api_key = resolve_openrouter_key(None)
        else:
            api_key = resolve_api_key(None)
    if not api_key:
        if provider == "moonshot":
            missing_env = MOONSHOT_API_KEY_ENV
        elif provider == "openrouter":
            missing_env = OPENROUTER_API_KEY_ENV
        else:
            missing_env = API_KEY_ENV
        raise RuntimeError(
            f"未找到 API Key，请通过 --api-key、环境变量 {missing_env}，或 macOS Keychain 设置"
        )

    # 根据 provider 选择对应 Client
    if provider == "moonshot":
        client = MoonshotClient(endpoint=MOONSHOT_ENDPOINT)
    elif provider == "openrouter":
        client = OpenRouterClient(endpoint=OPENROUTER_ENDPOINT)
    else:
        client = DeepSeekClient(endpoint=endpoint)

    if not stream:
        obj = client.chat_completion(
            messages=messages, model=model, api_key=api_key, timeout=timeout
        )
        usage: Dict[str, Any] = {}
        try:
            usage = obj.get("usage") or {}
        except Exception:
            usage = {}
        try:
            choices = obj.get("choices") or []
            if not choices:
                return (
                    (json.dumps(obj, ensure_ascii=False), usage)
                    if return_usage
                    else json.dumps(obj, ensure_ascii=False)
                )
            msg = choices[0].get("message") or {}
            content = msg.get("content")
            content_str = (
                content
                if isinstance(content, str)
                else json.dumps(msg, ensure_ascii=False)
            )
            return (content_str, usage) if return_usage else content_str
        except Exception:
            return (
                (json.dumps(obj, ensure_ascii=False), usage)
                if return_usage
                else json.dumps(obj, ensure_ascii=False)
            )

    # 流式模式
    collected: List[str] = []
    collected_reasoning: List[str] = []
    usage = {}
    has_reasoning = False
    reasoning_ended = False

    extractor = ThinkTagExtractor() if provider == "deepseek" else None

    for chunk in client.stream_chat_completion(
        messages=messages, model=model, api_key=api_key, timeout=timeout
    ):
        # 部分实现会将 usage 置于最后一个 chunk（或与空 content 同时出现）
        if isinstance(chunk, dict):
            if "usage" in chunk and chunk.get("usage"):
                try:
                    usage = chunk.get("usage") or usage
                except Exception:
                    pass

        if chunk.get("done"):
            break
        try:
            choices = chunk.get("choices") or []
            if not choices:
                continue
            delta = choices[0].get("delta") or {}
            # reasoning 字段差异：
            # - deepseek/moonshot: reasoning_content
            # - openrouter: reasoning
            reasoning_piece = (
                delta.get("reasoning_content")
                if provider != "openrouter"
                else delta.get("reasoning")
            ) or ""
            if reasoning_piece:
                collected_reasoning.append(reasoning_piece)
                if on_reasoning:
                    on_reasoning(reasoning_piece)
                has_reasoning = True
            # 处理 content，兼容 DeepSeek 把 <think> 思考混入 content（包含被拆分成多段的部分）
            raw_piece = delta.get("content") or ""
            if raw_piece:
                if extractor:
                    # 使用流式增强版本，支持在 <think> 未闭合时增量输出推理
                    complete_segments, reasoning_delta, clean_content = (
                        extractor.feed_streaming(raw_piece)
                    )
                    # 增量推理片段
                    if reasoning_delta:
                        collected_reasoning.append(reasoning_delta)
                        if on_reasoning:
                            on_reasoning(reasoning_delta)
                        has_reasoning = True
                    # 完整闭合段（未做过增量时）
                    if complete_segments:
                        for seg in complete_segments:
                            if seg:
                                collected_reasoning.append(seg)
                                if on_reasoning:
                                    on_reasoning(seg)
                                has_reasoning = True
                else:
                    clean_content = raw_piece
                if clean_content:
                    # 第一次从 reasoning 切换到正文时触发结束回调
                    if has_reasoning and not reasoning_ended:
                        if on_reasoning_end:
                            on_reasoning_end()
                        reasoning_ended = True
                    collected.append(clean_content)
                    if on_delta:
                        on_delta(clean_content)
        except Exception:
            continue

    # 如果只有 reasoning 没有 content，也要调用结束回调
    # 冲洗（flush）剩余 pending，处理末尾被拆分但最终完整的 <think> 片段或未闭合残留
    if extractor:
        tail_reasoning, tail_clean = extractor.finish()
        if tail_reasoning:
            for seg in tail_reasoning:
                if seg:
                    collected_reasoning.append(seg)
                    if on_reasoning:
                        on_reasoning(seg)
                    has_reasoning = True
        if tail_clean:
            if has_reasoning and not reasoning_ended:
                if on_reasoning_end:
                    on_reasoning_end()
                reasoning_ended = True
            collected.append(tail_clean)
            if on_delta:
                on_delta(tail_clean)
    # 若 flush 后仍未触发正文且存在 reasoning，需要显式结束 reasoning
    if has_reasoning and not reasoning_ended and on_reasoning_end:
        on_reasoning_end()

    text = "".join(collected)
    return (text, usage) if return_usage else text


#
# endregion 8 DeepSeek / Moonshot Clients + Invoke Wrappers
#############################


#############################
# region 9 Jina Search & Fetch
#
def _random_user_agent() -> str:
    """随机返回常见桌面浏览器（Safari/Firefox）的 User-Agent。"""
    safari = (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.5 Safari/605.1.15"
    )
    firefox = (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:128.0) "
        "Gecko/20100101 Firefox/128.0"
    )
    return random.choice([safari, firefox])


def build_jina_headers(
    api_key: str,
    accept: str = "*/*",
    respond_with: Optional[str] = None,
    return_format: Optional[str] = None,
) -> Dict[str, str]:
    """构造 Jina 请求所需的公共请求头，随机浏览器 UA，可配置 Accept/X-Respond-With/X-Return-Format。"""
    headers: Dict[str, str] = {
        "Authorization": f"Bearer {api_key}",
        "User-Agent": _random_user_agent(),
        "Accept": accept,
    }
    if respond_with:
        headers["X-Respond-With"] = respond_with
    if return_format:
        headers["X-Return-Format"] = return_format
    return headers


def perform_jina_search(
    query: str,
    no_content: bool = True,
    api_key: Optional[str] = None,
    endpoint: str = JINA_SEARCH_ENDPOINT,
    timeout: int = 30,
) -> str:
    """调用 Jina Search API 进行网页搜索，返回精简结果文本。
    - 默认通过请求头 X-Respond-With: no-content 只返回摘要条目。
    - 需要 JINA_API_KEY 或 macOS Keychain (service=todo_yaml_jina)。
    """
    key = resolve_jina_key(api_key)
    if not key:
        raise RuntimeError(
            f"未找到 Jina API Key，请设置环境变量 {JINA_API_KEY_ENV} 或在 macOS Keychain 中保存（服务名 {JINA_KEYCHAIN_SERVICE}）。"
        )
    q = urllib.parse.quote_plus(query)
    url = endpoint.rstrip("/") + f"/?q={q}"
    headers = build_jina_headers(
        api_key=key,
        accept="*/*",
        respond_with=("no-content" if no_content else None),
    )
    req = urllib.request.Request(url, method="GET", headers=headers)
    try:
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            body = resp.read().decode("utf-8")
            return body
    except urllib.error.HTTPError as he:
        err = he.read().decode("utf-8", errors="ignore")
        raise RuntimeError(f"HTTP {he.code}: {err}")
    except urllib.error.URLError as ue:
        raise RuntimeError(f"网络错误: {ue}")


def perform_jina_fetch_markdown(
    url: str,
    api_key: Optional[str] = None,
    endpoint: str = JINA_READER_ENDPOINT,
    timeout: int = 60,
    token_budget: int = 16_000,
) -> str:
    """通过 Jina Reader 获取网页内容并返回 Markdown。
    - 使用 Accept: text/event-stream, X-Respond-With: readerlm-v2, X-Return-Format: markdown
    - url 可传入完整链接或主机名（未带协议时默认加 https://）
    """
    key = resolve_jina_key(api_key)
    if not key:
        raise RuntimeError(
            f"未找到 Jina API Key，请设置环境变量 {JINA_API_KEY_ENV} 或在 macOS Keychain 中保存（服务名 {JINA_KEYCHAIN_SERVICE}）。"
        )
    target = url.strip()
    if not (target.startswith("http://") or target.startswith("https://")):
        target = "https://" + target
    full = endpoint.rstrip("/") + "/" + target
    headers = build_jina_headers(
        api_key=key,
        # respond_with="readerlm-v2",
        return_format="markdown",
    )
    # headers["X-Engine"] = "cf-browser-rendering"
    headers["X-Token-Budget"] = str(
        token_budget if token_budget < 32_000 else 32_000
    )  # 限制每个页面的上限
    req = urllib.request.Request(full, method="GET", headers=headers)
    try:
        with urllib.request.urlopen(req, timeout=timeout) as resp:
            body = resp.read().decode("utf-8", errors="replace")
            clean_body = f"url: {url}\ncontent:\n{body}"
            return clean_body
    except urllib.error.HTTPError as he:
        err = he.read().decode("utf-8", errors="ignore")
        raise RuntimeError(
            f"HTTP {he.code}: {err}, The maximum budget limit is 32000, you can adjust it as needed."
        )
    except urllib.error.URLError as ue:
        raise RuntimeError(f"网络错误: {ue}")


#
# endregion 9 Jina Search & Fetch
#############################


#############################
# region 10 Task CRUD & Reports
#
def safe_load_all(path: Path) -> List[Dict[str, Any]]:
    if not path.exists():
        return []
    text = path.read_text(encoding="utf-8")
    try:
        docs = list(yaml.safe_load_all(text))
        # filter out None docs (possible from leading/trailing ---)
        return [normalize_doc(d) for d in docs if d]
    except Exception:
        # 容错：无法解析整个文件时，尝试按 '---' 分割并解析能解析的段
        parts: List[Dict[str, Any]] = []
        for part in text.split("---"):
            part = part.strip()
            if not part:
                continue
            try:
                d = yaml.safe_load(part)
                if d:
                    parts.append(d)
            except Exception:
                # 将无法解析的段当成原始日志保留为单字段
                parts.append({"date": None, "raw": part})
        return [normalize_doc(p) for p in parts]


def write_all(docs: List[Dict[str, Any]]) -> None:
    content = ""
    for d in docs:
        content += "---\n"
        content += yaml.safe_dump(d, sort_keys=False, allow_unicode=True)
    # 备份
    if FILE.exists():
        FILE.replace(BACKUP)
    if portalocker:
        with portalocker.Lock(str(FILE), "w", timeout=2) as fh:
            fh.write(content)
    else:
        FILE.write_text(content, encoding="utf-8")


def find_doc(docs: List[Dict[str, Any]], date_str: str) -> Optional[Dict[str, Any]]:
    for d in docs:
        if d.get("date") == date_str:
            return d
    return None


def add_task(
    title: str,
    time: Optional[str] = None,
    project: Optional[str] = None,
    tags: Optional[List[str]] = None,
    notes: Optional[str] = None,
) -> None:
    docs = safe_load_all(FILE)
    today = datetime.date.today().isoformat()
    doc = find_doc(docs, today)
    if doc is None:
        doc = {"date": today, "tasks": []}
        docs.insert(0, doc)
    if "tasks" not in doc or not isinstance(doc["tasks"], list):
        doc["tasks"] = []
    task = {
        "id": gen_id(),
        "time": time,
        "title": title,
        "notes": notes or "",
        "status": "todo",
        "project": project,
        "tags": tags or [],
    }
    doc["tasks"].append(task)
    write_all(docs)
    print(task["id"])


def list_tasks_for_date(date_str: str) -> None:
    """
    列出指定日期或日期范围内的任务。
    支持：
      - 单日：YYYY-MM-DD
      - 范围：YYYY-MM-DD..YYYY-MM-DD （顺序可乱，含端点）
    """
    if ".." in date_str:
        start_raw, end_raw = date_str.split("..", 1)
        start_raw, end_raw = start_raw.strip(), end_raw.strip()
        if not start_raw or not end_raw:
            print("Invalid range format, expected YYYY-MM-DD..YYYY-MM-DD")
            return
        try:
            start = datetime.date.fromisoformat(start_raw)
            end = datetime.date.fromisoformat(end_raw)
        except Exception:
            print("Invalid ISO date in range")
            return
        if start > end:
            start, end = end, start
        docs = safe_load_all(FILE)
        any_printed = False
        for d in docs:
            d_date = d.get("date")
            if not d_date:
                continue
            try:
                dd = datetime.date.fromisoformat(d_date)
            except Exception:
                continue
            if start <= dd <= end:
                if not any_printed:
                    # first header no extra blank
                    pass
                any_printed = True
                print(f"=== {d_date} ===")
                for t in d.get("tasks", []):
                    print(
                        f"[{t.get('status')}] {t.get('time') or '--'} {t.get('id')} {t.get('title')}"
                    )
                print()
        if not any_printed:
            print(f"No documents in range {start.isoformat()}..{end.isoformat()}")
        return
    # 单日
    docs = safe_load_all(FILE)
    doc = find_doc(docs, date_str)
    if not doc:
        print(f"No document for date {date_str}")
        return
    for t in doc.get("tasks", []):
        print(
            f"[{t.get('status')}] {t.get('time') or '--'} {t.get('id')} {t.get('title')}"
        )


def list_all() -> None:
    docs = safe_load_all(FILE)
    for d in docs:
        date = d.get("date") or "<raw>"
        print(f"=== {date} ===")
        for t in d.get("tasks", []):
            print(
                f"[{t.get('status')}] {t.get('time') or '--'} {t.get('id')} {t.get('title')}"
            )
        print()


def search(query: str) -> None:
    docs = safe_load_all(FILE)
    found = 0
    for d in docs:
        date = d.get("date")
        for t in d.get("tasks", []):
            txt = " ".join(filter(None, [t.get("title", ""), t.get("notes", "")]))
            if (
                query.lower() in txt.lower()
                or query.lower() in " ".join(t.get("tags", [])).lower()
            ):
                found += 1
                print(f"{date} [{t.get('status')}] {t.get('id')} {t.get('title')}")
    if found == 0:
        print("No matches")


def complete(task_id: str, note_append: Optional[str] = None) -> None:
    docs = safe_load_all(FILE)
    changed = False
    for d in docs:
        for t in d.get("tasks", []):
            if t.get("id") == task_id:
                t["status"] = "done"
                if note_append:
                    # append to notes with timestamp
                    stamp = datetime.datetime.now().isoformat()
                    prev = t.get("notes", "")
                    t["notes"] = (
                        prev + "\n" if prev else ""
                    ) + f"[{stamp}] {note_append}"
                changed = True
                break
        if changed:
            break
    if changed:
        write_all(docs)
        print("Marked done:", task_id)
    else:
        print("Task id not found")


def update_task(
    task_id: str,
    title: Optional[str] = None,
    time: Optional[str] = None,
    status: Optional[str] = None,
    project: Optional[str] = None,
    tags: Optional[List[str]] = None,
    notes: Optional[str] = None,
    note_append: Optional[str] = None,
) -> None:
    """Update fields of a task by id. Valid status values: todo, in-progress, waiting, done."""
    docs = safe_load_all(FILE)
    for d in docs:
        for t in d.get("tasks", []):
            if t.get("id") == task_id:
                if title is not None:
                    t["title"] = str(title)
                if time is not None:
                    t["time"] = time
                if status is not None:
                    if status not in STATUS_VALUES:
                        raise ValueError(
                            f"invalid status: {status}; allowed: {', '.join(STATUS_VALUES)}"
                        )
                    t["status"] = status
                if project is not None:
                    t["project"] = project
                if tags is not None:
                    if not isinstance(tags, list):
                        tags = [str(tags)]
                    t["tags"] = [s for s in (tags or []) if str(s).strip()]
                if notes is not None:
                    t["notes"] = notes
                if note_append:
                    stamp = datetime.datetime.now().isoformat()
                    prev = t.get("notes", "")
                    t["notes"] = (
                        prev + "\n" if prev else ""
                    ) + f"[{stamp}] {note_append}"
                write_all(docs)
                print("Updated:", task_id)
                return
    print("Task id not found")


def show_task(task_id: str) -> None:
    """显示指定任务 ID 的详细信息（日期 / 基本字段 / 标签 / 备注）。
    用途：快速查看单条任务的完整内容。
    """
    docs = safe_load_all(FILE)
    for d in docs:
        date = d.get("date")
        for t in d.get("tasks", []):
            if t.get("id") == task_id:
                print(f"Date: {date}")
                print(f"ID: {t.get('id')}")
                print(f"Title: {t.get('title')}")
                print(f"Time: {t.get('time') or '--'}")
                print(f"Status: {t.get('status')}")
                print(f"Project: {t.get('project') or '--'}")
                tags = t.get("tags") or []
                if not isinstance(tags, list):
                    tags = [str(tags)]
                print(
                    "Tags:", ", ".join([str(x) for x in tags if str(x).strip()]) or "--"
                )
                notes = t.get("notes") or ""
                if notes.strip():
                    print("Notes:\n" + notes)
                else:
                    print("Notes: --")
                return
    print("Task id not found")


def delete_task(task_id: str) -> None:
    """Delete a task by id"""
    docs = safe_load_all(FILE)
    for d in docs:
        tasks = d.get("tasks", [])
        for i, t in enumerate(list(tasks)):
            if t.get("id") == task_id:
                del tasks[i]
                write_all(docs)
                print("Deleted:", task_id)
                return
    print("Task id not found")


def export_csv(out_path: str) -> None:
    docs = safe_load_all(FILE)
    rows: List[Dict[str, Any]] = []
    for d in docs:
        date = d.get("date")
        for t in d.get("tasks", []):
            rows.append(
                {
                    "date": date,
                    "id": t.get("id"),
                    "time": t.get("time"),
                    "title": t.get("title"),
                    "status": t.get("status"),
                    "project": t.get("project"),
                    "tags": ",".join(t.get("tags", [])),
                    "notes": t.get("notes", "").replace("\n", " / "),
                }
            )
    with open(out_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(
            f,
            fieldnames=(
                list(rows[0].keys())
                if rows
                else [
                    "date",
                    "id",
                    "time",
                    "title",
                    "status",
                    "project",
                    "tags",
                    "notes",
                ]
            ),
        )
        writer.writeheader()
        for r in rows:
            writer.writerow(r)
    print("Exported to", out_path)


def export_md(out_path: str) -> None:
    docs = safe_load_all(FILE)
    with open(out_path, "w", encoding="utf-8") as f:
        for d in docs:
            f.write(f"## {d.get('date')}\n\n")
            for t in d.get("tasks", []):
                f.write(
                    f"- **[{t.get('status')}]** {t.get('time') or '--'} {t.get('title')}  \n"
                )
                if t.get("notes"):
                    f.write(f"  > {t.get('notes').replace(chr(10), chr(10)+'  > ')}\n")
                f.write("\n")
    print("Exported to", out_path)


def report_daily(date_str: Optional[str] = None) -> None:
    docs = safe_load_all(FILE)
    date_str = date_str or datetime.date.today().isoformat()
    doc = find_doc(docs, date_str)
    if not doc:
        print("No data for", date_str)
        return
    total = len(doc.get("tasks", []))
    done = sum(1 for t in doc.get("tasks", []) if t.get("status") == "done")
    in_progress = sum(
        1 for t in doc.get("tasks", []) if t.get("status") == "in-progress"
    )
    waiting = sum(1 for t in doc.get("tasks", []) if t.get("status") == "waiting")
    print(f"Daily report for {date_str}")

    print(
        f"Total: {total}, done: {done}, in-progress: {in_progress}, waiting: {waiting}"
    )
    # brief list of done items
    print("\nDone items:")
    for t in doc.get("tasks", []):
        if t.get("status") == "done":
            print(f"- {t.get('time') or '--'} {t.get('title')} ({t.get('id')})")


def report_weekly(week_start: Optional[str] = None) -> None:
    # week_start ISO date (Monday) or default to current week's Monday
    today = datetime.date.today()
    if week_start:
        start = datetime.date.fromisoformat(week_start)
    else:
        start = today - datetime.timedelta(days=today.weekday())
    end = start + datetime.timedelta(days=6)
    docs = safe_load_all(FILE)
    counts: Dict[str, int] = {"total": 0, "done": 0}
    by_project: Dict[str, Dict[str, int]] = {}
    for d in docs:
        d_date = d.get("date")
        if not d_date:
            continue
        dd = datetime.date.fromisoformat(d_date)
        if start <= dd <= end:
            for t in d.get("tasks", []):
                counts["total"] += 1
                if t.get("status") == "done":
                    counts["done"] += 1
                proj = t.get("project") or "unassigned"
                by_project.setdefault(proj, {"total": 0, "done": 0})
                by_project[proj]["total"] += 1
                if t.get("status") == "done":
                    by_project[proj]["done"] += 1
    print(f"Weekly report {start.isoformat()} to {end.isoformat()}")
    print(f"Total tasks: {counts['total']}, Done: {counts['done']}")
    print("\nBy project:")
    for p, v in by_project.items():
        print(f"- {p}: total {v['total']}, done {v['done']}")


#
# endregion 10 Task CRUD & Reports
#############################


#############################
# region 11 Bio Store Functions
#
def _bio_now_iso() -> str:
    return datetime.datetime.now().isoformat()


def _bio_read_store() -> Dict[str, Any]:
    """读取 bio 存储，返回 {version, bios: []} 结构。"""
    if not BIO_FILE.exists():
        return {"version": SCHEMA_VERSION, "bios": []}
    try:
        obj = yaml.safe_load(BIO_FILE.read_text(encoding="utf-8")) or {}
    except Exception:
        obj = {}
    if not isinstance(obj, dict):
        obj = {}
    bios = obj.get("bios")
    if not isinstance(bios, list):
        bios = []
    return {"version": str(obj.get("version") or SCHEMA_VERSION), "bios": bios}


def _bio_write_store(store: Dict[str, Any]) -> None:
    text = yaml.safe_dump(store, sort_keys=False, allow_unicode=True)
    if portalocker:
        with portalocker.Lock(str(BIO_FILE), "w", timeout=2) as fh:
            fh.write(text)
    else:
        BIO_FILE.write_text(text, encoding="utf-8")


def bio_list_entries() -> None:
    # 展示全部字段：id、title、tags、created/updated 与 content（markdown）
    store = _bio_read_store()
    bios = [b for b in store.get("bios", []) if isinstance(b, dict)]
    if not bios:
        print("No bio entries")
        return

    for idx, e in enumerate(bios, 1):
        eid = (e.get("id") or "").strip()
        title = (e.get("title") or "").strip()
        content = (e.get("content") or "").strip()
        tags = e.get("tags") or []
        if not isinstance(tags, list):
            tags = [str(tags)]
        created = (e.get("created_at") or "").strip()
        updated = (e.get("updated_at") or "").strip()

        if HAVE_RICH and Console is not None and Markdown is not None:
            c = Console()
            c.rule(f"[{idx}] {title} ({eid})")
            meta = []
            if tags:
                meta.append(
                    "tags: " + ", ".join([str(t) for t in tags if str(t).strip()])
                )
            if created or updated:
                meta.append(f"created: {created}")
                meta.append(f"updated: {updated}")
            if meta:
                c.print(" | ".join(meta))
            if content:
                c.print(Markdown(content))
            c.print("")
        else:
            print(f"--- [{idx}] {title} ({eid}) ---")
            if tags:
                print("tags:", ", ".join([str(t) for t in tags if str(t).strip()]))
            if created or updated:
                print(f"created: {created}  updated: {updated}")
            if content:
                print(content)
            print("")


def bio_add_entry(title: str, content: str, tags: Optional[List[str]] = None) -> None:
    store = _bio_read_store()
    eid = gen_id()
    entry = {
        "id": eid,
        "title": title,
        "content": content,
        "tags": [s for s in (tags or []) if str(s).strip()],
        "created_at": _bio_now_iso(),
        "updated_at": _bio_now_iso(),
    }
    store.setdefault("bios", []).append(entry)
    _bio_write_store(store)
    print(eid)


def bio_update_entry(
    entry_id: str,
    title: Optional[str] = None,
    content: Optional[str] = None,
    tags: Optional[List[str]] = None,
) -> None:
    store = _bio_read_store()
    for e in store.get("bios", []):
        if e.get("id") == entry_id:
            if title is not None:
                e["title"] = str(title)
            if content is not None:
                e["content"] = str(content)
            if tags is not None:
                e["tags"] = [s for s in (tags or []) if str(s).strip()]
            e["updated_at"] = _bio_now_iso()
            _bio_write_store(store)
            print("Updated:", entry_id)
            return
    print("Bio id not found")


def bio_delete_entry(entry_id: str) -> None:
    store = _bio_read_store()
    bios = store.get("bios", [])
    for i, e in enumerate(list(bios)):
        if e.get("id") == entry_id:
            del bios[i]
            _bio_write_store(store)
            print("Deleted:", entry_id)
            return
    print("Bio id not found")


def build_user_bio_markdown() -> str:
    """将 Bio 条目渲染为 Markdown，供插入 System Prompt。
    返回空字符串表示无内容。
    """
    store = _bio_read_store()
    bios = [b for b in store.get("bios", []) if isinstance(b, dict)]
    if not bios:
        return ""
    lines: List[str] = []
    lines.append("# User Bio")
    lines.append("")
    lines.append(
        "User Bio 记录了当前与你对话的{{ User }}的个人信息，与你对话的是一个活人，因此你需要有情感，有温度，给人活人感。"
    )
    lines.append("")
    for b in bios:
        title = (b.get("title") or "").strip()
        content = (b.get("content") or "").strip()
        if title:
            lines.append(f"### {title}")
            lines.append("")
        if content:
            lines.append(content)
            lines.append("")
    return "\n".join(lines).strip()


#
# endregion 11 Bio Store Functions
#############################

#############################
# region 12 ANTML Parsing & Tool Description Builders
#


def build_tools_description(
    specs: Dict[str, Any], order: Optional[List[str]] = None
) -> str:
    """根据工具元数据生成工具描述字符串，格式与原 TOOLS_DESCRIPTION 保持一致。"""
    order = order or list(specs.keys())
    lines: List[str] = []
    lines.append("# Tools")
    lines.append("")
    lines.append("## functions")
    lines.append("")
    lines.append("namespace functions {")
    lines.append("")

    for name in order:
        spec = specs.get(name)
        if not spec:
            continue
        desc = spec.get("description")
        if desc:
            # 支持多行 docstring：逐行加 // 前缀，避免破坏 TS 结构
            for ln in str(desc).splitlines():
                ln = ln.rstrip()
                lines.append(f"// {ln}" if ln else "//")
        lines.append(f"type {name} = (_: {{")
        params: List[Dict[str, Any]] = spec.get("params", [])
        for p in params:
            p_name = p.get("name", "")
            p_type = p.get("type", "string")
            optional = "?" if not p.get("required", False) else ""
            # 生成注释，包含 default 与 description
            comment_parts: List[str] = []
            if "default" in p:
                try:
                    import json as _json

                    default_str = _json.dumps(p.get("default"), ensure_ascii=False)
                except Exception:
                    default_str = str(p.get("default"))
                comment_parts.append(f"default: {default_str}")
            if p.get("description"):
                # 参数描述换行压缩为单行，避免打断行内注释
                desc_inline = " ".join(str(p.get("description")).split())
                if desc_inline:
                    comment_parts.append(desc_inline)
            comment = " // " + "; ".join(comment_parts) if comment_parts else ""

            param_line = f"  {p_name}{optional}: {p_type}," + comment
            lines.append(param_line)
        # 为所有工具追加一个可选的 commentary 参数，仅用于可见性说明，不会传给后端工具
        lines.append(
            "  commentary?: string, // optional; 调用意图/思考说明，仅用于向用户展示，提高可解释性，不会传入工具"
        )
        lines.append("}) => any;")
        lines.append("")

    lines.append("} // namespace functions")
    return "  \n".join(lines).strip()


def derive_tool_specs_from_wrappers(registry: Dict[str, Any]) -> Dict[str, Any]:
    """根据 wrapper 的显式函数签名推导工具元数据（完全移除旧式 params 支持）。
    规则：
    - 参数顺序：按函数签名中形参顺序；
    - 必填参数：无默认值则为必填；
    - 类型：根据类型注解做简单映射（str->string, bool->boolean, int/float->number；其它->string）；
    - 特殊说明：参数名为 tags 时，附加 description: "comma separated"；
    - 描述：使用函数 docstring；
    - 默认值：保留默认值到 spec.default。
    """
    import typing as _t

    specs: Dict[str, Any] = {}

    for name, fn in registry.items():
        base = inspect.unwrap(fn)
        desc = inspect.getdoc(base) or ""
        try:
            sig = inspect.signature(base)
        except Exception:
            specs[name] = {"description": desc, "params": []}
            continue
        try:
            type_hints = _t.get_type_hints(base, include_extras=True)
        except Exception:
            type_hints = {}

        params_list: List[Dict[str, Any]] = []
        for pname, p in sig.parameters.items():
            if p.kind in (p.VAR_POSITIONAL, p.VAR_KEYWORD):
                continue
            required = p.default is inspect._empty
            ann = type_hints.get(pname, p.annotation)

            # 展开 Optional/Union[*, None]
            origin = _t.get_origin(ann)
            args = _t.get_args(ann)
            if origin is _t.Union and args:
                non_none = [a for a in args if a is not type(None)]  # noqa: E721
                if len(non_none) == 1:
                    ann = non_none[0]

            # 类型映射
            if ann in (int, float):
                ptype = "number"
            elif ann is bool:
                ptype = "boolean"
            else:
                ptype = "string"

            spec: Dict[str, Any] = {
                "name": pname,
                "type": ptype,
                "required": required,
            }
            # 默认值存入
            if p.default is not inspect._empty:
                spec["default"] = p.default
            if pname == "tags":
                spec["description"] = "comma separated"
            params_list.append(spec)

        specs[name] = {"description": desc, "params": params_list}

    return specs


# 解析 <antml:function_calls> XML 并返回调用列表
# 返回形如 [{"name": str, "params": {k: v}}]
def parse_antml_calls(text: str) -> List[Dict[str, Any]]:
    start = text.find("<antml:function_calls>")
    end = text.find("</antml:function_calls>")
    if start == -1 or end == -1:
        return []
    xml_str = text[start : end + len("</antml:function_calls>")]
    # 容错：移除未声明的 antml: 命名空间前缀，避免 XML 解析错误（unbound prefix）
    sanitized = xml_str.replace("<antml:", "<").replace("</antml:", "</")
    try:
        root = ET.fromstring(sanitized)
    except Exception:
        return []
    calls: List[Dict[str, Any]] = []

    def tag_name(e: Any) -> str:
        t = getattr(e, "tag", "")
        if "}" in t:
            return t.split("}", 1)[1]
        if ":" in t:
            return t.split(":", 1)[1]
        return t

    for inv in list(root):
        if tag_name(inv) != "invoke":
            continue
        name_attr = inv.attrib.get("name")
        name: str = name_attr if isinstance(name_attr, str) else ""
        params: Dict[str, Any] = {}
        for p in list(inv):
            if tag_name(p) != "parameter":
                continue
            key_attr = p.attrib.get("name")
            key: str = key_attr if isinstance(key_attr, str) else ""
            val = (p.text or "").strip()
            if key:
                params[key] = val
        if name:
            calls.append({"name": name, "params": params})
    return calls


# 新增：移除文本中的 <antml:function_calls> 区块，保留其余自然语言内容
# 当模型同时返回自然语言与工具调用时，可用于提取先行展示给用户的文本
# 注意：仅移除首个成对的 antml 区块，避免误删其他内容
def strip_antml_block(text: str) -> str:
    start = text.find("<antml:function_calls>")
    if start == -1:
        return text
    end = text.find("</antml:function_calls>", start)
    # 若尚未收到闭合标签，先只保留 antml 之前的自然语言，避免把半截 antml 显示出来
    if end == -1:
        return text[:start].rstrip()
    closing = end + len("</antml:function_calls>")
    return (text[:start] + text[closing:]).strip()


def strip_all_antml_blocks(text: str) -> str:
    """移除文本中所有 antml:function_calls 区块；若存在未闭合的尾部块则裁掉尾部。"""
    s = text
    OPEN = "<antml:function_calls>"
    CLOSE = "</antml:function_calls>"
    while True:
        i = s.find(OPEN)
        if i == -1:
            break
        j = s.find(CLOSE, i)
        if j == -1:
            # 未闭合：截断至开标签前
            s = s[:i]
            break
        s = s[:i] + s[j + len(CLOSE) :]
    return s.strip()


# region
def preface_before_antml(text: str) -> str:
    """仅返回 antml 开标签之前的自然语言（用于首帧先行回复展示）。"""
    i = text.find("<antml:function_calls>")
    return text[:i].rstrip() if i != -1 else text


# 将工具结果封装为 XML，供模型继续参考
def build_antml_results(results: List[Dict[str, str]]) -> str:
    # results: [{"name": str, "output": str}]
    parts = ["<antml:function_results>"]
    for r in results:
        name = r.get("name", "")
        out = r.get("output", "")
        parts.append(
            f'  <antml:result name="{name}"><![CDATA[\n{out}\n]]></antml:result>'
        )
    parts.append("</antml:function_results>")
    return "\n".join(parts)


# 工具注册与执行
def _capture_print(fn: Any, *args: Any, **kwargs: Any) -> str:
    buf = io.StringIO()
    try:
        with redirect_stdout(buf):
            rv = fn(*args, **kwargs)
        printed = buf.getvalue()
        if rv is not None and printed.strip() == "":
            return str(rv)
        return printed
    except Exception as e:
        return f"ERROR: {e}"


def execute_tools(calls: List[Dict[str, Any]]) -> List[Dict[str, str]]:
    """执行工具（仅支持新式显式参数 wrapper）。
    - 使用函数签名校验必填参数，缺失时返回 ERROR: missing <param>
    - 仅透传与签名匹配的关键字参数
    """
    results: List[Dict[str, str]] = []
    for c in calls:
        name_val = c.get("name")
        name = name_val if isinstance(name_val, str) else ""
        params = c.get("params")
        params_dict: Dict[str, Any] = params if isinstance(params, dict) else {}
        fn = TOOLS_REGISTRY.get(name)
        if not fn:
            results.append({"name": name, "output": f"ERROR: unknown tool '{name}'"})
            continue
        try:
            sig = inspect.signature(fn)
            # 只保留签名中存在的键
            accepted = {k: v for k, v in params_dict.items() if k in sig.parameters}
            # 检查缺少的必填参数
            required = [
                n
                for n, p in sig.parameters.items()
                if p.default is inspect._empty
                and p.kind in (p.POSITIONAL_OR_KEYWORD, p.KEYWORD_ONLY)
            ]
            missing = [n for n in required if n not in accepted]
            if missing:
                results.append({"name": name, "output": f"ERROR: missing {missing[0]}"})
                continue
            out = fn(**accepted)
            results.append(
                {"name": name, "output": out if isinstance(out, str) else str(out)}
            )
        except Exception as e:
            results.append({"name": name, "output": f"ERROR: {e}"})
    return results


def get_tools_description() -> str:
    # 优先从 tool_* 包装函数自动推导；若失败则回退到静态 SPECS。
    derived = derive_tool_specs_from_wrappers(TOOLS_REGISTRY)
    order = list(derived.keys())
    return build_tools_description(derived, order)


#
# endregion 12 ANTML Parsing & Tool Description Builders
#############################


#############################
# region 13 Calculator & Date Helpers
#
def _safe_calc_eval(expr: str) -> float:
    """
    安全计算表达式，支持的运算符与语法：
    - 加减乘除: +, -, *, /
    - 整除与取余: //, %
    - 幂运算: **
    - 一元正负号: +x, -x
    - 括号: ( )
    - 数字: 整数与小数
    不支持：变量、函数调用、位运算、比较/布尔、下标、属性等。
    """
    if not isinstance(expr, str):
        raise ValueError("expression must be string")
    s = expr.strip()
    if not s:
        raise ValueError("empty expression")
    if len(s) > 1000:
        raise ValueError("expression too long")

    allowed_binops = {
        ast.Add: lambda a, b: a + b,
        ast.Sub: lambda a, b: a - b,
        ast.Mult: lambda a, b: a * b,
        ast.Div: lambda a, b: a / b,
        ast.FloorDiv: lambda a, b: a // b,
        ast.Mod: lambda a, b: a % b,
        ast.Pow: lambda a, b: a**b,
    }
    allowed_unary = {
        ast.UAdd: lambda a: +a,
        ast.USub: lambda a: -a,
    }

    node = ast.parse(s, mode="eval")

    def _eval(n: ast.AST) -> float:
        if isinstance(n, ast.Expression):
            return _eval(n.body)
        if isinstance(n, ast.Constant):
            if isinstance(n.value, (int, float)):
                return n.value
            raise ValueError("only numeric constants allowed")
        if isinstance(n, ast.Num):  # py<3.8
            return n.n  # type: ignore
        if isinstance(n, ast.UnaryOp) and type(n.op) in allowed_unary:
            return allowed_unary[type(n.op)](_eval(n.operand))
        if isinstance(n, ast.BinOp) and type(n.op) in allowed_binops:
            left = _eval(n.left)
            right = _eval(n.right)
            # 简单防护：避免极端幂运算
            if isinstance(n.op, ast.Pow):
                if abs(right) > 100 or abs(left) > 1e6:
                    raise ValueError("pow too large")
            return allowed_binops[type(n.op)](left, right)
        # 显式拒绝其它节点类型
        raise ValueError(f"unsupported expression element: {type(n).__name__}")

    res = _eval(node)
    return res


def _parse_iso_date(date_str: str, fmt: str = "%Y-%m-%d") -> datetime.date:
    return datetime.datetime.strptime(date_str.strip(), fmt).date()


def _days_in_month(year: int, month: int) -> int:
    if month == 12:
        next_month = datetime.date(year + 1, 1, 1)
    else:
        next_month = datetime.date(year, month + 1, 1)
    this_month = datetime.date(year, month, 1)
    return (next_month - this_month).days


def _add_months(d: datetime.date, months: int) -> datetime.date:
    y = d.year + (d.month - 1 + months) // 12
    m = (d.month - 1 + months) % 12 + 1
    day = min(d.day, _days_in_month(y, m))
    return datetime.date(y, m, day)


def _add_years(d: datetime.date, years: int) -> datetime.date:
    y = d.year + years
    m = d.month
    day = d.day
    # 处理闰年 2-29 溢出
    max_day = _days_in_month(y, m)
    if day > max_day:
        day = max_day
    return datetime.date(y, m, day)


def _apply_interval(base: datetime.date, interval: str) -> datetime.date:
    """
    interval 格式：由若干片段组成，每个片段为  [+-]?<int><unit>
    unit 支持: y(年), m(月), w(周), d(天)
    示例:
    "3d"       -> 加 3 天
    "-2w"      -> 减 2 周
    "1y2m-3d"  -> 加 1 年 2 月，减 3 天
    "10d 2w"   -> 加 10 天再加 2 周（空格分隔亦可）
    处理顺序：按出现顺序依次应用（y/m/w/d 混排时按写法顺序执行）
    """
    if not isinstance(interval, str) or not interval.strip():
        raise ValueError("interval required")
    s = interval.replace(" ", "")
    tokens = re.findall(r"([+\-]?\d+)\s*([ymwd])", s, flags=re.IGNORECASE)
    if not tokens:
        raise ValueError("invalid interval")
    cur = base
    for num_str, unit in tokens:
        n = int(num_str)
        u = unit.lower()
        if u == "y":
            cur = _add_years(cur, n)
        elif u == "m":
            cur = _add_months(cur, n)
        elif u == "w":
            cur = cur + datetime.timedelta(weeks=n)
        elif u == "d":
            cur = cur + datetime.timedelta(days=n)
        else:
            raise ValueError(f"unsupported unit: {unit}")
    return cur


#
# endregion 13 Calculator & Date Helpers
#############################


#############################
# region 14 MCP Server
#
_MCP_STATE: Dict[str, Any] = {"servers": {}}


def _load_mcp_servers() -> Dict[str, Any]:
    """读取新版 ~/.llm_todo_chat__mcp_servers.json（新格式，直接包含 mcpServers）。不存在返回空结构。"""
    if not MCP_SERVERS_FILE.exists():
        return {"mcpServers": {}}
    try:
        data = json.loads(MCP_SERVERS_FILE.read_text(encoding="utf-8"))
        if not isinstance(data, dict):
            return {"mcpServers": {}}
        mcp = data.get("mcpServers")
        if not isinstance(mcp, dict):
            return {"mcpServers": {}}
        return {"mcpServers": mcp}
    except Exception:
        return {"mcpServers": {}}


def _save_mcp_servers(data: Dict[str, Any]) -> None:
    """写回新格式（仅包含 mcpServers）。"""
    try:
        # 仅保留 mcpServers 字段，其余忽略
        out = {
            "mcpServers": (
                data.get("mcpServers")
                if isinstance(data.get("mcpServers"), dict)
                else {}
            )
        }
        tmp = MCP_SERVERS_FILE.with_suffix(".tmp")
        tmp.write_text(
            json.dumps(out, ensure_ascii=False, indent=2, sort_keys=True),
            encoding="utf-8",
        )
        tmp.replace(MCP_SERVERS_FILE)
    except Exception as e:
        print(f"[mcp] 写配置失败: {e}", file=sys.stderr)


# ================== 新实现：使用 fastmcp.Client 多服务器配置 ==================
# 目标：替换手写 JSON-RPC / 子进程协议解析逻辑，统一走 fastmcp 官方传输栈
# 说明：
# 1. 仍支持旧 JSON (servers:{ name:{command,args,env,timeoutSeconds}}) —— 动态转换
# 2. FastMCP Client 使用异步；对外保持同步 API（内部用 asyncio.run，若已在事件循环内则回退到 nest）
# 3. 缓存一个全局 CLIENT；首次调用时构建；如配置文件时间戳变化可强制重建（简化为环境变量触发）
# 4. 提供：_build_fastmcp_config(), _ensure_fastmcp_client(), mcp_call(), list_registered_mcp_capabilities()
# 5. 若未安装 fastmcp 则回退返回错误提示
try:
    from fastmcp import Client as _FastMCPClient  # type: ignore
except Exception:
    _FastMCPClient = None  # type: ignore

_FASTMCP_CLIENT: Optional[_FastMCPClient] = None
_FASTMCP_CLIENT_CONFIG_HASH: Optional[str] = None


def _hash_obj(o: Any) -> str:
    try:
        return hashlib.sha256(
            json.dumps(o, sort_keys=True, ensure_ascii=False).encode("utf-8")
        ).hexdigest()
    except Exception:
        return uuid.uuid4().hex


def _build_fastmcp_config() -> Dict[str, Any]:
    """
    读取并返回 { "mcpServers": { name: {transport, command, args, env, timeout?} } }
    额外增强：
      - 若设置环境变量 TODO_MCP_NO_BANNER=1/true/on，则为 fastmcp CLI 启动命令自动注入 --no-banner
        支持形态：
          * fastmcp run server_spec ...
          * uv run fastmcp run server_spec ...
    """
    cfg = _load_mcp_servers()  # {"mcpServers": {...}}
    m = cfg.setdefault("mcpServers", {})
    global_no_banner = os.getenv("TODO_MCP_NO_BANNER", "").strip().lower() in {
        "1",
        "true",
        "yes",
        "on",
    }
    for name, sc in list(m.items()):
        if not isinstance(sc, dict):
            continue
        # 服务器自身 env 里的标志
        server_flag = (
            str(sc.get("env", {}).get("TODO_MCP_NO_BANNER", "")).strip().lower()
        )
        want_no_banner = global_no_banner or (server_flag in {"1", "true", "yes", "on"})
        if not want_no_banner:
            continue
        cmd = sc.get("command")
        args = sc.get("args") or []
        if not isinstance(args, list):
            continue
        # fastmcp run pattern
        if cmd == "fastmcp" and args and args[0] == "run":
            if "--no-banner" not in args:
                sc["args"] = ["run", "--no-banner", *args[1:]]
        # uv run fastmcp run pattern
        elif (
            cmd == "uv"
            and len(args) >= 3
            and args[0] == "run"
            and args[1] == "fastmcp"
            and args[2] == "run"
        ):
            if "--no-banner" not in args[3:]:
                sc["args"] = ["run", "fastmcp", "run", "--no-banner", *args[3:]]
        # uv run python/python3 -m module  pattern
        elif (
            cmd == "uv"
            and len(args) >= 2
            and args[0] == "run"
            and args[1] in {"python", "python3"}
        ):
            # 处理形态：
            #   uv run python3 -m mcp_server_context7 [extra...]
            #   uv run python3 server.py [extra...]
            # 目的：改写成 fastmcp run --no-banner <server_spec> [extra...]
            # 注意：
            #   - 若是 -m module 形式，需要把 module 映射成物理文件路径（module[.sub]* -> path + .py）
            #   - 若无法找到对应文件则放弃改写，避免 fastmcp CLI 报 File not found
            mod = None
            rest: list[str] = []
            used_dash_m = False
            if "-m" in args:
                used_dash_m = True
                try:
                    mi = args.index("-m")
                    if mi + 1 < len(args):
                        mod = args[mi + 1]
                        rest = args[mi + 2 :]
                except Exception:
                    mod = None
            else:
                # 形如 uv run python3 server.py
                if len(args) >= 3 and not args[2].startswith("-"):
                    mod = args[2]
                    rest = args[3:]
            if mod:
                mod_spec = mod
                if used_dash_m and not mod.endswith(".py"):
                    # 尝试把模块名转成文件路径
                    candidate = mod.replace(".", os.sep) + ".py"
                    if os.path.isfile(candidate):
                        mod_spec = candidate
                    else:
                        # 找不到对应文件，放弃改写（保持原 args，避免报错）
                        continue
                # 重写为 fastmcp run --no-banner <spec> [rest...]
                sc["args"] = ["run", "fastmcp", "run", "--no-banner", mod_spec, *rest]
    return cfg


def _run_async(coro):
    """
    在同步环境中安全运行协程：
    - 如果当前无事件循环：直接 asyncio.run
    - 如果已有事件循环（如在交互 REPL/某些框架内）：使用 nest_asyncio 回退
    """
    try:
        import asyncio

        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None
        if loop and loop.is_running():
            # 动态引入 nest_asyncio（若存在）避免死锁；否则创建新任务并等待
            try:
                import nest_asyncio  # type: ignore

                nest_asyncio.apply()
            except Exception:
                pass
            return asyncio.ensure_future(coro) if not asyncio.isfuture(coro) else coro
        else:
            return asyncio.run(coro)
    except Exception as e:
        raise RuntimeError(f"_run_async failed: {e}")


def _ensure_fastmcp_client(force_recreate: bool = False) -> Optional[_FastMCPClient]:
    global _FASTMCP_CLIENT, _FASTMCP_CLIENT_CONFIG_HASH
    if _FastMCPClient is None:
        return None
    cfg = _build_fastmcp_config()
    h = _hash_obj(cfg)
    if (not force_recreate) and _FASTMCP_CLIENT and h == _FASTMCP_CLIENT_CONFIG_HASH:
        return _FASTMCP_CLIENT
    # 关闭旧 client（如已存在）
    if _FASTMCP_CLIENT:
        try:
            # 尝试优雅关闭
            _run_async(_FASTMCP_CLIENT.close())  # type: ignore
        except Exception:
            pass
    _FASTMCP_CLIENT = _FastMCPClient(cfg)
    _FASTMCP_CLIENT_CONFIG_HASH = h
    return _FASTMCP_CLIENT


def register_mcp_server(
    name: str,
    entry: str,
    meta: Optional[Dict[str, Any]] = None,  # meta 不再写入文件，仅保留兼容参数位
    env: Optional[Dict[str, Any]] = None,
) -> None:
    """
    写入新格式配置：
    {
      "mcpServers": {
        "<name>": {
          "transport": "stdio",
          "command": "<entry>",
          "args": [],
          "env": {...},
          "timeout": 30.0
        }
      }
    }
    """
    data = _load_mcp_servers()  # {"mcpServers": {...}}
    servers = data.setdefault("mcpServers", {})
    if name in servers:
        raise RuntimeError(f"server 已存在: {name}")
    servers[name] = {
        "transport": "stdio",
        "command": entry,
        "args": [],
        "env": env or {},
        "timeout": 30.0,
    }
    _save_mcp_servers(data)
    _ensure_fastmcp_client(force_recreate=True)


def remove_mcp_server(name: str) -> None:
    data = _load_mcp_servers()
    servers = data.get("mcpServers") or {}
    if name in servers:
        del servers[name]
        _save_mcp_servers(data)
    _ensure_fastmcp_client(force_recreate=True)


def print_mcp_servers(json_mode: bool = False) -> None:
    cfg = _build_fastmcp_config()
    items = []
    for name, sc in cfg.get("mcpServers", {}).items():
        items.append(
            {
                "name": name,
                "transport": sc.get("transport"),
                "command": sc.get("command"),
                "args": sc.get("args"),
                "timeout": sc.get("timeout"),
            }
        )
    if json_mode:
        print(json.dumps(items, ensure_ascii=False, indent=2))
    else:
        for it in items:
            print(
                f"{it['name']}: transport={it['transport']} cmd={it['command']} args={it['args']} timeout={it['timeout']}"
            )


def mcp_call(
    server: str,
    tool: str,
    params_json: str,
    timeout_override: Optional[float] = None,
    raw: bool = False,
) -> str:
    """
    使用 fastmcp.Client 调用工具。
    - server: legacy 名称（对应 config 中的 mcpServers key）
    - tool: 不含前缀的原始工具名；会自动拼接 server_tool 形式尝试。
    - params_json: JSON 对象字符串
    - raw: 返回原始 fastmcp result.data / result.text 序列化
    """
    if _FastMCPClient is None:
        return "ERROR: fastmcp not installed (uv pip install fastmcp)"
    try:
        params = json.loads(params_json) if params_json.strip() else {}
        if not isinstance(params, dict):
            return "ERROR: params-json-must-be-object"
    except Exception as e:
        return f"ERROR: invalid-json: {e}"

    cfg = _build_fastmcp_config()  # 每次读取最新配置，支持动态修改

    async def _run():
        client = _FastMCPClient(cfg)  # 每次调用创建新实例，避免复用已关闭连接
        try:
            async with client:
                try:
                    tools = await client.list_tools()
                except Exception as e:
                    return f"ERROR: list-tools-failed: {e}"
                names = {t.name for t in tools}
                candidate = f"{server}_{tool}"
                actual = candidate if candidate in names else tool
                if actual not in names:
                    return f"ERROR: tool-not-found ({tool})"
                try:
                    result = await client.call_tool(
                        actual, params, timeout=timeout_override
                    )
                except Exception as e:
                    return f"ERROR: call-failed: {e}"

                # 兼容 fastmcp 返回：没有 result.text；需要从 content(list[TextContent]) 聚合
                def _extract_text(r) -> str:
                    texts = []
                    for blk in getattr(r, "content", []) or []:
                        # mcp.types.TextContent: 有属性 type='text' 与 text
                        if getattr(blk, "type", None) == "text":
                            t = getattr(blk, "text", None)
                            if isinstance(t, str) and t.strip():
                                texts.append(t.rstrip())
                    return "\n".join(texts).strip()

                aggregated_text = _extract_text(result)
                data = getattr(result, "data", None)
                structured_content = getattr(result, "structured_content", None)

                if raw:
                    try:
                        return json.dumps(
                            {
                                "name": actual,
                                "is_error": getattr(result, "is_error", False),
                                "data": data,
                                "structured_content": structured_content,
                                "content_text": aggregated_text or None,
                                "content_len": len(
                                    getattr(result, "content", []) or []
                                ),
                            },
                            ensure_ascii=False,
                            indent=2,
                        )
                    except Exception:
                        # 退化：尽量仍返回可读信息
                        return aggregated_text or str(data) or str(result)

                # 优先返回聚合文本；否则序列化 data / structured_content
                if aggregated_text:
                    return aggregated_text
                # 若有 data（结构化解析结果）则输出 JSON
                if data is not None:
                    try:
                        return json.dumps(data, ensure_ascii=False)
                    except Exception:
                        return str(data)
                # 退化到 structured_content
                if structured_content is not None:
                    try:
                        return json.dumps(structured_content, ensure_ascii=False)
                    except Exception:
                        return str(structured_content)
                # 最后兜底：原始 repr
                return str(result)
        except Exception as e:
            return f"ERROR: client-context: {e}"

    out = _run_async(_run())
    if hasattr(out, "result"):
        try:
            return out.result()  # type: ignore
        except Exception as e:
            return f"ERROR: {e}"
    return out  # 已是字符串


def list_registered_mcp_capabilities(
    server: Optional[str] = None, json_mode: bool = False
) -> str:
    """
    列出工具（通过 fastmcp），保持与旧接口兼容的输出结构。
    server: 指定 server 名则只输出该 server 前缀工具。
    """
    if _FastMCPClient is None:
        msg = "ERROR: fastmcp not installed"
        print(msg)
        return msg

    cfg = _build_fastmcp_config()

    async def _run():
        client = _FastMCPClient(cfg)
        try:
            async with client:
                try:
                    tools = await client.list_tools()
                except Exception as e:
                    err = {"error": f"list-tools-failed: {e}"}
                    print(json.dumps(err, ensure_ascii=False))
                    return err

                def _schema_dict(s: Any) -> Dict[str, Any]:
                    if s is None:
                        return {}
                    if isinstance(s, dict):
                        return s
                    # 兼容 pydantic / dataclass 等多种形式
                    for attr in ("model_json_schema", "schema", "to_dict"):
                        if hasattr(s, attr):
                            try:
                                fn = getattr(s, attr)
                                data = fn() if callable(fn) else fn
                                if isinstance(data, dict):
                                    return data
                            except Exception:
                                pass
                    return {}

                items = []
                for t in tools:
                    name = getattr(t, "name", None)
                    if not name:
                        continue
                    desc = getattr(t, "description", "") or ""
                    if server and not name.startswith(f"{server}_"):
                        continue
                    schema = None
                    # fastmcp Tool 通常为 input_schema; 做多名称兜底
                    for attr in ("input_schema", "inputSchema", "schema"):
                        if hasattr(t, attr):
                            schema = getattr(t, attr)
                            if schema is not None:
                                break
                    sd = _schema_dict(schema)
                    props = sd.get("properties") if isinstance(sd, dict) else None
                    required = (
                        set(sd.get("required") or []) if isinstance(sd, dict) else set()
                    )
                    params_list = []
                    if isinstance(props, dict):
                        for p_name, meta in props.items():
                            if not isinstance(meta, dict):
                                meta = {}
                            p_type = meta.get("type") or "string"
                            p_desc = meta.get("description") or ""
                            params_list.append(
                                {
                                    "name": p_name,
                                    "type": p_type,
                                    "required": p_name in required,
                                    "description": p_desc,
                                }
                            )
                    item = {"name": name, "description": desc}
                    if params_list:
                        item["params"] = params_list  # 扩展字段（向后兼容：旧代码忽略）
                    items.append(item)

                if json_mode:
                    print(json.dumps(items, ensure_ascii=False, indent=2))
                else:
                    lines = [
                        f"[tools] count={len(items)}"
                        + (f" (filtered by server={server})" if server else "")
                    ]
                    for it in items:
                        lines.append(f"  - {it['name']}: {it['description'][:60]}")
                        # 增加参数行
                        for p in it.get("params", []):
                            rflag = "*" if p.get("required") else ""
                            # 安全获取首行描述：可能为空导致 splitlines() 结果为空列表
                            _raw_desc = p.get("description") or ""
                            _desc_lines = _raw_desc.splitlines()
                            p_desc = _desc_lines[0] if _desc_lines else ""
                            if len(p_desc) > 60:
                                p_desc = p_desc[:57] + "..."
                            lines.append(
                                f"      * {p['name']}{rflag} <{p.get('type','')}>: {p_desc}"
                            )
                    print("\n".join(lines))
                return items
        except Exception as e:
            err = {"error": f"client-context: {e}"}
            print(json.dumps(err, ensure_ascii=False))
            return err

    out = _run_async(_run())
    if hasattr(out, "result"):
        try:
            _ = out.result()  # type: ignore
        except Exception:
            pass
    return ""  # 兼容旧签名不依赖返回值


#
# endregion 14 MCP Server
#############################


#############################
# region 15 Tool Wrappers (bio/todo/jina/reflect/fs/human/calc/date)
#
# bio wrappers
def tool__bio__add(title: str, content: str, tags: Optional[str] = None) -> str:
    """Add a bio entry with title and markdown content; optional tags (comma separated)"""
    tags_list = [s.strip() for s in tags.split(",")] if isinstance(tags, str) else None
    return _capture_print(bio_add_entry, title, content, tags_list)


def tool__bio__update(
    id: str,
    title: Optional[str] = None,
    content: Optional[str] = None,
    tags: Optional[str] = None,
) -> str:
    """Update a bio entry by id; fields: title/content/tags (comma separated)"""
    tags_list = [s.strip() for s in tags.split(",")] if isinstance(tags, str) else None
    return _capture_print(bio_update_entry, id, title, content, tags_list)


def tool__bio__delete(id: str) -> str:
    """Delete a bio entry by id"""
    return _capture_print(bio_delete_entry, id)


def tool__bio__list() -> str:
    """List all bio entries with full details"""
    return _capture_print(bio_list_entries)


# 文件保存工具与 Human-in-Loop 工具
def tool__fs__save_file(
    dir: str,
    filename: str,
    content: str,
    append: str = "false",
    make_dirs: str = "true",
    encoding: str = "utf-8",
) -> str:
    """
    Save text content into a file under a user specified directory.

    Parameters:
    - dir: target directory (will be expanded: ~ and environment variables)
    - filename: file name (if contains path separators and is relative, it will be resolved under dir)
    - content: text content to write
    - append: "true"/"false" (default false) — append when true, else overwrite
    - make_dirs: "true"/"false" (default true) — create directory if not exists
    - encoding: file encoding (default utf-8)

    Returns:
      JSON string: {"path": "<abs_path>", "bytes": <int>, "mode": "append|write"}
    Errors are returned as: "ERROR: <message>"
    """
    try:
        mode_append = str(append).strip().lower() in {"1", "true", "yes", "on"}
        allow_mkdir = str(make_dirs).strip().lower() in {"1", "true", "yes", "on"}
        dir_path = Path(os.path.expanduser(os.path.expandvars(dir))).resolve()
        if not dir_path.exists():
            if allow_mkdir:
                dir_path.mkdir(parents=True, exist_ok=True)
            else:
                return "ERROR: directory not exists"
        if not dir_path.is_dir():
            return "ERROR: dir is not a directory"

        fname = filename.strip()
        target = Path(fname)
        if not target.is_absolute():
            target = (dir_path / fname).resolve()

        # 简单安全防护：禁止写入非常规 /dev 等特殊路径
        forbidden = {"/dev", "/proc", "/sys"}
        if any(
            str(target).startswith(fb + os.sep) or str(target) == fb for fb in forbidden
        ):
            return "ERROR: forbidden path"

        # 确保父目录存在（当 filename 包含子目录时）
        if not target.parent.exists():
            if allow_mkdir:
                target.parent.mkdir(parents=True, exist_ok=True)
            else:
                return "ERROR: parent directory not exists"

        data = content if isinstance(content, str) else str(content)
        write_mode = "a" if mode_append else "w"
        with open(target, write_mode, encoding=encoding) as f:
            f.write(data)
        out = {
            "path": str(target),
            "bytes": len(data.encode(encoding, errors="ignore")),
            "mode": "append" if mode_append else "write",
        }
        return json.dumps(out, ensure_ascii=False)
    except Exception as e:
        return f"ERROR: {e}"


def tool__human__input(
    prompt: str,
    default: Optional[str] = None,
    kind: str = "text",
) -> str:
    """
    Human-in-Loop input tool (Panel 风格集成方案2):
    - 使用 prompt_toolkit Application + Layout 将输入框真正置于“面板”内部。
    - 支持 kind: text | confirm | secret
      * text    : 普通单行输入
      * confirm : 按回车直接返回 "HIT"（或 default）
      * secret  : 密码模式（不回显）
    - 若无 TTY / 无 prompt_toolkit，则回退到内置 input / getpass。
    - 移除旧的 __HUMAN_INPUT_START__/__HUMAN_INPUT_END__ 标记。
    返回:
      用户输入的字符串；或以 "ERROR: ..." 开头的错误提示。
    """
    if not sys.stdin.isatty():
        return "ERROR: human-input-unavailable (stdin not tty)"

    kind_norm = (kind or "text").strip().lower()
    msg = prompt.strip() if isinstance(prompt, str) else "Input:"

    # 优先使用 prompt_toolkit 构建“真正面板输入”
    if HAVE_PTK:
        try:
            from prompt_toolkit.application import Application
            from prompt_toolkit.document import Document
            from prompt_toolkit.filters import Condition
            from prompt_toolkit.key_binding import KeyBindings
            from prompt_toolkit.layout import HSplit, Layout
            from prompt_toolkit.styles import Style
            from prompt_toolkit.validation import ValidationError, Validator
            from prompt_toolkit.widgets import Frame, TextArea
        except Exception:
            # 若核心组件导入失败，回退简单模式
            HAVE_LOCAL_PTK = False
        else:
            HAVE_LOCAL_PTK = True
        if HAVE_LOCAL_PTK:
            # 富显示（可选）：用 rich 渲染一条上方说明，避免闪烁（不强制）
            # if HAVE_RICH and Console is not None:
            #     try:
            #         console = Console()
            #         console.print(
            #             Panel.fit(
            #                 msg,
            #                 title="Human Input",
            #                 border_style="cyan",
            #                 style="bold",
            #             )
            #         )
            #     except Exception:
            #         pass

            # confirm 模式：仅等待 Enter
            if kind_norm == "confirm":
                kb = KeyBindings()
                done = {"value": default if default is not None else "HIT"}

                @kb.add("enter")
                def _enter(event):
                    event.app.exit()

                info = TextArea(
                    text=msg + "\n(按回车继续)",
                    focusable=False,
                    style="class:info",
                )
                dummy = TextArea(
                    text="",
                    focusable=False,
                    style="class:dim",
                )
                root = Frame(body=HSplit([info, dummy]), title="Confirm")
                style = Style.from_dict(
                    {
                        "frame": "bg:#1f1f1f #ffffff",
                        "info": "bg:#1f1f1f #00afff",
                        "dim": "bg:#1f1f1f #555555",
                    }
                )
                app = Application(
                    layout=Layout(root),
                    key_bindings=kb,
                    full_screen=False,
                    style=style,
                )
                app.run()
                return done["value"]

            # text / secret 输入模式
            kb = KeyBindings()
            result_holder: Dict[str, Optional[str]] = {"value": None}

            # 简单长度验证示例（可按需扩展）
            class _LineValidator(Validator):
                def validate(self, document: Document) -> None:
                    txt = document.text
                    if "\n" in txt:
                        raise ValidationError(
                            message="只支持单行输入", cursor_position=len(txt)
                        )

            password_mode = kind_norm == "secret"

            input_field = TextArea(
                text=default or "",
                multiline=False,
                password=password_mode,
                prompt="> ",
                style="class:input-field",
                validator=_LineValidator(),
            )
            info_lines = [msg]
            if password_mode:
                info_lines.append("(密码输入: 不回显)")
            else:
                info_lines.append("(输入后回车确认)")
            if default:
                info_lines.append(f"(默认: {default})")
            info_area = TextArea(
                text="\n".join(info_lines),
                focusable=False,
                style="class:info",
            )

            @kb.add("enter")
            def _accept(event):
                # validator 会在此自动触发
                result_holder["value"] = input_field.text
                event.app.exit()

            @kb.add("c-c")
            @kb.add("c-d")
            def _cancel(event):
                result_holder["value"] = None
                event.app.exit()

            root = Frame(
                body=HSplit([info_area, input_field]),
                title="Secret" if password_mode else "Input",
                style="class:frame",
            )
            style = Style.from_dict(
                {
                    "frame": "bg:#1f1f1f #ffffff",
                    "info": "bg:#1f1f1f #00afff",
                    "input-field": "bg:#202020 #ffffff",
                }
            )

            app = Application(
                layout=Layout(root, focused_element=input_field),
                key_bindings=kb,
                style=style,
                full_screen=False,
            )
            try:
                app.run()
            except KeyboardInterrupt:
                return "ERROR: user-cancelled"

            val = result_holder["value"]
            if (not val) and default is not None:
                return default
            if val is None:
                return "ERROR: user-cancelled"
            return val

    # ---------- 回退路径（无 prompt_toolkit） ----------
    try:
        if kind_norm == "confirm":
            input(msg + " (press Enter to continue)> ")
            return default if default is not None else "HIT"
        elif kind_norm == "secret":
            try:
                import getpass as _gp

                v = _gp.getpass(msg + " (secret)> ")
            except Exception:
                v = input(msg + "> ")
        else:
            v = input(msg + "> ")
        if (not v) and default is not None:
            return default
        return v
    except KeyboardInterrupt:
        return "ERROR: user-cancelled"
    except EOFError:
        return "ERROR: eof"
    except Exception as e:
        return f"ERROR: {e}"


# 会话重置工具
CONTROL_RESET = "CONTROL:RESET_MESSAGES"
CURRENT_CHAT_MESSAGES: Optional[List[Dict[str, str]]] = None
PENDING_RESET_MESSAGES: Optional[List[Dict[str, str]]] = None


def tool__reflect__negate_and_reflect(
    first_user: Optional[str] = None,
    inherited: Optional[str] = None,
    next_direction: Optional[str] = None,
    current_status: Optional[str] = None,
    style: str = "concise-plan",
) -> str:
    """
    否定并反思（Negate & Reflect）工具：
    - 直接重置当前对话消息序列（messages），以“首条用户消息 + 反思提示”作为新的 user-assistant 起点。
    - 若未显式提供 first_user，则从当前 messages 中寻找首个 role=='user' 的消息作为首条用户消息。
    - 最终消息序列（保留 system，如存在）:
      [system?], {"role":"user","content":<first_user>}, {"role":"assistant","content":<assistant_seed>}
    返回:
    - 固定控制标记字符串 CONTROL:RESET_MESSAGES，用于调用侧识别进行后续处理。
    """
    try:
        global CURRENT_CHAT_MESSAGES, PENDING_RESET_MESSAGES
        if not isinstance(CURRENT_CHAT_MESSAGES, list):
            return "ERROR: no-active-messages"

        # 取 system（若存在）
        system_msg = None
        if (
            len(CURRENT_CHAT_MESSAGES) > 0
            and isinstance(CURRENT_CHAT_MESSAGES[0], dict)
            and CURRENT_CHAT_MESSAGES[0].get("role") == "system"
        ):
            system_msg = CURRENT_CHAT_MESSAGES[0]

        # 判定首条用户消息
        fu = first_user.strip() if isinstance(first_user, str) else ""
        if not fu:
            for m in CURRENT_CHAT_MESSAGES:
                if isinstance(m, dict) and m.get("role") == "user":
                    t = m.get("content") or ""
                    if isinstance(t, str) and t.strip():
                        fu = t.strip()
                        break
        if not fu:
            return "ERROR: missing first_user"

        # 组装反思提示
        sections: List[str] = []
        if isinstance(current_status, str) and current_status.strip():
            sections.append(f"当前问题现状\n- {current_status.strip()}")
        if isinstance(inherited, str) and inherited.strip():
            sections.append(f"需继承的关键信息\n- {inherited.strip()}")
        if isinstance(next_direction, str) and next_direction.strip():
            sections.append(f"下一步方向\n- {next_direction.strip()}")

        header = "否定与反思"
        guidance = (
            "请先否定前一轮可能的假设与路径，指出易错点与忽视点；"
            "随后给出一个更稳健的下一步行动方案，并包含：\n"
            "- 验证标准（如何判断方向对/错）\n"
            "- 停-改-继续 准则（何时停止/如何调整/何时继续推进）"
        )
        body_parts = [header, ""]
        if sections:
            body_parts.append("\n\n".join(sections))
            body_parts.append("")
        if style == "concise-plan":
            body_parts.append(guidance)
        else:
            body_parts.append(guidance)
        assistant_seed = "\n".join(body_parts).strip()

        # 预置新的起始对
        new_pair = [
            {
                "role": "user",
                "content": fu,
            },
            {"role": "assistant", "content": assistant_seed},
        ]
        PENDING_RESET_MESSAGES = list(new_pair)

        # 直接就地重置当前会话消息（保留 system）
        CURRENT_CHAT_MESSAGES.clear()
        if system_msg is not None:
            CURRENT_CHAT_MESSAGES.append(system_msg)
        CURRENT_CHAT_MESSAGES.extend(new_pair)

        return CONTROL_RESET
    except Exception as e:
        return f"ERROR: {e}"


# 会话终止控制常量（用于安全/政策触发的强制结束）
CONTROL_TERMINATE = "CONTROL:TERMINATE_CONVERSATION"


def tool__safety__terminate(
    reason: Optional[str] = None,
    category: Optional[str] = None,
    user_message: Optional[str] = None,
) -> str:
    """
    安全终止对话工具（Safety Termination Tool）
    使用场景：
    - 用户请求 / 讨论 违法、暴力、仇恨、恐怖主义、歧视、骚扰、侵犯隐私、危险行为指导、成人/未成年人不当内容、自残自杀指导、医疗/法律/投资等需专业资质的高风险指令（且不可安全满足）等。
    - 用户持续试图绕过安全限制或以微调/提示注入方式诱导生成不当内容。
    行为准则：
    1. 不提供被拒绝内容的细节、步骤、配方、名单、代码、具体执行方法等。
    2. 不鼓励、煽动、强化或共谋任何危险或不当行为。
    3. 给予简洁、冷静、礼貌的拒绝说明（由上游模型在调用完本工具后自行生成或直接结束）。
    4. 返回固定控制信号，供宿主程序检测后立即结束当前会话/阻断后续模型生成。
    参数:
      - reason: （可选）简短自然语言说明（面向日志/审计），不回显给用户亦可；应避免复述敏感细节。
      - category: （可选）策略分类标签，如："illicit","violence","hate","self-harm","sexual","privacy","extremism","harassment","medical","legal","financial","other".
      - user_message: （可选）触发消息的脱敏/部分截断版本，仅用于内部审计（避免原文泄露）。
    返回:
      - CONTROL:TERMINATE_CONVERSATION 控制标记；可能附加简短 JSON 结构（序列化失败则仅返回标记）。
    """
    meta = {
        "reason": (reason or "").strip(),
        "category": (category or "").strip(),
        "user_message": (user_message or "").strip(),
        "ts": datetime.datetime.now().isoformat(),
    }
    try:
        packed = json.dumps(meta, ensure_ascii=False)
        return f"{CONTROL_TERMINATE} {packed}"
    except Exception:
        return CONTROL_TERMINATE


# 代办事项工具
def tool__todo__add_task(
    title: str,
    time: Optional[str] = None,
    project: Optional[str] = None,
    tags: Optional[str] = None,
    notes: Optional[str] = None,
) -> str:
    """Add a task to today's document"""
    tags_list = [s.strip() for s in tags.split(",")] if isinstance(tags, str) else None
    return _capture_print(add_task, title, time, project, tags_list, notes)


def tool__todo__list(date: Optional[str] = None) -> str:
    """List tasks. Defaults to today when omitted.
    - 单日：YYYY-MM-DD （缺省为今天）
    - 范围：YYYY-MM-DD..YYYY-MM-DD （顺序可颠倒，含端点）
    """
    d = date or datetime.date.today().isoformat()
    return _capture_print(list_tasks_for_date, d)


def tool__todo__search(query: str) -> str:
    """Search tasks by query across title, notes and tags"""
    return _capture_print(search, query)


def tool__todo__complete(id: str, note: Optional[str] = None) -> str:
    """Complete a task by id, optionally appending a note"""
    return _capture_print(complete, id, note)


def tool__todo__report_daily(date: Optional[str] = None) -> str:
    """Generate a daily report"""
    return _capture_print(report_daily, date)


def tool__todo__report_weekly(start: Optional[str] = None) -> str:
    """Generate a weekly report (start is Monday ISO date)"""
    return _capture_print(report_weekly, start)


def tool__todo__update(
    id: str,
    title: Optional[str] = None,
    time: Optional[str] = None,
    status: Optional[str] = None,
    project: Optional[str] = None,
    tags: Optional[str] = None,
    notes: Optional[str] = None,
    note_append: Optional[str] = None,
) -> str:
    """Update fields of a task by id. Optional fields: title, time, status, project, tags (comma separated), notes (replace), note_append (append with timestamp)."""
    tags_list = [s.strip() for s in tags.split(",")] if isinstance(tags, str) else None
    return _capture_print(
        update_task,
        id,
        title,
        time,
        status,
        project,
        tags_list,
        notes,
        note_append,
    )


def tool__todo__show(id: str) -> str:
    """Show full task details by id (date, all fields, tags, notes)."""
    return _capture_print(show_task, id)


def tool__todo__delete(id: str) -> str:
    """Delete a task by id"""
    return _capture_print(delete_task, id)


# JINA 搜索工具
def tool__jina__web_search(query: str) -> str:
    """Search the web via Jina Search API and return brief results.
    Parameters:
    - query: The question to search, Limitations and guidance:
        - The query does NOT support advanced search syntax (e.g., AND/OR/(), site:, filetype:, exact quotes, minus operator). Plain keyword matching only.
        - Prefer question-form, single-intent queries. Be clear and specific. Example: "How much did Ethereum's Dencun upgrade reduce fees on major L2s?"
        - Try one focused keyword set per call; iterate by rephrasing the question if needed.
        - By default this returns "no-content" summaries; to read the source, pair with tool__jina__fetch_markdown.
    Returns:
    - Concise search result text (Jina no-content summaries), or a string starting with 'ERROR: ' on failure.
    """
    try:
        return perform_jina_search(query=query, no_content=True)
    except Exception as e:
        return f"ERROR: {e}"


def tool__jina__fetch_markdown(url: str, token_budget: str = "16_000") -> str:
    """Fetch a web page via Jina Reader and return Markdown
    Parameters:
    - token_budget: integer, between 16_000 and 32_000
    """
    try:
        return perform_jina_fetch_markdown(url=url, token_budget=int(token_budget))
    except Exception as e:
        return f"ERROR: {e}"


# ===== Tools: Calculator & Date calculator =====
def tool__calc__eval(expression: str) -> str:
    """
    计算器：安全评估算术表达式。
    支持: +, -, *, /, //, %, **, 一元 +/-, 括号 ()，整数与小数。
    不支持：变量、函数、位运算、比较/布尔、下标/属性等。
    """
    try:
        res = _safe_calc_eval(expression)
        # 统一输出：整数显示为整型，浮点保留尽量短的表示
        if isinstance(res, float):
            # 去除无意义的小数位
            out = f"{res:.12g}"
        else:
            out = str(res)
        return out
    except Exception as e:
        return f"ERROR: {e}"


def tool__date__calc(
    op: str,
    date1: str = "",
    date2: str = "",
    date: str = "",
    interval: str = "",
    unit: str = "days",
    fmt: str = "%Y-%m-%d",
) -> str:
    """
    日期计算器：
    - 差值: op=diff，提供 date1 与 date2（格式由 fmt 指定，默认 YYYY-MM-DD），unit 支持 days/weeks（默认 days）
    - 加间隔: op=add，提供 date 与 interval（支持 y/m/w/d，如 "1y2m-3d" 或 "10d 2w"），返回新日期
    参数:
    - fmt: 日期格式（默认 "%Y-%m-%d"）
    - unit: 差值单位（days|weeks）
    示例:
    diff: op=diff, date1=2025-08-01, date2=2025-08-14 -> 13
    add : op=add,  date=2025-08-14, interval="1y2m-3d" -> 2026-10-11
    """
    try:
        op_s = (op or "").strip().lower()
        if op_s == "diff":
            if not date1 or not date2:
                return "ERROR: date1 and date2 are required for diff"
            d1 = _parse_iso_date(date1, fmt)
            d2 = _parse_iso_date(date2, fmt)
            delta_days = (d2 - d1).days
            u = (unit or "days").strip().lower()
            if u in ("day", "days"):
                return str(delta_days)
            if u in ("week", "weeks"):
                # 保留小数周，便于精确（如 10 天 -> 1.428571… 周）
                return f"{delta_days / 7.0:.6f}"
            return "ERROR: unit must be days or weeks"
        elif op_s == "add":
            if not date or not interval:
                return "ERROR: date and interval are required for add"
            base = _parse_iso_date(date, fmt)
            res = _apply_interval(base, interval)
            return res.strftime(fmt)
        else:
            return "ERROR: op must be 'diff' or 'add'"
    except Exception as e:
        return f"ERROR: {e}"


# 新增：MCP 通用调用与列出工具包装器
def tool__mcp__call(
    server: str,
    tool: str,
    params_json: str = "{}",
    raw: str = "false",
) -> str:
    """Call an MCP server tool via fastmcp.
    Parameters:
    - server: MCP server name (对应 mcpServers 配置中的键)
    - tool: 目标工具名（不含前缀，会自动按 <server>_<tool> 形式匹配；若直接提供全名也会尝试）
    - params_json: JSON 对象字符串，作为工具参数
    - raw: "true"/"false" 返回原始结构（包含 data/text）
    返回：
      - 工具执行结果文本；或以 "ERROR: " 开头的错误信息
    使用建议：
      - 当需要调用尚未自动注入到 TOOLS_REGISTRY 的远程工具时，可用本包装器。
      - 若希望让模型自动发现并直接以 <server>_<tool> 形式调用，可在启动阶段先手动执行一次 tool__mcp__list 促使人类将其加入上下文说明。
    """
    try:
        want_raw = str(raw).strip().lower() in {"1", "true", "yes", "on"}
        return mcp_call(server=server, tool=tool, params_json=params_json, raw=want_raw)
    except Exception as e:
        return f"ERROR: {e}"


def tool__mcp__list(server: str | None = None, json_mode: str = "false") -> str:
    """List registered MCP tools (optionally filtered by server).
    Parameters:
    - server: 仅列出该 server 前缀的工具（可为空）
    - json_mode: "true" 返回 JSON 结构；否则返回可读文本
    """
    try:
        jm = str(json_mode).strip().lower() in {"1", "true", "yes", "on"}
        # 复用已有函数并捕获其打印输出
        return _capture_print(list_registered_mcp_capabilities, server, jm)
    except Exception as e:
        return f"ERROR: {e}"


TOOLS_REGISTRY: Dict[str, Any] = {
    # Bio 工具注册
    "tool__bio__add": tool__bio__add,
    "tool__bio__update": tool__bio__update,
    "tool__bio__delete": tool__bio__delete,
    "tool__bio__list": tool__bio__list,
    # Todo 工具
    "tool__todo__add_task": tool__todo__add_task,
    "tool__todo__list": tool__todo__list,
    "tool__todo__show": tool__todo__show,
    "tool__todo__complete": tool__todo__complete,
    "tool__todo__report_daily": tool__todo__report_daily,
    "tool__todo__report_weekly": tool__todo__report_weekly,
    "tool__todo__update": tool__todo__update,
    "tool__todo__delete": tool__todo__delete,
    # # Jina 工具
    "tool__jina__web_search": tool__jina__web_search,
    "tool__jina__fetch_markdown": tool__jina__fetch_markdown,
    # Reflect 工具
    "tool__reflect__negate_and_reflect": tool__reflect__negate_and_reflect,
    # Human-in-Loop 与文件系统工具
    "tool__human__input": tool__human__input,
    "tool__fs__save_file": tool__fs__save_file,
    # 安全终止会话工具
    "tool__safety__terminate": tool__safety__terminate,
    # Util 工具
    "tool__calc__eval": tool__calc__eval,
    "tool__date__calc": tool__date__calc,
    "tool__mcp__call": tool__mcp__call,
    "tool__mcp__list": tool__mcp__list,
}

#
# endregion 15 Tool Wrappers (bio/todo/jina/reflect/fs/human/calc/date)
#############################


#############################
# region 16 Interactive Chat (interactive_invoke)
#
def interactive_invoke(
    system_prompt: str = DEFAULT_SYSTEM_PROMPT,
    model: str = "deepseek-chat",
    provider: str = "deepseek",
    api_key: Optional[str] = None,
    use_keychain: bool = True,
    initial_user: Optional[str] = None,
    role: str = "default",
    stream: bool = False,
    theme: str = "auto",
) -> None:
    """在终端进入多轮对话模式，支持 XML 工具调用。输入 /exit 退出。
    使用 prompt_toolkit 获得更好的中文输入与历史/补全体验，并用 rich 美化输出。

    新增：
    - 旋转指示器（弱色）展示 LLM 正在思考/调用 API。
    - 工具调用的请求与结果面板（弱色）。
    - 用户与助手消息分别使用不同颜色面板展示。
    - 在助手面板下方显示最新上下文窗口用量（依据 DeepSeek 返回的 usage），并统计会话累计消耗。
    - 对话管理：/undo 或 /del N 删除某一轮（user-assistant）对话。
    - 当模型消息混合自然语言与 <antml> 工具调用时，先展示自然语言，再执行工具并继续对话。
    """
    if provider == "moonshot":
        resolved_key = resolve_moonshot_key(api_key, use_keychain=use_keychain)
    elif provider == "openrouter":
        resolved_key = resolve_openrouter_key(api_key, use_keychain=use_keychain)
    else:
        resolved_key = resolve_api_key(api_key, use_keychain=use_keychain)
    if not resolved_key:
        if provider == "moonshot":
            missing_env = MOONSHOT_API_KEY_ENV
        elif provider == "openrouter":
            missing_env = OPENROUTER_API_KEY_ENV
        else:
            missing_env = API_KEY_ENV
        print(
            f"未找到 API Key，请通过 --api-key、环境变量 {missing_env}，或 macOS Keychain 设置",
            file=sys.stderr,
        )
        sys.exit(1)

    # 确保交互依赖存在
    if not (HAVE_PTK and HAVE_RICH):
        print(
            "缺少依赖，请先安装:\n\n  uv pip install prompt-toolkit rich\n",
            file=sys.stderr,
        )
        sys.exit(1)

    # 主题与风格定义
    def _select_theme(preferred: Optional[str]) -> str:
        t = (preferred or os.getenv("TODO_THEME") or "auto").strip().lower()
        if t not in {"light", "dark", "auto"}:
            t = "auto"
        if t == "auto":
            # 简单策略：默认 dark；如需更智能可按终端/主题检测扩展
            return "dark"
        return t

    def _theme_colors(name: str) -> Dict[str, str]:
        if name == "light":
            # 白昼模式：冷青/紫，保证在浅底上依然清晰；思考弱化但可读
            return {
                "ROLE_USER_BORDER": "bold deep_sky_blue3",  # 深天蓝
                "ROLE_ASSIST_BORDER": "bold medium_orchid3",  # 中兰花紫
                "WEAK_BORDER": "grey50",  # 中性灰
                "WEAK_STYLE": "dim",
                "REASONING_STYLE": "italic dim",
                "REASONING_BORDER": "light_steel_blue",  # 浅钢蓝
                "REASONING_PANEL_STYLE": "dim",
                "WELCOME_COLOR": "#4a90e2",  # 莫奈蓝
            }
        # 夜间模式：高对比霓虹风，回复更亮，思考略弱
        return {
            "ROLE_USER_BORDER": "bold dodger_blue1",  # 道奇蓝
            "ROLE_ASSIST_BORDER": "bold gold1",  # 金色
            "WEAK_BORDER": "grey66",  # 较亮灰
            "WEAK_STYLE": "dim",
            "REASONING_STYLE": "italic dim",
            "REASONING_BORDER": "light_goldenrod2",  # 浅金黄
            "REASONING_PANEL_STYLE": "dim",
            "WELCOME_COLOR": "#ffd700",  # 梵高金
        }

    _theme = _select_theme(theme)
    _pal = _theme_colors(_theme)
    ROLE_USER_BORDER = _pal["ROLE_USER_BORDER"]
    ROLE_ASSIST_BORDER = _pal["ROLE_ASSIST_BORDER"]
    WEAK_BORDER = _pal["WEAK_BORDER"]
    WEAK_STYLE = _pal["WEAK_STYLE"]
    REASONING_STYLE = _pal["REASONING_STYLE"]
    REASONING_BORDER = _pal["REASONING_BORDER"]
    REASONING_PANEL_STYLE = _pal["REASONING_PANEL_STYLE"]
    WELCOME_COLOR = _pal["WELCOME_COLOR"]
    MAX_CONTEXT_TOKENS = 65536  # DeepSeek 64k 上限

    # === 流式输出用动态 Panel 盒子 ===
    class _StreamPanels:
        def __init__(self, console: Any):
            self.console = console
            self.reasoning_parts: List[str] = []
            self.content_parts: List[str] = []
            self.antml_started = False
            self.started = False
            self.live: Any = None
            self.preface_text: str = ""
            self.antml_closed: bool = False
            # 节流与大文本参数（可用环境变量覆盖）
            self.last_update_ts: float = 0.0
            self.pending_chars: int = 0
            self.min_update_interval: float = float(
                os.getenv("TODO_STREAM_MIN_INTERVAL", "0.08")
            )  # 秒
            self.min_delta_chars: int = int(
                os.getenv("TODO_STREAM_MIN_DELTA_CHARS", "256")
            )
            self.MAX_RENDER_CHARS: int = int(
                os.getenv("TODO_STREAM_MAX_CHARS", "400000")
            )
            self.TAIL_RENDER_CHARS: int = int(
                os.getenv("TODO_STREAM_TAIL_CHARS", "4000")
            )
            # 可配置强制刷新频次（每 N 次内容增量触发一次刷新；0 或 <=1 表示不额外依赖次数）
            self.force_every_n: int = int(os.getenv("TODO_STREAM_FORCE_EVERY_N", "0"))
            self._update_call_count: int = (
                0  # 新增：累计 add_reasoning/add_content 调用次数
            )

        def _render(self) -> Any:

            # 思考 Panel
            try:
                from rich.text import Text  # type: ignore
            except Exception:
                Text = None  # type: ignore
            reasoning_txt = "".join(self.reasoning_parts)
            r_body: RenderableType  # type: ignore
            # 超长思考也仅尾部展示，避免卡顿
            if len(reasoning_txt) > self.MAX_RENDER_CHARS:
                tail = reasoning_txt[-self.TAIL_RENDER_CHARS :]
                head_note = (
                    f"…（思考输出较长，仅显示末尾 {self.TAIL_RENDER_CHARS} 字符）\n"
                )
                reasoning_render = head_note + tail
                if HAVE_RICH and Text is not None:
                    r_body = Text(reasoning_render, style=REASONING_STYLE)
                else:
                    r_body = reasoning_render
            else:
                if HAVE_RICH and Text is not None:
                    r_body = Text(reasoning_txt, style=REASONING_STYLE)
                else:
                    r_body = reasoning_txt or ""

            reason_panel = Panel(
                (
                    r_body
                    if reasoning_txt
                    else (
                        Text("（暂无思考输出）", style="dim")
                        if (HAVE_RICH and Text is not None)
                        else "（暂无思考输出）"
                    )
                ),
                title="助手（思考）",
                border_style=REASONING_BORDER,
                style=REASONING_PANEL_STYLE,
            )

            # 回复 Panel（在检测到 antml 前渲染正文；检测到后改为提示）
            c_body: RenderableType  # type: ignore

            if not self.antml_started:
                body = "".join(self.content_parts)
                if len(body) <= self.MAX_RENDER_CHARS:
                    # 短文本时用 Markdown；长文本 Markdown 解析很慢
                    c_body = (
                        Markdown(body)
                        if (Markdown is not None and body)
                        else (body or "")
                    )
                else:
                    tail = body[-self.TAIL_RENDER_CHARS :]
                    note = f"…（输出较长，仅显示末尾 {self.TAIL_RENDER_CHARS} 字符）\n"
                    # 大文本流式过程禁用 Markdown，改用纯文本以提速
                    c_body = note + tail
                reply_title = "助手（回复）"
            else:
                preface = (self.preface_text or "").strip()
                if preface:
                    # 对先行回复也应用长文本尾部展示策略
                    if len(preface) <= self.MAX_RENDER_CHARS:
                        c_body = (
                            Markdown(preface)
                            if HAVE_RICH and Markdown is not None
                            else preface
                        )
                    else:
                        tail = preface[-self.TAIL_RENDER_CHARS :]
                        note = (
                            f"…（输出较长，仅显示末尾 {self.TAIL_RENDER_CHARS} 字符）\n"
                        )
                        c_body = note + tail
                    reply_title = "助手（先行回复）"
                else:
                    try:
                        from rich.text import Text as _Text  # type: ignore

                        c_body = _Text("已生成工具调用，稍后执行…", style="dim")
                    except Exception:
                        c_body = "已生成工具调用，稍后执行…"
                    reply_title = "助手（回复）"

            reply_panel = Panel(
                c_body,
                title=reply_title,
                border_style=ROLE_ASSIST_BORDER,
            )

            # 组合两个 Panel（上下堆叠）
            if HAVE_RICH and Group is not None:
                return Group(reason_panel, reply_panel)
            return f"{reason_panel}\n{reply_panel}"

        def _ensure_started(self) -> None:
            if not self.started and HAVE_RICH and Live is not None:
                # 降低刷新频率，减少渲染压力
                self.live = Live(self._render(), console=self.console, refresh_per_second=8)  # type: ignore
                self.live.start()
                self.started = True

        # 新增：节流判断
        def _should_update(self) -> bool:
            now = time.monotonic()
            if (now - self.last_update_ts) >= self.min_update_interval:
                return True
            if self.pending_chars >= self.min_delta_chars:
                return True
            return False

        def _do_update(self) -> None:
            if self.live:
                self.live.update(self._render())
            self.pending_chars = 0
            self.last_update_ts = time.monotonic()

        def add_reasoning(self, piece: str) -> None:
            if not piece:
                return
            self.reasoning_parts.append(piece)

            # 新增：调用计数与强制刷新逻辑（reasoning）
            self._update_call_count += 1
            if (
                self.force_every_n > 1
                and (self._update_call_count % self.force_every_n == 0)
                and self.live
            ):
                self.pending_chars = 0  # 重置字符计数，避免下次立即又因字符触发
                self.last_update_ts = 0  # 置零时间以允许下一次正常节流判断
                self._ensure_started()
                self._do_update()
                return  # 本次已强制刷新，结束

            self.pending_chars += len(piece)
            self._ensure_started()
            if self._should_update():
                self._do_update()

        def add_content(self, piece: str) -> None:
            if not piece:
                return
            if not self.antml_started:
                self.content_parts.append(piece)
                joined = "".join(self.content_parts)
                if "<antml:function_calls>" in joined:
                    # 首次检测到开标签：仅展示开标签之前的自然语言，避免半截标签外泄
                    self.antml_started = True
                    try:
                        self.preface_text = preface_before_antml(joined)
                    except Exception:
                        self.preface_text = joined
            else:
                # antml 开始后仍累积，保证 stop 时能展示提示
                self.content_parts.append(piece)
                joined = "".join(self.content_parts)
                # 首次检测到闭合标签后，升级为“移除所有工具块”的完整自然语言（含工具块之后的文字）
                if (not self.antml_closed) and ("</antml:function_calls>" in joined):
                    try:
                        self.preface_text = strip_all_antml_blocks(joined)
                        # 占位符：避免被 Markdown 当作 HTML 标签吞掉，使用反引号包裹
                        _OPEN = "<antml:function_calls>"
                        _CLOSE = "</antml:function_calls>"
                        _PLACE_RAW = "<｜调用工具｜>"
                        _PLACE_SHOW = "`" + _PLACE_RAW + "`"
                        _s = joined
                        _i = _s.find(_OPEN)
                        if _i != -1:
                            _j = _s.find(_CLOSE, _i)
                            if _j != -1:
                                after_idx = _j + len(_CLOSE)
                                before_part = _s[:_i]
                                after_part = _s[after_idx:]
                                # 若结尾即工具块（after_part 为空），仍强制加入占位符，防止语义断裂
                                merged = (
                                    before_part + _PLACE_SHOW + after_part
                                ).strip()
                                self.preface_text = merged
                                # 若稍后模型又输出自然语言分片，会在 elif self.antml_closed 分支刷新
                    except Exception:
                        # 回退为仅保留开标签之前的部分
                        self.preface_text = preface_before_antml(joined)
                    self.antml_closed = True
                elif self.antml_closed:
                    # 已闭合且继续到来新内容：需要持续把占位符保留在最初位置
                    try:
                        _OPEN = "<antml:function_calls>"
                        _CLOSE = "</antml:function_calls>"
                        _PLACE_RAW = "<｜调用工具｜>"
                        _PLACE_SHOW = "`" + _PLACE_RAW + "`"
                        _s = joined
                        _i = _s.find(_OPEN)
                        if _i != -1:
                            _j = _s.find(_CLOSE, _i)
                            if _j != -1:
                                after_idx = _j + len(_CLOSE)
                                before_part = _s[:_i]
                                after_part = _s[after_idx:]
                                merged = (
                                    before_part + _PLACE_SHOW + after_part
                                ).strip()
                                self.preface_text = merged
                        else:
                            # antml 原块可能已被剥离；若占位符不存在则补上（追加到末尾）
                            base_txt = strip_all_antml_blocks(joined)
                            if "<｜调用工具｜>" in base_txt or _PLACE_SHOW in base_txt:
                                self.preface_text = base_txt
                            else:
                                self.preface_text = (
                                    base_txt.rstrip() + " " + _PLACE_SHOW
                                ).strip()
                    except Exception:
                        pass

            # 新增：调用计数与强制刷新逻辑（content）
            self._update_call_count += 1
            if (
                self.force_every_n > 1
                and (self._update_call_count % self.force_every_n == 0)
                and self.live
            ):
                self.pending_chars = 0
                self.last_update_ts = 0
                self._ensure_started()
                self._do_update()
                return

            self.pending_chars += len(piece)
            self._ensure_started()
            if self._should_update():
                self._do_update()

        def stop(self) -> None:
            # 最终强制刷新一次，确保末尾占位符（例如 `<｜调用工具｜>` 包裹成的反引号片段）在节流未触发时仍被渲染
            if self.live:
                try:
                    self._do_update()  # 尝试最后一次刷新（忽略潜在异常）
                except Exception:
                    pass
                self.live.stop()
                self.live = None
            self.started = False
            try:
                self.console.print("")  # type: ignore
            except Exception:
                pass

    # 累计会话用量（基于每次请求的 usage 叠加，仅作参考，不代表当前上下文长度）
    session_usage = {"prompt_tokens": 0, "completion_tokens": 0, "total_tokens": 0}

    # 记录每一轮对话在 messages 中的片段位置，便于删除；并保存该轮的 usage 与摘要
    turns: List[Dict[str, Any]] = (
        []
    )  # {start:int, count:int, usage:dict, user:str, assistant:str}

    # 安全终止对话标志（由 tool__safety__terminate 触发）
    conversation_terminated: bool = False

    tools_desc = get_tools_description()
    guidance = (
        "\n\n"
        "当需要使用工具时，请严格按照以下 ANTML (Anthropic Tool Markup Language) 格式输出：  \n"
        "<antml:function_calls>  \n"
        '  <antml:invoke name="工具名称">  \n'
        '    <antml:parameter name="参数名1"><![CDATA[ 参数值1 ]]></antml:parameter>  \n'
        '    <antml:parameter name="参数名..."><![CDATA[ 参数值... ]]></antml:parameter>  \n'
        '    <antml:parameter name="参数名N"><![CDATA[ 参数值N ]]></antml:parameter>  \n'
        "  </antml:invoke>  \n"
        "</antml:function_calls>  \n"
        "### 详细规范说明  \n"
        "1. **外层容器**: 使用 `<antml:function_calls>` 标签包裹所有工具调用  \n"
        '2. **工具调用**: 每个工具使用 `<antml:invoke name="工具名">` 标签  \n'
        '3. **参数传递**: 使用 `<antml:parameter name="参数名"><![CDATA[  参数值 ]]></antml:parameter>` 格式  \n'
        '4. **commentary**: 额外加入 `<antml:parameter name="commentary"><![CDATA[ 原因/思考 ]]></antml:parameter>`，用于说明调用该工具的思考过程与理由；思考说明，仅用于向用户展示，提高可解释性，不会传入工具  \n'
        "5. **内部通信标签**: 工具调用结果的传递 `<antml:function_results>`，工具返回时由工具进行包装，你即不生成该标签，也不暴露该标签给用户。  \n工具调用结果的传递 `<antml:function_results>`，工具返回时由工具进行包装，你即不生成该标签，也不暴露该标签给用户。  \n工具调用结果的传递 `<antml:function_results>`，工具返回时由工具进行包装，你即不生成该标签，也不暴露该标签给用户。  \n"
        "### 示例演示  \n"
        "<antml:function_calls>  \n"
        '  <antml:invoke name="tool__jina__web_search">  \n'
        '    <antml:parameter name="commentary"><![CDATA[ 用户在问 X 的权威定义；，可能是为了确认具体网站链接，但我已有的知识不足以回答这个问题，让我先进行关键词搜索，看看有什么线索。我需要先用单一意图关键词检索定义与来源。 ]]></antml:parameter>  \n'
        '    <antml:parameter name="query"><![CDATA[ X term definition ]]></antml:parameter>  \n'
        "  </antml:invoke>  \n"
        "</antml:function_calls>  \n"
        "若无需工具，直接回复自然语言。深度研究模式下建议使用“工具后即刻反思并接续下一步”的紧耦合循环。  \n"
        "\n\n"
        "# 工具调用的解释性\n\n"
        "当你进行解释性文字输出时，仅在“解释”段落内转义 antml 标签符号，避免被宿主程序解析。  \n"
        "  - 按如下映射进行转义：`< -> &lt;`，`> -> &gt;`，`& -> &amp;`；在属性上下文再转义：`\" -> &quot;`，`' -> &apos;`。  \n"
        "  - 代码块与工具载荷（payload）不转义，请用代码围栏包裹，原样输出。  \n"
        "  - 将所有工具调用统一放在整条回复最末尾独立小节`工具调用`内；若无工具调用，写明`工具调用：无`。  \n"
        "  - 禁止在解释段落中输出未转义的 `<`、`>`、`&`；不要使用真实 XML 标签作为分隔符，使用纯文本分隔线（如`---`）。  \n"
    )
    # 若调用方未指定 --system（仍为 DEFAULT_SYSTEM_PROMPT），则在交互模式中使用角色身份提示词
    canonical_role = (role or "default").replace("-", "_").replace(" ", "_").lower()
    effective_system = (
        (
            build_role_identity_deep_researcher_prompt()
            if canonical_role == "deep_researcher"
            else (
                build_role_identity_game_roleplay_prompt()
                if canonical_role == "game_roleplay"
                else build_role_identity_prompt()
            )
        )
        if system_prompt == DEFAULT_SYSTEM_PROMPT
        else system_prompt
    )
    # 新增：在 header 与 effective_system 之间插入用户 Bio Markdown
    bio_md = build_user_bio_markdown()
    header = build_system_header(provider=provider, model=model)
    footer = build_system_footer(provider=provider, model=model)
    parts: List[str] = [header]
    if bio_md.strip():
        parts.append("")
        parts.append(bio_md)
    parts.extend(["", effective_system, "", tools_desc, "", guidance])
    parts.extend(["", footer])
    system_full = "\n".join(parts)
    messages: List[Dict[str, str]] = [{"role": "system", "content": system_full}]

    # 将本轮会话 messages 暴露给工具（就地清空/扩展以重置）
    global CURRENT_CHAT_MESSAGES
    CURRENT_CHAT_MESSAGES = messages

    # 新增：启动持久化会话并记录 system 提示词
    try:
        init_chat_db()
    except Exception:
        pass
    chat_session_uuid = chatdb_start_session(
        role=canonical_role, model=model, system_prompt=system_full, theme=_theme
    )
    chatdb_log_message(chat_session_uuid, 0, "system", system_full)

    console = Console()  # type: ignore

    # 新增：历史记录限制与禁用
    _hist_disabled = str(os.getenv(HISTORY_DISABLE_ENV, "")).strip().lower() in {
        "1",
        "true",
        "yes",
        "on",
    }
    _hist_max_lines = _parse_int_env(HISTORY_MAX_LINES_ENV, 20000)
    _hist_max_bytes = _parse_int_env(HISTORY_MAX_BYTES_ENV, 5_000_000)
    if not _hist_disabled:
        try:
            _prune_history_file(HISTORY_FILE, _hist_max_lines, _hist_max_bytes)
        except Exception:
            pass

    session = PromptSession(  # type: ignore
        "invoke> ",
        history=(None if _hist_disabled else FileHistory(str(HISTORY_FILE))),  # type: ignore
        auto_suggest=AutoSuggestFromHistory(),  # type: ignore
        completer=WordCompleter(
            [
                "/exit",
                ":q",
                "quit",
                "exit",
                "/tools",
                ":tools",
                "/help",
                ":help",
                "--help",
                "-h",
                "/undo",
                ":undo",
                "/del",
                "/turns",
                ":turns",
                "/history",
                "/system",
                ":system",
                ":model",
                "/model",
                ":role",
                "/role",
                "/block",
                "/blockend",
            ],
            ignore_case=True,
        ),  # type: ignore
    )

    # 新增：顶部欢迎语（粉玫瑰色）
    try:
        welcome_text = (
            "“最好的效率系统，是让你无需思考‘怎么用’而直接进入‘去做’的状态。”"
        )
        console.print(Panel(welcome_text, border_style=WELCOME_COLOR, style=WELCOME_COLOR))  # type: ignore
    except Exception:
        print("最好的效率系统，是让你无需思考‘怎么用’而直接进入‘去做’的状态。")

    def _print_user(text: str) -> None:
        try:
            content = Markdown(text) if Markdown else text  # type: ignore
            console.print(Panel(content, title="用户", border_style=ROLE_USER_BORDER))  # type: ignore
        except Exception:
            console.print(Panel(text, title="用户", border_style=ROLE_USER_BORDER))  # type: ignore

    def _print_assistant(text: str) -> None:
        out = (text or "").strip()
        try:
            content = Markdown(out) if out and Markdown else out  # type: ignore
            console.print(Panel(content, title="助手", border_style=ROLE_ASSIST_BORDER))  # type: ignore
        except Exception:
            console.print(Panel(out, title="助手", border_style=ROLE_ASSIST_BORDER))  # type: ignore

    # 新增：用于展示“先行回复”（当助手消息中夹带 antml 时，先把自然语言部分展示给用户）
    def _print_assistant_preface(text: str) -> None:
        out = (text or "").strip()
        if not out:
            return
        try:
            content = Markdown(out) if out and Markdown else out  # type: ignore
            console.print(Panel(content, title="助手（先行回复）", border_style=ROLE_ASSIST_BORDER))  # type: ignore
        except Exception:
            console.print(Panel(out, title="助手（先行回复）", border_style=ROLE_ASSIST_BORDER))  # type: ignore

    def _print_tool_request(calls_obj: List[Dict[str, Any]]) -> None:
        try:
            calls_json = json.dumps(calls_obj, ensure_ascii=False, indent=2)
            render = (
                Syntax(calls_json, "json", theme="monokai", word_wrap=True)  # type: ignore
                if Syntax is not None
                else calls_json
            )
            console.print(Panel(render, title="工具调用请求", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
        except Exception:
            console.print(Panel(str(calls_obj), title="工具调用请求", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore

    def _print_tool_results(results_obj: List[Dict[str, Any]]) -> None:
        try:
            results_json = json.dumps(results_obj, ensure_ascii=False, indent=2)
            render = (
                Syntax(results_json, "json", theme="monokai", word_wrap=True)  # type: ignore
                if Syntax is not None
                else results_json
            )
            console.print(Panel(render, title="工具调用结果", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
        except Exception:
            console.print(Panel(str(results_obj), title="工具调用结果", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore

    # 新增：单独输出每次工具调用附带的 commentary（不参与工具执行，仅展示）
    def _print_tool_commentaries(calls_obj: List[Dict[str, Any]]) -> None:
        for c in calls_obj:
            try:
                name = c.get("name", "")
                params = c.get("params", {}) or {}
                comm = params.get("commentary")
                if isinstance(comm, str) and comm.strip():
                    title = f"工具思考: {name}" if name else "工具思考"
                    try:
                        content = Markdown(comm.strip()) if Markdown else comm.strip()  # type: ignore
                        console.print(  # type: ignore
                            Panel(
                                content,
                                title=title,
                                border_style=WEAK_BORDER,
                                style="italic dim",
                            )
                        )
                    except Exception:
                        console.print(  # type: ignore
                            Panel(
                                comm.strip(),
                                title=title,
                                border_style=WEAK_BORDER,
                                style="italic dim",
                            )
                        )
            except Exception:
                # 忽略任何展示上的异常，避免干扰主流程
                pass

    # 新增：上下文窗口用量展示
    def _print_token_usage(
        latest_usage: Dict[str, Any], elapsed_sec: Optional[float] = None
    ) -> None:
        p = int((latest_usage or {}).get("prompt_tokens") or 0)
        c = int((latest_usage or {}).get("completion_tokens") or 0)
        tot = int((latest_usage or {}).get("total_tokens") or 0)
        pct = (p / MAX_CONTEXT_TOKENS * 100.0) if MAX_CONTEXT_TOKENS else 0.0
        details = (latest_usage or {}).get("prompt_tokens_details") or {}
        cached = details.get("cached_tokens")
        hit = (latest_usage or {}).get("prompt_cache_hit_tokens")
        miss = (latest_usage or {}).get("prompt_cache_miss_tokens")

        lines: List[str] = []
        lines.append(f"本次请求: prompt {p}, completion {c}, total {tot}")
        if isinstance(elapsed_sec, (int, float)) and elapsed_sec and elapsed_sec > 0:
            c_tps = (c / elapsed_sec) if c > 0 else 0.0
            lines.append(
                f"耗时: {elapsed_sec:.3f}s; 速率: completion {c_tps:.2f} tok/s"
            )
        lines.append(f"上下文占用: {p}/{MAX_CONTEXT_TOKENS} ({pct:.2f}%)")

        detail_parts: List[str] = []
        if isinstance(cached, int):
            detail_parts.append(f"cached {cached}")
        if isinstance(hit, int):
            detail_parts.append(f"cache_hit {hit}")
        if isinstance(miss, int):
            detail_parts.append(f"cache_miss {miss}")
        if detail_parts:
            lines.append("详情: " + ", ".join(detail_parts))
        lines.append(
            f"会话累计消耗: prompt {session_usage['prompt_tokens']}, completion {session_usage['completion_tokens']}, total {session_usage['total_tokens']}"
        )
        try:
            console.print(Panel("\n".join(lines), title="上下文窗口用量", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
        except Exception:
            print("\n".join(lines))

    def _add_usage(u: Optional[Dict[str, Any]]) -> None:
        if not isinstance(u, dict):
            return
        session_usage["prompt_tokens"] += int(u.get("prompt_tokens") or 0)
        session_usage["completion_tokens"] += int(u.get("completion_tokens") or 0)
        session_usage["total_tokens"] += int(u.get("total_tokens") or 0)

    def _snippet(s: Optional[str], n: int = 30) -> str:
        txt = (s or "").replace("\n", " ")
        return (txt[:n] + ("…" if len(txt) > n else "")) if txt else ""

    def _print_turns_overview() -> None:
        if not turns:
            console.print(Panel("无对话记录。", title="对话流水", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
            return
        lines: List[str] = []
        for i, t in enumerate(turns, 1):
            u = t.get("usage") or {}
            p = int(u.get("prompt_tokens") or 0)
            c = int(u.get("completion_tokens") or 0)
            tot = int(u.get("total_tokens") or 0)
            us = _snippet(t.get("user"))
            asst = _snippet(t.get("assistant"))
            lines.append(
                f"{i}. prompt {p}, completion {c}, total {tot} | 用户: {us} | 助手: {asst}"
            )
        console.print(Panel("\n".join(lines), title="对话流水", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore

    def _delete_turn(n: int) -> None:
        if not (1 <= n <= len(turns)):
            console.print(Panel(f"无效的轮次编号: {n}", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
            return
        info = turns.pop(n - 1)
        start = info["start"]
        count = info["count"]
        # 从会话累计中扣除该轮 usage
        u = info.get("usage") or {}
        try:
            session_usage["prompt_tokens"] = max(
                0, session_usage["prompt_tokens"] - int(u.get("prompt_tokens") or 0)
            )
            session_usage["completion_tokens"] = max(
                0,
                session_usage["completion_tokens"]
                - int(u.get("completion_tokens") or 0),
            )
            session_usage["total_tokens"] = max(
                0, session_usage["total_tokens"] - int(u.get("total_tokens") or 0)
            )
        except Exception:
            pass
        # 删除消息并回调后续起点
        del messages[start : start + count]
        for j in range(n - 1, len(turns)):
            turns[j]["start"] -= count
        console.print(Panel(f"已删除第 {n} 轮对话（移除 {count} 条消息）。后续回复将基于更新后的上下文。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore

    def chat_turn(user_text: str) -> None:
        # 本轮起始位置
        start_len = len(messages)
        # turn 序号（从 1 开始，0 为 system）
        turn_index = len(turns) + 1
        # 展示用户消息（彩色）
        _print_user(user_text)

        nonlocal conversation_terminated  # 新增：允许在子函数内更新终止标志

        messages.append(
            {
                "role": "user",
                "content": user_text
                + build_author_note(provider=provider, model=model),
            }
        )  # 注入脚注防止遗忘
        # 新增：记录用户消息
        chatdb_log_message(chat_session_uuid, turn_index, "user", user_text)
        latest_elapsed: Optional[float] = None

        # 统一的安全换行函数：优先使用 rich，失败回退到 stdout
        def _newline(times: int = 1) -> None:
            if times <= 0:
                return
            try:
                # rich 的空字符串打印自带换行；多次调用以产生多行
                for _ in range(times):
                    console.print("")
            except Exception:
                try:
                    sys.stdout.write("\n" * times)
                    sys.stdout.flush()
                except Exception:
                    pass

        # 新增：回调工厂 —— 复用思考输出与结束换行（改为写入 StreamBox）
        def _make_reasoning_handlers(
            box: _StreamPanels,
        ) -> Tuple[ReasoningHandler, ReasoningEndHandler, ReasoningState]:
            state: ReasoningState = {"started": False}

            def _on_reasoning(piece: str) -> None:
                if not piece:
                    return
                state["started"] = True
                box.add_reasoning(piece)

            def _on_reasoning_end() -> None:
                # 双 Panel 自行承载
                pass

            return _on_reasoning, _on_reasoning_end, state

        # 新增：回调工厂 —— 复用 content 分片输出（改为写入 StreamBox，并保留 antml 检测）
        def _make_content_delta_handler(
            box: _StreamPanels,
        ) -> Tuple[DeltaHandler, ContentDeltaState]:
            state: ContentDeltaState = {
                "assistant_buf": [],
                "content_started": False,
                "antml_started": False,
            }

            def _on_delta(piece: str) -> None:
                if not piece:
                    return
                state["assistant_buf"].append(piece)
                if not state["antml_started"] and "<antml:function_calls>" in "".join(
                    state["assistant_buf"]
                ):
                    state["antml_started"] = True
                box.add_content(piece)

            return _on_delta, state

        try:
            # 先得出一轮回答
            if not stream:
                # 非流式：保持原面板风格
                with console.status("[dim]模型思考中...[/dim]", spinner="dots", spinner_style=WEAK_BORDER):  # type: ignore
                    _t0 = time.perf_counter()
                    assistant, usage1 = invoke_chat(
                        messages,
                        model=model,
                        provider=provider,
                        api_key=resolved_key,
                        return_usage=True,
                    )
                    latest_elapsed = time.perf_counter() - _t0
                # 新增：记录助手消息（非流式，无 reasoning）
                chatdb_log_message(
                    chat_session_uuid,
                    turn_index,
                    "assistant",
                    assistant,
                    reasoning=None,
                    usage=usage1,
                    elapsed_sec=latest_elapsed,
                )
            else:
                # 流式：实时输出 content 与 reasoning_content
                stream_ui = _StreamPanels(console)
                # 收集 reasoning 以便入库
                r_collected: List[str] = []
                on_reasoning, on_reasoning_end, r_state = _make_reasoning_handlers(
                    stream_ui
                )

                # 修改：在回调中累积 reasoning 文本
                def _on_reasoning_wrapper(piece: str) -> None:
                    if piece:
                        r_collected.append(piece)
                    on_reasoning(piece)

                on_delta, delta_state = _make_content_delta_handler(stream_ui)

                # 执行流式调用（会在回调中边到边打）
                _t0 = time.perf_counter()
                assistant, usage1 = invoke_chat(
                    messages,
                    model=model,
                    provider=provider,
                    api_key=resolved_key,
                    stream=True,
                    on_delta=on_delta,
                    on_reasoning=_on_reasoning_wrapper,
                    on_reasoning_end=on_reasoning_end,
                    return_usage=True,
                )
                latest_elapsed = time.perf_counter() - _t0
                # 结束动态 Panel
                stream_ui.stop()
                # 新增：记录助手消息（含流式 reasoning）
                chatdb_log_message(
                    chat_session_uuid,
                    turn_index,
                    "assistant",
                    assistant,
                    reasoning=("".join(r_collected) if r_collected else None),
                    usage=usage1,
                    elapsed_sec=latest_elapsed,
                )
                # 新增：长输出自动保存
                try:
                    LONG_SAVE_THRESHOLD = int(
                        os.getenv("TODO_STREAM_SAVE_THRESHOLD", "20000")
                    )
                    if (
                        isinstance(assistant, str)
                        and len(assistant) >= LONG_SAVE_THRESHOLD
                    ):
                        tmp_path = Path(f"/tmp/todo_invoke_{int(time.time())}.txt")
                        tmp_path.write_text(assistant, encoding="utf-8")
                        console.print(Panel(f"输出较长，已保存至: {tmp_path}", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                except Exception:
                    pass

            latest_usage: Dict[str, Any] = usage1 or {}
            _add_usage(usage1)

            # 将工具调用处理改为循环，直到没有 antml 或达到安全上限
            MAX_TOOL_ROUNDS = 6 if canonical_role == "deep_researcher" else 2
            tool_rounds = 0

            # 当触发“否定并反思”时，标记并提前结束本轮对话
            reflect_reset_triggered = False

            while True:
                calls = parse_antml_calls(assistant)
                if not calls:
                    break
                if tool_rounds >= MAX_TOOL_ROUNDS:
                    try:
                        console.print(Panel(f"已达到每轮工具调用上限 {MAX_TOOL_ROUNDS}，停止继续调用。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                    except Exception:
                        pass
                    break

                # 记录工具调用（含 commentary）
                round_index = tool_rounds + 1
                chatdb_log_tool_calls(chat_session_uuid, turn_index, round_index, calls)

                # 流式模式下：前面已实时输出过自然语言部分，这里不再重复展示 preface
                if not stream:
                    preface = strip_antml_block(assistant)
                    if preface and preface.strip():
                        _print_assistant_preface(preface)

                _print_tool_request(calls)
                # 单独展示 commentary
                _print_tool_commentaries(calls)
                # 执行工具（弱色旋转指示器）
                need_human = any(
                    isinstance(c.get("name"), str)
                    and c.get("name") == "tool__human__input"
                    for c in calls
                )
                if need_human:
                    # 人类输入工具会在内部打印 __HUMAN_INPUT_START__/END__，若仍包在 spinner 下会造成视觉叠加
                    try:
                        console.print(
                            Panel(
                                "等待人工输入工具执行（已暂停旋转指示器）",
                                border_style=WEAK_BORDER,
                                style=WEAK_STYLE,
                            )
                        )  # type: ignore
                    except Exception:
                        pass
                    results = execute_tools(calls)
                else:
                    with console.status("[dim]执行工具中...[/dim]", spinner="dots", spinner_style=WEAK_BORDER):  # type: ignore
                        results = execute_tools(calls)
                _print_tool_results(results)

                # 记录工具结果
                chatdb_log_tool_results(
                    chat_session_uuid, turn_index, round_index, results
                )
                # 同时把结果 XML 作为一条 role=tool 的消息入库（便于串读）
                results_xml = build_antml_results(results)
                chatdb_log_message(chat_session_uuid, turn_index, "tool", results_xml)

                # 把结果注入对话再问一次
                messages.append({"role": "assistant", "content": assistant})
                messages.append({"role": "user", "content": results_xml})

                # 检查是否有会话重置信号，若有则在再次调用前，按新起点彻底重置
                reflect_reset_triggered = any(
                    isinstance(r.get("output"), str)
                    and r.get("output").startswith(CONTROL_RESET)
                    for r in results
                )
                if reflect_reset_triggered:
                    global PENDING_RESET_MESSAGES, CURRENT_CHAT_MESSAGES
                    base_system = (
                        messages[0]
                        if messages
                        and isinstance(messages[0], dict)
                        and messages[0].get("role") == "system"
                        else None
                    )
                    new_pair = PENDING_RESET_MESSAGES or []
                    messages.clear()
                    if base_system is not None:
                        messages.append(base_system)
                    messages.extend(new_pair)
                    CURRENT_CHAT_MESSAGES = messages  # 保持指针一致
                    PENDING_RESET_MESSAGES = None

                    turns.clear()
                    start_len = len(messages)

                    try:
                        console.print(Panel("已执行“否定并反思”：已重置为新的对话起点，等待你的下一条输入。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                    except Exception:
                        print(
                            "已执行“否定并反思”：已重置为新的对话起点，等待你的下一条输入。"
                        )
                    # 反思成功，退出循环
                    break

                # 新增：检测安全终止控制信号（会话立即终止，不再追加模型调用）
                termination_triggered = any(
                    isinstance(r.get("output"), str)
                    and r.get("output").startswith(CONTROL_TERMINATE)
                    for r in results
                )
                if termination_triggered:
                    conversation_terminated = True
                    # 解析可选元数据（CONTROL:... 后的 JSON）
                    meta_raw = None
                    for r in results:
                        out = r.get("output") or ""
                        if isinstance(out, str) and out.startswith(CONTROL_TERMINATE):
                            parts_meta = out[len(CONTROL_TERMINATE) :].strip()
                            if parts_meta:
                                meta_raw = parts_meta
                            break
                    meta_view = ""
                    if meta_raw:
                        try:
                            meta_obj = json.loads(meta_raw)
                            cat = meta_obj.get("category") or ""
                            meta_view = f"分类: {cat}" if cat else ""
                        except Exception:
                            pass
                    try:
                        console.print(
                            Panel(
                                "出于安全与合规原因，对话已被终止。"
                                + (f"\n{meta_view}" if meta_view else ""),
                                title="安全终止",
                                border_style=WEAK_BORDER,
                                style=WEAK_STYLE,
                            )
                        )  # type: ignore
                    except Exception:
                        print("出于安全与合规原因，对话已被终止。")
                    break  # 跳出工具循环

                # 再次调用模型；失败时回滚注入的两条消息并交给外层异常处理
                try:
                    if not stream:
                        with console.status("[dim]模型思考中...[/dim]", spinner="dots", spinner_style=WEAK_BORDER):  # type: ignore
                            _t0 = time.perf_counter()
                            assistant, usageN = invoke_chat(
                                messages,
                                model=model,
                                provider=provider,
                                api_key=resolved_key,
                                return_usage=True,
                            )
                            latest_elapsed = time.perf_counter() - _t0
                        # 记录助手追问（非流式）
                        chatdb_log_message(
                            chat_session_uuid,
                            turn_index,
                            "assistant",
                            assistant,
                            reasoning=None,
                            usage=usageN,
                            elapsed_sec=latest_elapsed,
                        )
                    else:
                        # 第二轮及后续也使用流式输出
                        stream_ui2 = _StreamPanels(console)
                        r2_collected: List[str] = []
                        on_reasoning2, on_reasoning_end2, r2_state = (
                            _make_reasoning_handlers(stream_ui2)
                        )

                        def _on_reasoning_wrapper2(piece: str) -> None:
                            if piece:
                                r2_collected.append(piece)
                            on_reasoning2(piece)

                        on_delta2, delta2_state = _make_content_delta_handler(
                            stream_ui2
                        )

                        _t0 = time.perf_counter()
                        assistant, usageN = invoke_chat(
                            messages,
                            model=model,
                            provider=provider,
                            api_key=resolved_key,
                            stream=True,
                            on_delta=on_delta2,
                            on_reasoning=_on_reasoning_wrapper2,
                            on_reasoning_end=on_reasoning_end2,
                            return_usage=True,
                        )
                        latest_elapsed = time.perf_counter() - _t0
                        stream_ui2.stop()
                        # 记录助手追问（流式）
                        chatdb_log_message(
                            chat_session_uuid,
                            turn_index,
                            "assistant",
                            assistant,
                            reasoning=("".join(r2_collected) if r2_collected else None),
                            usage=usageN,
                            elapsed_sec=latest_elapsed,
                        )
                        # 新增：后续轮次也保存长输出
                        try:
                            LONG_SAVE_THRESHOLD = int(
                                os.getenv("TODO_STREAM_SAVE_THRESHOLD", "20000")
                            )
                            if (
                                isinstance(assistant, str)
                                and len(assistant) >= LONG_SAVE_THRESHOLD
                            ):
                                tmp_path = Path(
                                    f"/tmp/todo_invoke_{int(time.time())}.txt"
                                )
                                tmp_path.write_text(assistant, encoding="utf-8")
                                console.print(Panel(f"输出较长，已保存至: {tmp_path}", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                        except Exception:
                            pass
                except Exception:
                    try:
                        if not reflect_reset_triggered:
                            del messages[-2:]
                    except Exception:
                        pass
                    raise

                latest_usage = usageN or {}
                _add_usage(usageN)
                tool_rounds += 1

            # 若已触发反思重置，则结束本轮对话，等待用户继续
            if reflect_reset_triggered:
                try:
                    base_idx = (
                        1 if (messages and messages[0].get("role") == "system") else 0
                    )
                    if len(messages) >= base_idx + 2:
                        turns.append(
                            {
                                "start": base_idx,
                                "count": 2,
                                "usage": {
                                    "prompt_tokens": 0,
                                    "completion_tokens": 0,
                                    "total_tokens": 0,
                                },
                                "user": messages[base_idx].get("content", ""),
                                "assistant": messages[base_idx + 1].get("content", ""),
                            }
                        )
                    # 反思流程结束，新内容已覆盖，重置反思触发状态
                    reflect_reset_triggered = False
                except Exception:
                    pass
                return

            # 若安全终止已触发，直接结束本轮并不再输出后续助手内容
            if conversation_terminated:
                return

            # 已流式输出过的回复无需再以面板重复打印
            if not stream:
                _print_assistant(assistant)
            # 在助手 panel 下展示上下文窗口用量
            _print_token_usage(latest_usage, elapsed_sec=latest_elapsed)
            messages.append({"role": "assistant", "content": assistant})

            # 记录本轮片段范围与 usage、摘要
            end_len = len(messages)
            turns.append(
                {
                    "start": start_len,
                    "count": end_len - start_len,
                    "usage": latest_usage or {},
                    "user": user_text,
                    "assistant": assistant,
                }
            )
        except KeyboardInterrupt:
            # 用户在生成/流式过程中按下 Ctrl+C：撤回本轮新增消息并提示已中断，而不退出整体会话
            try:
                del messages[start_len:]
            except Exception:
                pass
            try:
                console.print(Panel("已中断当前生成（Ctrl+C）。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
            except Exception:
                print("已中断当前生成（Ctrl+C）。")
            return
        except Exception as e:
            # 任一阶段失败时回滚本轮新增的消息，保持会话上下文整洁，便于用户重试
            try:
                del messages[start_len:]
            except Exception:
                pass
            # 以弱色提示错误，但不中断交互循环
            try:
                console.print(Panel(f"模型调用失败：{e}", title="错误", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
            except Exception:
                print(f"模型调用失败：{e}")
            return

    if initial_user:
        chat_turn(initial_user)

    # 新增：块输入模式状态
    block_mode: bool = False
    block_lines: List[str] = []

    try:
        while True:
            try:
                user_in = session.prompt().strip()  # type: ignore
                _ctrl_c_count = 0  # 正常获取到输入即重置 Ctrl+C 计数
                # 新增：每次输入后再裁剪一次，防止会话内无限增长
                if not _hist_disabled:
                    _prune_history_file(HISTORY_FILE, _hist_max_lines, _hist_max_bytes)
            except KeyboardInterrupt:
                # 第一次 Ctrl+C：取消当前输入并给出提示；第二次（连续）才退出
                if "_ctrl_c_count" not in locals():
                    _ctrl_c_count = 0
                _ctrl_c_count += 1
                if _ctrl_c_count >= 2:
                    console.print("")  # 退出（与原行为一致，留空行美观）
                    break
                try:
                    console.print(Panel("已取消当前输入（再次 Ctrl+C 退出交互）。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                except Exception:
                    print("已取消当前输入（再次 Ctrl+C 退出交互）。")
                continue
            except EOFError:
                console.print("")
                break
            # 块输入模式处理
            if block_mode:
                if user_in == "/blockend":
                    block_text = "\n".join(block_lines).strip()
                    block_lines.clear()
                    block_mode = False
                    if block_text:
                        chat_turn(block_text)
                    else:
                        try:
                            console.print(Panel("空块已丢弃。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                        except Exception:
                            print("空块已丢弃。")
                    continue
                else:
                    # 累积块内容行（原样保留）
                    block_lines.append(user_in)
                    continue

            # 进入块输入模式
            if user_in == "/block":
                block_mode = True
                block_lines.clear()
                try:
                    console.print(Panel("进入块输入模式：粘贴多行文本，输入 /blockend 结束。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                except Exception:
                    print("进入块输入模式：输入 /blockend 结束。")
                continue

            # 未在块模式下收到 /blockend
            if user_in == "/blockend":
                try:
                    console.print(Panel("当前不在块输入模式。使用 /block 开始。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                except Exception:
                    print("当前不在块输入模式。使用 /block 开始。")
                continue

            if user_in in {"/exit", ":q", "quit", "exit"}:
                break
            if user_in in {"/tools", ":tools"}:
                try:
                    console.print(Panel("工具描述", title="Tools", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                    # 以 typescript 语法高亮展示工具签名
                    if Syntax is not None:  # type: ignore
                        console.print(Syntax(tools_desc, "ts", theme="monokai", word_wrap=True))  # type: ignore
                    else:
                        console.print(tools_desc)
                except Exception:
                    console.print(tools_desc)
                continue
            # 新增：查看系统提示词
            if user_in in {"/system", ":system"}:
                try:
                    content = Markdown(system_full) if Markdown else system_full  # type: ignore
                    console.print(Panel(content, title="系统提示词", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                except Exception:
                    console.print(Panel(system_full, title="系统提示词", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                continue
            if user_in.startswith("/model") or user_in.startswith(":model"):
                parts = user_in.split(maxsplit=1)
                # 无参数或帮助时输出当前模型与用法
                if len(parts) == 1 or parts[1] in {"?", "help", "-h", "--help"}:
                    try:
                        console.print(Panel(f"当前模型: {model}\n用法: /model <new_model>", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                    except Exception:
                        print(f"当前模型: {model}\n用法: /model <new_model>")
                    continue
                new_model = (parts[1] or "").strip()
                if not new_model:
                    try:
                        console.print(Panel("用法: /model <new_model>", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                    except Exception:
                        print("用法: /model <new_model>")
                    continue
                # 切换模型（对后续对话生效，不重置上下文）
                model = new_model
                try:
                    console.print(Panel(f"已切换模型: {model}", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                except Exception:
                    print(f"已切换模型: {model}")
                # 可选：记录一条系统日志到会话数据库（不加入上下文）
                try:
                    chatdb_log_message(
                        chat_session_uuid,
                        len(turns) + 1,
                        "system",
                        f"[switch-model] {model}",
                    )
                except Exception:
                    pass
                continue

            if user_in.startswith("/role") or user_in.startswith(":role"):
                parts = user_in.split(maxsplit=1)
                if len(parts) == 1 or parts[1] in {"?", "help", "-h", "--help"}:
                    try:
                        console.print(
                            Panel(
                                f"当前角色: {canonical_role}\n可选: default, deep_researcher, game_roleplay\n用法: /role <name>",
                                border_style=WEAK_BORDER,
                                style=WEAK_STYLE,
                            )
                        )  # type: ignore
                    except Exception:
                        print(
                            f"当前角色: {canonical_role}\n可选: default, deep_researcher, game_roleplay\n用法: /role <name>"
                        )
                    continue

                new_role_raw = (parts[1] or "").strip()
                if not new_role_raw:
                    try:
                        console.print(Panel("用法: /role <name>", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                    except Exception:
                        print("用法: /role <name>")
                    continue

                # 规范化与生效
                canonical_role = (
                    new_role_raw.replace("-", "_").replace(" ", "_").lower()
                )

                # 当调用方使用的是默认系统提示词时，按角色构造新的系统提示；否则沿用用户自定义 system
                new_effective_system = (
                    (
                        build_role_identity_deep_researcher_prompt()
                        if canonical_role == "deep_researcher"
                        else (
                            build_role_identity_game_roleplay_prompt()
                            if canonical_role == "game_roleplay"
                            else build_role_identity_prompt()
                        )
                    )
                    if system_prompt == DEFAULT_SYSTEM_PROMPT
                    else system_prompt
                )

                # 重新拼装 system_full，并替换 messages[0]
                parts_list: List[str] = [header]
                if bio_md.strip():
                    parts_list.append("")
                    parts_list.append(bio_md)
                parts_list.extend(
                    ["", new_effective_system, "", tools_desc, "", guidance]
                )
                parts_list.extend(["", footer])
                system_full = "\n".join(parts_list)

                if messages and messages[0].get("role") == "system":
                    messages[0]["content"] = system_full
                else:
                    messages.insert(0, {"role": "system", "content": system_full})

                try:
                    console.print(Panel(f"已切换角色: {canonical_role}", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                except Exception:
                    print(f"已切换角色: {canonical_role}")

                # 可选：写入一条系统日志（不参与对话上下文推理）
                try:
                    chatdb_log_message(
                        chat_session_uuid,
                        len(turns) + 1,
                        "system",
                        f"[switch-role] {canonical_role}",
                    )
                except Exception:
                    pass
                continue

            if user_in in {"/turns", ":turns", "/history"}:
                _print_turns_overview()
                continue
            if user_in in {
                "/help",
                ":help",
                "--help",
                "-h",
            }:
                console.print(
                    "输入内容与模型对话；/tools 查看可用工具；/system 查看系统提示词；/turns 列出对话流水；/undo 撤销上一轮；/del N 删除第 N 轮；/model <name> 切换模型；/role <name> 切换角色；/block 进入多行块输入；/blockend 结束块输入；/exit 退出。"
                )
                continue
            # 撤销与删除回合
            if user_in in {"/undo", ":undo", "/del-last"}:
                if turns:
                    _delete_turn(len(turns))
                else:
                    console.print(Panel("没有可删除的对话。", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                continue
            if user_in.startswith("/del") or user_in.startswith(":del"):
                parts = user_in.split()
                if len(parts) == 2 and parts[1].isdigit():
                    _delete_turn(int(parts[1]))
                else:
                    console.print(Panel("用法: /del <轮次编号>", border_style=WEAK_BORDER, style=WEAK_STYLE))  # type: ignore
                continue
            if not user_in:
                continue
            chat_turn(user_in)
    except KeyboardInterrupt:
        console.print("")  # newline
    except Exception as loop_e:
        # 新增：兜底异常捕获，避免 DB 会话泄漏或连接处于不一致状态
        try:
            console.print(
                Panel(
                    f"交互主循环出现未捕获异常：{loop_e}",
                    title="异常",
                    border_style=WEAK_BORDER,
                    style=WEAK_STYLE,
                )
            )  # type: ignore
        except Exception:
            print(f"交互主循环出现未捕获异常：{loop_e}")
    finally:
        # 统一在 finally 中结束会话，防止异常时 DB 连接悬挂或损坏
        try:
            chatdb_end_session(chat_session_uuid)
        except Exception:
            pass
        return


#
# endregion 16 Interactive Chat (interactive_invoke)
#############################


#############################
# region 17 CLI main() & Argument Parsing
#
def main() -> None:
    p = argparse.ArgumentParser()
    sub = p.add_subparsers(dest="cmd")
    addp = sub.add_parser("add")
    addp.add_argument("title", nargs="+")
    addp.add_argument("--time")
    addp.add_argument("--project")
    addp.add_argument("--tags", help="comma separated")
    addp.add_argument("--notes", help="pass multi-line notes with \\n or quoted block")

    sub.add_parser("today")
    sub.add_parser("list-all")
    lp = sub.add_parser("list")
    lp.add_argument("--date")
    sp = sub.add_parser("search")
    sp.add_argument("query")
    cp = sub.add_parser("complete")
    cp.add_argument("id")
    cp.add_argument("--note", help="append note on completion")

    # new: update & delete
    upd = sub.add_parser("update")
    upd.add_argument("id")
    upd.add_argument("--title")
    upd.add_argument("--time")
    upd.add_argument("--status", choices=STATUS_VALUES)
    upd.add_argument("--project")
    upd.add_argument("--tags", help="comma separated; empty string to clear")
    upd.add_argument("--notes", help="replace entire notes")
    upd.add_argument("--note-append", help="append note with timestamp")

    delp = sub.add_parser("delete")
    delp.add_argument("id")

    exp = sub.add_parser("export")
    exp.add_argument("--format", choices=["csv", "md"], default="csv")
    exp.add_argument("--out", default="todo_export")
    sub.add_parser("report-daily").add_argument("--date", nargs="?")
    sub.add_parser("report-weekly").add_argument("--start", nargs="?")

    # 新增命令：打印 tools 描述
    sub.add_parser("tools")

    # 新增命令：列出使用到的文件路径
    pp = sub.add_parser("paths")
    pp.add_argument("--json", action="store_true", help="以 JSON 格式输出路径信息")

    # 设置/读取 API Key（支持 DeepSeek 与 Jina；保留 --api-key 兼容 DeepSeek）
    keyp = sub.add_parser("config-api")
    keyp.add_argument(
        "--deepseek-key",
        help=f"explicit DeepSeek key, or set env {API_KEY_ENV}",
    )
    keyp.add_argument(
        "--jina-key",
        help=f"explicit Jina key, or set env {JINA_API_KEY_ENV}",
    )
    keyp.add_argument(
        "--moonshot-key",
        help=f"explicit Moonshot key, or set env {MOONSHOT_API_KEY_ENV}",
    )
    keyp.add_argument(
        "--openrouter-key",
        help=f"explicit OpenRouter key, or set env {OPENROUTER_API_KEY_ENV}",
    )

    # 新增：Jina Web 搜索
    wsp = sub.add_parser("web-search")
    wsp.add_argument("query")
    wsp.add_argument("--api-key", help=f"explicit key, or set env {JINA_API_KEY_ENV}")
    wsp.add_argument(
        "--full", action="store_true", help="return full content instead of no-content"
    )

    # 新增：Jina Reader 抓取网页 Markdown
    wfp = sub.add_parser("web-fetch")
    wfp.add_argument("url")
    wfp.add_argument("--api-key", help=f"explicit key, or set env {JINA_API_KEY_ENV}")

    # 调用 DeepSeek
    inv = sub.add_parser("invoke")
    inv.add_argument(
        "prompt", nargs="?", help="user prompt text (optional in --interactive)"
    )
    inv.add_argument(
        "--interactive",
        action="store_true",
        help="enter interactive multi-turn chat with tool calls (XML)",
    )
    inv.add_argument("--system", default=DEFAULT_SYSTEM_PROMPT)
    inv.add_argument(
        "--model",
        choices=[
            "deepseek-chat",
            "deepseek-reasoner",
            "kimi-k2-turbo-preview",
            "kimi-k2-0711-preview",
            "kimi-thinking-preview",
            # --- OpenRouter 示例模型 ---
            "openai/gpt-5-mini",
            "openai/gpt-oss-120b",
            "deepseek/deepseek-r1-0528",
        ],
        default="deepseek-chat",
    )
    inv.add_argument(
        "--provider", choices=["deepseek", "moonshot", "openrouter"], default="deepseek"
    )
    inv.add_argument("--api-key")
    inv.add_argument(
        "--no-keychain", action="store_true", help="do not read from Keychain"
    )
    inv.add_argument(
        "--role",
        choices=[
            "default",
            "deep-researcher",
            "deep_researcher",
            "deep researcher",
            "game-roleplay",
            "game_roleplay",
            "game roleplay",
        ],
        default="default",
        help="选择角色身份；deep researcher 启用深度研究模式; game roleplay 开启角色扮演",
    )
    inv.add_argument(
        "--stream",
        action="store_true",
        help="以流式方式输出模型回复",
    )
    inv.add_argument(
        "--theme",
        choices=["light", "dark", "auto"],
        default="auto",
        help="交互配色主题（light/dark/auto，亦可用环境变量 TODO_THEME 指定）",
    )

    mcp_reg = sub.add_parser(
        "mcp-register", help="快速注册（或覆盖）一个 process 模式 MCP Server"
    )
    mcp_reg.add_argument("name", help="server 名称")
    mcp_reg.add_argument(
        "entry",
        nargs="?",
        help="向后兼容：作为 command；若使用 --command 则可省略",
    )
    mcp_reg.add_argument("--command", help="可执行程序（缺省使用 entry）")
    mcp_reg.add_argument(
        "--args",
        nargs="*",
        default=[],
        help="传给命令的参数（空格分隔）",
    )
    mcp_reg.add_argument(
        "--env",
        action="append",
        default=[],
        help="注入环境变量（格式 KEY=VALUE，可多次）",
    )
    mcp_reg.add_argument(
        "--timeout",
        type=int,
        default=30,
        help="初始化 & 工具调用默认超时秒数（默认 30）",
    )
    mcp_reg.add_argument(
        "--meta",
        help="附加 JSON 元数据（可选）",
    )
    mcp_reg.add_argument(
        "--no-overwrite",
        action="store_true",
        help="存在时不覆盖（默认覆盖）",
    )

    # 新增：精细新增 process（与 mcp-register 近似，保留分离语义）
    mcp_add_proc = sub.add_parser(
        "mcp-add-process",
        help="显式新增一个 process 模式 MCP Server（不存在时添加，存在报错）",
    )
    mcp_add_proc.add_argument("name")
    mcp_add_proc.add_argument("--command", required=True)
    mcp_add_proc.add_argument("--args", nargs="*", default=[])
    mcp_add_proc.add_argument(
        "--env", action="append", default=[], help="KEY=VALUE，可多次"
    )
    mcp_add_proc.add_argument(
        "--timeout", type=int, default=30, help="超时秒数（默认 30）"
    )

    # 新增：更新
    mcp_upd = sub.add_parser(
        "mcp-update", help="更新已存在 server 的 command/args/env/timeout"
    )
    mcp_upd.add_argument("name")
    mcp_upd.add_argument("--command")
    mcp_upd.add_argument(
        "--args", nargs="*", help="若提供则整体替换 args；不提供保持不变"
    )
    mcp_upd.add_argument(
        "--env-set",
        action="append",
        default=[],
        help="设置/覆盖环境变量 KEY=VALUE，可多次",
    )
    mcp_upd.add_argument(
        "--env-del",
        action="append",
        default=[],
        help="删除环境变量 KEY，可多次",
    )
    mcp_upd.add_argument("--timeout", type=int, help="新的 timeoutSeconds")

    # 新增：关闭（不移除配置，只终止进程）
    mcp_shutdown = sub.add_parser(
        "mcp-shutdown", help="终止正在运行的 server 进程（保留配置）"
    )
    mcp_shutdown.add_argument("name")

    # 新增：tail stderr
    mcp_tail = sub.add_parser("mcp-tail", help="查看 server 最近 stderr 日志")
    mcp_tail.add_argument("name")
    mcp_tail.add_argument(
        "--lines", type=int, default=100, help="显示最近 N 行（默认 100）"
    )

    mcp_list = sub.add_parser("mcp-list")
    mcp_list.add_argument("--json", action="store_true")

    mcp_rm = sub.add_parser("mcp-remove")
    mcp_rm.add_argument("name")

    mcp_call_p = sub.add_parser("mcp-call", help="调用指定 MCP server 的工具")
    mcp_call_p.add_argument("server", help="server 名称")
    mcp_call_p.add_argument("tool", help="工具名称")
    mcp_call_p.add_argument(
        "--params",
        default="{}",
        help="JSON 对象字符串参数（默认 {}）",
    )
    mcp_call_p.add_argument(
        "--timeout",
        type=int,
        default=60,
        help="调用超时秒数（默认 60，覆盖配置文件 timeoutSeconds）",
    )
    mcp_call_p.add_argument(
        "--raw",
        action="store_true",
        help="输出原始 result JSON（不抽取 content.text）",
    )

    # --- 新增：mcp-capabilities 子命令 ---
    mcp_caps_p = sub.add_parser(
        "mcp-capabilities", help="列出（全部或指定）MCP server 的工具能力"
    )
    mcp_caps_p.add_argument(
        "--server",
        help="仅列出指定 server（缺省列出全部）",
    )
    mcp_caps_p.add_argument("--json", action="store_true", help="以 JSON 形式输出")

    args = p.parse_args()
    # 解析参数后再检查依赖，确保 -h 帮助可用
    ensure_dependencies()

    if args.cmd == "add":
        add_task(
            " ".join(args.title),
            time=args.time,
            project=args.project,
            tags=(args.tags.split(",") if args.tags else []),
            notes=(args.notes or ""),
        )
    elif args.cmd == "today":
        list_tasks_for_date(datetime.date.today().isoformat())
    elif args.cmd == "list-all":
        list_all()
    elif args.cmd == "list":
        list_tasks_for_date(args.date or datetime.date.today().isoformat())
    elif args.cmd == "search":
        search(args.query)
    elif args.cmd == "complete":
        complete(args.id, note_append=args.note)
    elif args.cmd == "update":
        update_task(
            args.id,
            title=getattr(args, "title", None),
            time=getattr(args, "time", None),
            status=getattr(args, "status", None),
            project=getattr(args, "project", None),
            tags=(args.tags.split(",") if args.tags is not None else None),
            notes=getattr(args, "notes", None),
            note_append=getattr(args, "note_append", None),
        )
    elif args.cmd == "delete":
        delete_task(args.id)
    elif args.cmd == "export":
        out = args.out + (".csv" if args.format == "csv" else ".md")
        if args.format == "csv":
            export_csv(out)
        else:
            export_md(out)
    elif args.cmd == "report-daily":
        report_daily(getattr(args, "date", None))
    elif args.cmd == "report-weekly":
        report_weekly(getattr(args, "start", None))
    elif args.cmd == "tools":
        print(get_tools_description())
    elif args.cmd == "paths":
        list_paths("json" if getattr(args, "json", False) else "plain")
    elif args.cmd == "config-api":
        # 读取输入：优先命令行参数，其次环境变量（便于快速补全）
        deepseek_key = (
            getattr(args, "deepseek_key", None)
            or getattr(args, "api_key", None)
            or os.getenv(API_KEY_ENV)
        )
        jina_key = getattr(args, "jina_key", None) or os.getenv(JINA_API_KEY_ENV)

        moonshot_key = getattr(args, "moonshot_key", None) or os.getenv(
            MOONSHOT_API_KEY_ENV
        )

        openrouter_key = getattr(args, "openrouter_key", None) or os.getenv(
            OPENROUTER_API_KEY_ENV
        )

        if (
            not deepseek_key
            and not jina_key
            and not moonshot_key
            and not openrouter_key
        ):
            print(
                f"请通过 --deepseek-key / --jina-key / --moonshot-key / --openrouter-key 传入，或先设置环境变量 {API_KEY_ENV} / {JINA_API_KEY_ENV} / {MOONSHOT_API_KEY_ENV} / {OPENROUTER_API_KEY_ENV}",
                file=sys.stderr,
            )
            sys.exit(1)

        # DeepSeek Key 处理
        if deepseek_key:
            dq = deepseek_key.replace("'", "'\"'\"'")
            d_export = f"export {API_KEY_ENV}='{dq}'"
            d_persist = f'echo "{d_export}" >> ~/.zshrc && source ~/.zshrc'
            if _is_macos():
                ok = save_api_key_to_keychain(deepseek_key, service=KEYCHAIN_SERVICE)
                if ok:
                    print("Saved DeepSeek key to Keychain")
                else:
                    print("保存 DeepSeek Key 到 Keychain 失败，可改用环境变量：")
                    print("\n# 当前会话生效")
                    print(d_export)
                    print("\n# 永久生效（追加到 ~/.zshrc）")
                    print(d_persist)
            else:
                print("当前环境不支持 Keychain，请使用环境变量配置 DeepSeek Key：")
                print("\n# 当前会话生效")
                print(d_export)
                print("\n# 永久生效（追加到 ~/.zshrc）")
                print(d_persist)

        # Moonshot Key 处理
        if moonshot_key:
            mq = moonshot_key.replace("'", "'\"'\"'")
            m_export = f"export {MOONSHOT_API_KEY_ENV}='{mq}'"
            m_persist = f'echo "{m_export}" >> ~/.zshrc && source ~/.zshrc'
            if _is_macos():
                ok = save_api_key_to_keychain(
                    moonshot_key, service=MOONSHOT_KEYCHAIN_SERVICE
                )
                if ok:
                    print("Saved Moonshot key to Keychain")
                else:
                    print("保存 Moonshot Key 到 Keychain 失败，可改用环境变量：")
                    print("\n# 当前会话生效")
                    print(m_export)
                    print("\n# 永久生效（追加到 ~/.zshrc）")
                    print(m_persist)
            else:
                print("当前环境不支持 Keychain，请使用环境变量配置 Moonshot Key：")
                print("\n# 当前会话生效")
                print(m_export)
                print("\n# 永久生效（追加到 ~/.zshrc）")
                print(m_persist)
        # OpenRouter Key 处理
        if openrouter_key:
            oq = openrouter_key.replace("'", "'\"'\"'")
            o_export = f"export {OPENROUTER_API_KEY_ENV}='{oq}'"
            o_persist = f'echo "{o_export}" >> ~/.zshrc && source ~/.zshrc'
            if _is_macos():
                ok = save_api_key_to_keychain(
                    openrouter_key, service=OPENROUTER_KEYCHAIN_SERVICE
                )
                if ok:
                    print("Saved OpenRouter key to Keychain")
                else:
                    print("保存 OpenRouter Key 到 Keychain 失败，可改用环境变量：")
                    print("\n# 当前会话生效")
                    print(o_export)
                    print("\n# 永久生效（追加到 ~/.zshrc）")
                    print(o_persist)
            else:
                print("当前环境不支持 Keychain，请使用环境变量配置 OpenRouter Key：")
                print("\n# 当前会话生效")
                print(o_export)
                print("\n# 永久生效（追加到 ~/.zshrc）")
                print(o_persist)

        # Jina Key 处理
        if jina_key:
            jq = jina_key.replace("'", "'\"'\"'")
            j_export = f"export {JINA_API_KEY_ENV}='{jq}'"
            j_persist = f'echo "{j_export}" >> ~/.zshrc && source ~/.zshrc'
            if _is_macos():
                ok = save_api_key_to_keychain(jina_key, service=JINA_KEYCHAIN_SERVICE)
                if ok:
                    print("Saved Jina key to Keychain")
                else:
                    print("保存 Jina Key 到 Keychain 失败，可改用环境变量：")
                    print("\n# 当前会话生效")
                    print(j_export)
                    print("\n# 永久生效（追加到 ~/.zshrc）")
                    print(j_persist)
            else:
                print("当前环境不支持 Keychain，请使用环境变量配置 Jina Key：")
                print("\n# 当前会话生效")
                print(j_export)
                print("\n# 永久生效（追加到 ~/.zshrc）")
                print(j_persist)

    elif args.cmd == "mcp-register":
        # 统一注册（允许覆盖）
        name = args.name
        cmd = args.command or args.entry
        if not cmd:
            print("缺少 command（未提供 entry 也未提供 --command）", file=sys.stderr)
            sys.exit(1)
        # 解析 env
        env_map: Dict[str, str] = {}
        for item in args.env:
            if "=" not in item:
                print(f"--env 需为 KEY=VAL: {item}", file=sys.stderr)
                sys.exit(1)
            k, v = item.split("=", 1)
            env_map[k.strip()] = v
        meta_obj = None
        if getattr(args, "meta", None):
            try:
                meta_obj = json.loads(args.meta)
            except Exception as e:
                print(f"解析 --meta 失败: {e}", file=sys.stderr)
                sys.exit(1)
        cfg = _load_mcp_servers()
        servers = cfg.setdefault("servers", {})
        if name in servers and getattr(args, "no_overwrite", False):
            print(f"已存在 server 且指定 --no-overwrite: {name}", file=sys.stderr)
            sys.exit(2)
        servers[name] = {
            "mode": "process",
            "command": cmd,
            "args": args.args,
            "env": env_map,
            "timeoutSeconds": int(args.timeout),
            "meta": meta_obj or {},
        }
        _save_mcp_servers(cfg)
        # 若已在内存中运行且 command 变化，需要提示用户重启
        in_state = _MCP_STATE["servers"].get(name)
        if in_state and in_state.get("initialized"):
            print(
                f"[mcp] 已更新配置，但进程仍在运行（需要 mcp-shutdown {name} 后下次调用自动重启）"
            )
        else:
            print(f"[mcp] 已注册: {name}")

    elif args.cmd == "mcp-add-process":
        name = args.name
        cfg = _load_mcp_servers()
        servers = cfg.setdefault("servers", {})
        if name in servers:
            print(f"server 已存在: {name}", file=sys.stderr)
            sys.exit(1)
        env_map: Dict[str, str] = {}
        for item in args.env:
            if "=" not in item:
                print(f"--env 需为 KEY=VAL: {item}", file=sys.stderr)
                sys.exit(1)
            k, v = item.split("=", 1)
            env_map[k.strip()] = v
        servers[name] = {
            "mode": "process",
            "command": args.command,
            "args": args.args,
            "env": env_map,
            "timeoutSeconds": int(args.timeout),
        }
        _save_mcp_servers(cfg)
        print(f"[mcp] 新增 process server: {name}")

    elif args.cmd == "mcp-update":
        name = args.name
        cfg = _load_mcp_servers()
        servers = cfg.setdefault("servers", {})
        conf = servers.get(name)
        if not conf:
            print(f"不存在 server: {name}", file=sys.stderr)
            sys.exit(1)
        changed = False
        if args.command:
            conf["command"] = args.command
            changed = True
        if args.args is not None:
            conf["args"] = args.args
            changed = True
        if args.timeout is not None:
            conf["timeoutSeconds"] = int(args.timeout)
            changed = True
        # env set
        if args.env_set:
            conf.setdefault("env", {})
            if not isinstance(conf["env"], dict):
                conf["env"] = {}
            for item in args.env_set:
                if "=" not in item:
                    print(f"--env-set 需为 KEY=VAL: {item}", file=sys.stderr)
                    sys.exit(1)
                k, v = item.split("=", 1)
                conf["env"][k.strip()] = v
                changed = True
        # env del
        if args.env_del:
            if isinstance(conf.get("env"), dict):
                for k in args.env_del:
                    conf["env"].pop(k, None)
                    changed = True
        if not changed:
            print("无任何变更参数（未做修改）")
        else:
            _save_mcp_servers(cfg)
            print(f"[mcp] 已更新: {name} (下次调用若进程仍旧需先 mcp-shutdown)")

    elif args.cmd == "mcp-shutdown":
        name = args.name
        st = _MCP_STATE["servers"].get(name)
        if not st:
            print(f"[mcp] 未在内存中: {name}")
        else:
            proc = st.get("proc")
            if proc and hasattr(proc, "terminate"):
                try:
                    proc.terminate()
                    print(f"[mcp] 已发送 terminate: {name}")
                except Exception as e:
                    print(f"[mcp] terminate 失败: {e}", file=sys.stderr)
            else:
                print(f"[mcp] 无活动进程: {name}")
            # 不移除状态（保持 capabilities 可查），标记未初始化
            st["initialized"] = False

    elif args.cmd == "mcp-tail":
        name = args.name
        lines = int(getattr(args, "lines", 100) or 100)
        st = _MCP_STATE["servers"].get(name)
        if not st:
            print(f"[mcp] 未在内存中: {name}", file=sys.stderr)
            sys.exit(1)
        buf = st.get("stderr_buffer")
        if not isinstance(buf, list):
            print(
                "[mcp] 当前未捕获 stderr（需要升级 _spawn_process 以启动 stderr 采集线程）",
                file=sys.stderr,
            )
            sys.exit(2)
        tail = buf[-lines:]
        print("\n".join(tail))

    elif args.cmd == "mcp-list":
        print_mcp_servers(json_mode=getattr(args, "json", False))
    elif args.cmd == "mcp-remove":
        remove_mcp_server(args.name)
    elif args.cmd == "mcp-call":
        result = mcp_call(
            args.server,
            args.tool,
            getattr(args, "params", "{}"),
            timeout_override=getattr(args, "timeout", None),
            raw=getattr(args, "raw", False),
        )
        print(result)
    elif args.cmd == "mcp-capabilities":
        out = list_registered_mcp_capabilities(
            server=getattr(args, "server", None),
            json_mode=getattr(args, "json", False),
        )
        # list_registered_mcp_capabilities 已内部打印；仅在非 JSON 模式下再显式打印（保持行为一致）
        if not getattr(args, "json", False):
            print(out)
    elif args.cmd == "web-search":
        try:
            content = perform_jina_search(
                query=args.query,
                no_content=(not getattr(args, "full", False)),
                api_key=getattr(args, "api_key", None),
                endpoint=JINA_SEARCH_ENDPOINT,
            )
            print(content)
        except Exception as e:
            print(f"Web search failed: {e}", file=sys.stderr)
            sys.exit(1)
    elif args.cmd == "web-fetch":
        try:
            content = perform_jina_fetch_markdown(
                url=args.url,
                api_key=getattr(args, "api_key", None),
                endpoint=JINA_READER_ENDPOINT,
            )
            print(content)
        except Exception as e:
            print(f"Web fetch failed: {e}", file=sys.stderr)
            sys.exit(1)
    elif args.cmd == "invoke":
        if getattr(args, "interactive", False):
            try:
                interactive_invoke(
                    system_prompt=args.system,
                    model=args.model,
                    provider=args.provider,
                    api_key=args.api_key,
                    use_keychain=(not args.no_keychain),
                    initial_user=args.prompt,
                    role=getattr(args, "role", "default"),
                    stream=getattr(args, "stream", False),
                    theme=getattr(args, "theme", "auto"),
                )
            except Exception as e:
                print(f"Interactive invoke failed: {e}", file=sys.stderr)
                sys.exit(1)
        else:
            if not args.prompt:
                print(
                    "Missing prompt. Provide a prompt or use --interactive.",
                    file=sys.stderr,
                )
                sys.exit(2)
            try:
                # 若未自定义 system，则根据 --role 自动注入角色提示词
                _canon_role = (
                    (getattr(args, "role", "default") or "default")
                    .replace("-", "_")
                    .replace(" ", "_")
                    .lower()
                )
                _system = (
                    (
                        build_role_identity_deep_researcher_prompt()
                        if _canon_role == "deep_researcher"
                        else (
                            build_role_identity_game_roleplay_prompt()
                            if _canon_role == "game_roleplay"
                            else build_role_identity_prompt()
                        )
                    )
                    if (args.system == DEFAULT_SYSTEM_PROMPT)
                    else args.system
                )
                if getattr(args, "stream", False):
                    if args.provider == "moonshot":

                        def _print_delta(s: str) -> None:
                            sys.stdout.write(s)
                            sys.stdout.flush()

                        _ = invoke_moonshot(
                            prompt=args.prompt,
                            system_prompt=(
                                _system if _system else MOONSHOT_DEFAULT_SYSTEM_PROMPT
                            ),
                            model=args.model,
                            api_key=args.api_key,
                            stream=True,
                            endpoint=MOONSHOT_ENDPOINT,
                            on_delta=_print_delta,
                        )
                    elif args.provider == "openrouter":

                        def _print_delta(s: str) -> None:
                            sys.stdout.write(s)
                            sys.stdout.flush()

                        def _print_reasoning(r: str) -> None:
                            # 可根据需要加颜色或前缀，这里简单输出到 stderr
                            sys.stderr.write(r)
                            sys.stderr.flush()

                        def _reasoning_end() -> None:
                            sys.stderr.write("\n--- reasoning end ---\n")
                            sys.stderr.flush()

                        _ = invoke_openrouter(
                            prompt=args.prompt,
                            model=args.model,
                            system_prompt=_system,
                            api_key=args.api_key,
                            stream=True,
                            on_delta=_print_delta,
                            on_reasoning=_print_reasoning,
                            on_reasoning_end=_reasoning_end,
                        )
                    else:
                        # 流式输出：边到边打
                        def _print_delta(s: str) -> None:
                            sys.stdout.write(s)
                            sys.stdout.flush()

                        _ = invoke_deepseek(
                            prompt=args.prompt,
                            system_prompt=_system,
                            model=args.model,
                            api_key=args.api_key,
                            stream=True,
                            endpoint=DEEPSEEK_ENDPOINT,
                            on_delta=_print_delta,
                        )
                    print("")
                else:
                    if args.provider == "moonshot":
                        content = invoke_moonshot(
                            prompt=args.prompt,
                            system_prompt=(
                                _system if _system else MOONSHOT_DEFAULT_SYSTEM_PROMPT
                            ),
                            model=args.model,
                            api_key=args.api_key,
                            stream=False,
                            endpoint=MOONSHOT_ENDPOINT,
                        )
                    elif args.provider == "openrouter":
                        content = invoke_openrouter(
                            prompt=args.prompt,
                            model=args.model,
                            system_prompt=_system,
                            api_key=args.api_key,
                            stream=False,
                        )
                    else:
                        content = invoke_deepseek(
                            prompt=args.prompt,
                            system_prompt=_system,
                            model=args.model,
                            api_key=args.api_key,
                            stream=False,
                            endpoint=DEEPSEEK_ENDPOINT,
                        )
                    print(content)
            except Exception as e:
                print(f"Invoke failed: {e}", file=sys.stderr)
                sys.exit(1)
    else:
        p.print_help()


#
# endregion 17 CLI main() & Argument Parsing
#############################

if __name__ == "__main__":
    main()
